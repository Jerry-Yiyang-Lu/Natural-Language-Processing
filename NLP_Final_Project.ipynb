{
  "metadata": {
    "orig_nbformat": 4,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bjp7sIPa1Cyy",
        "97oQNNir0wYu",
        "q_LJ34hc0ua6",
        "AjKWxZvOzs-q",
        "3E7hHv3w1znU",
        "Bs963S1k12Bj",
        "-a4XtoTG133J",
        "FolACw4-15Fd",
        "pY5BpysB16Sk",
        "wA9QjVzM17is"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Session Prep**"
      ],
      "metadata": {
        "id": "bjp7sIPa1Cyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR-mWy6bmK63",
        "outputId": "c000e4fe-326b-4f76-95b6-d27b1620af12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install pydrive to load data\n",
        "!pip install -U -q Pydrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials. get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "2mMQAPMUmLl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.google.com/spreadsheets/d/13g6pResyKlWomR7O-wiRnswIvVa5nGaU/edit?usp=sharing&ouid=108977082471473204318&rtpof=true&sd=true\n",
        "id = \"13g6pResyKlWomR7O-wiRnswIvVa5nGaU\"\n",
        "file = drive.CreateFile({'id':id})\n",
        "file.GetContentFile(\"E-Commerce Reviews Dataset.xlsx\")"
      ],
      "metadata": {
        "id": "JHB4dOkymOB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text normalization function\n",
        "# https://drive.google.com/file/d/1DEd0NGAZOz43u8TcCRooJQ4JZ-yP3yHS/view?usp=sharing\n",
        "id = \"1DEd0NGAZOz43u8TcCRooJQ4JZ-yP3yHS\"\n",
        "file_1 = drive.CreateFile({'id':id})\n",
        "file_1.GetContentFile(\"Text_Normalization_Function.ipynb\")\n",
        "%run \"Text_Normalization_Function.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goXl7VkPmQSo",
        "outputId": "1ba504ad-739c-4f1b-ed23-39e179ea602d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html.parser in /usr/local/lib/python3.7/dist-packages (0.2)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from html.parser) (3.11)\n",
            "Requirement already satisfied: pattern3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: pdfminer3k in /usr/local/lib/python3.7/dist-packages (from pattern3) (1.3.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern3) (4.6.3)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (from pattern3) (6.0.8)\n",
            "Requirement already satisfied: docx in /usr/local/lib/python3.7/dist-packages (from pattern3) (0.2.4)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (from pattern3) (3.17.6)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.7/dist-packages (from pattern3) (18.6.1)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (from pattern3) (20220319)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern3) (8.12.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern3) (2.0)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern3) (3.5.1)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern3) (3.1.0)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern3) (8.6.0)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern3) (3.5.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern3) (1.15.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.7/dist-packages (from portend>=2.1.1->cherrypy->pattern3) (5.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2022.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from docx->pattern3) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.7/dist-packages (from docx->pattern3) (7.1.2)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser->pattern3) (1.0.0)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy->pattern3) (3.7.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy->pattern3) (3.2.1)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (4.1.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern3) (3.8.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern3) (37.0.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern3) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern3) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern3) (2.21)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from pdfminer3k->pattern3) (3.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern3) (57.4.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the module 'sys' allows istalling module from inside Jupyter\n",
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install numpy\n",
        "import numpy as np\n",
        "\n",
        "!{sys.executable} -m pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "#Natrual Language ToolKit (NLTK)\n",
        "!{sys.executable} -m pip install nltk\n",
        "import nltk\n",
        "\n",
        "!{sys.executable} -m pip install sklearn\n",
        "from sklearn import metrics\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import  CountVectorizer #bag-of-words vectorizer \n",
        "from sklearn.decomposition import LatentDirichletAllocation #package for LDA\n",
        "\n",
        "# Plotting tools\n",
        "\n",
        "from pprint import pprint\n",
        "!{sys.executable} -m pip install pyLDAvis #visualizing LDA\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#define text normalization function\n",
        "# %run ./Text_Normalization_Function.ipynb #defining text normalization function\n",
        "\n",
        "#ignore warnings about future changes in functions as they take too much space\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ByGh528eFWWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ee8e96-d374-4d86-be52-4bd91f9c1545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"E-Commerce Reviews Dataset.xlsx\")"
      ],
      "metadata": {
        "id": "kmOjqXInmg6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg3VqCpOnYHF",
        "outputId": "2f403ef4-06d3-4968-dbec-817ca3b6f0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
              "       'Recommended IND', 'Positive Feedback Count', 'Division Name',\n",
              "       'Department Name', 'Class Name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSeZCkgGmrsH",
        "outputId": "c7dd5d40-4d55-431f-8b6a-d3e443379468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                    0\n",
              "Clothing ID                   0\n",
              "Age                           0\n",
              "Title                      3810\n",
              "Review Text                 845\n",
              "Rating                        0\n",
              "Recommended IND               0\n",
              "Positive Feedback Count       0\n",
              "Division Name                14\n",
              "Department Name              14\n",
              "Class Name                   14\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8_tFXaUnad7",
        "outputId": "faf80f3d-3ac8-4a78-c4dc-28b0a134dd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23486 entries, 0 to 23485\n",
            "Data columns (total 11 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Unnamed: 0               23486 non-null  float64\n",
            " 1   Clothing ID              23486 non-null  float64\n",
            " 2   Age                      23486 non-null  float64\n",
            " 3   Title                    19676 non-null  object \n",
            " 4   Review Text              22641 non-null  object \n",
            " 5   Rating                   23486 non-null  float64\n",
            " 6   Recommended IND          23486 non-null  float64\n",
            " 7   Positive Feedback Count  23486 non-null  float64\n",
            " 8   Division Name            23472 non-null  object \n",
            " 9   Department Name          23472 non-null  object \n",
            " 10  Class Name               23472 non-null  object \n",
            "dtypes: float64(6), object(5)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review=df.loc[:,[\"Review Text\",\"Age\",\"Department Name\"]].dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "f_vDhYVwmxpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8OY0gN_vwnk",
        "outputId": "2334c293-389b-4089-8682-4b78f6cd1b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22628"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_GenZ_tops=df_review.loc[(df['Age']<=25) & (df['Department Name']==\"Tops\"),][\"Review Text\"].tolist()\n",
        "df_GenZ_dress=df_review.loc[(df['Age']<=25) & (df['Department Name']==\"Dresses\"),][\"Review Text\"].tolist()\n",
        "df_GenZ_bottoms=df_review.loc[(df['Age']<=25) & (df['Department Name']==\"Bottoms\"),][\"Review Text\"].tolist()\n",
        "\n",
        "df_Millen_tops=df_review.loc[(df['Age']<=41) & (df['Age']>=26) & (df['Department Name']==\"Tops\"),][\"Review Text\"].tolist()\n",
        "df_Millen_dress=df_review.loc[(df['Age']<=41) & (df['Age']>=26) & (df['Department Name']==\"Dresses\"),][\"Review Text\"].tolist()\n",
        "df_Millen_bottoms=df_review.loc[(df['Age']<=41) & (df['Age']>=26) & (df['Department Name']==\"Bottoms\"),][\"Review Text\"].tolist()\n",
        "\n",
        "df_GenX_tops=df_review.loc[(df['Age']>=41) & (df['Department Name']==\"Tops\"),][\"Review Text\"].tolist()\n",
        "df_GenX_dress=df_review.loc[(df['Age']>=41) & (df['Department Name']==\"Dresses\"),][\"Review Text\"].tolist()\n",
        "df_GenX_bottoms=df_review.loc[(df['Age']>=41) & (df['Department Name']==\"Bottoms\"),][\"Review Text\"].tolist()"
      ],
      "metadata": {
        "id": "HDY6wo2lmt9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_review_list = df_review[\"Review Text\"].tolist()"
      ],
      "metadata": {
        "id": "vYYbQyVTn4nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(df_review)"
      ],
      "metadata": {
        "id": "2oYtY-Arpx1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (topic_idx))\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        \n",
        "def get_topic_words(vectorizer, lda_model, n_words):\n",
        "    keywords = np.array(vectorizer.get_feature_names())\n",
        "    topic_words = []\n",
        "    for topic_weights in lda_model.components_:\n",
        "        top_word_locs = (-topic_weights).argsort()[:n_words]\n",
        "        topic_words.append(keywords.take(top_word_locs).tolist())\n",
        "    return topic_words"
      ],
      "metadata": {
        "id": "Zs7RU66nFWWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GenZ_tops**"
      ],
      "metadata": {
        "id": "97oQNNir0wYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_GenZ_tops)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "TKdDdUca0wYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "0zi3u0e00wYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "065LJ-x20wYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6584ee2e-8173-45a5-e4b8-ec4330c0e33b",
        "id": "_4s2PCw60wYv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "size top like look fit love order wear really color\n",
            "Topic 1:\n",
            "color look fit size like side top bra dress small\n",
            "Topic 2:\n",
            "color size small top fit love look sweater perfect wear\n",
            "Topic 3:\n",
            "dress love wear great fit like buy look well size\n",
            "Topic 4:\n",
            "size top wear love look dress shoulder fit fabric nice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "eMWt7WOL0wYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5d9851-568b-4917-f399-a6b30fadae2f",
        "id": "Q05acByk0wYv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "0p      0.000444  0.000152  0.000119  0.000075  0.000171\n",
              "110lbs  0.000448  0.000152  0.000119  0.000072  0.000166\n",
              "12p     0.000248  0.000762  0.000119  0.000072  0.000166\n",
              "30dd    0.000056  0.000751  0.000583  0.000072  0.000171\n",
              "32d     0.000050  0.000152  0.000593  0.000072  0.000830\n",
              "34aa    0.000052  0.001364  0.000119  0.000072  0.000166\n",
              "34b     0.000052  0.001090  0.000808  0.000072  0.000166\n",
              "34c     0.000050  0.000174  0.000119  0.000640  0.000166\n",
              "34d     0.000248  0.000762  0.000594  0.000072  0.000166\n",
              "34dd    0.000644  0.000152  0.000124  0.000083  0.000806"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb72846c-65e5-41c2-8dc2-c91a80fec48e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0p</th>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110lbs</th>\n",
              "      <td>0.000448</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12p</th>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000762</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30dd</th>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.000751</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32d</th>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000593</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34aa</th>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.001364</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34b</th>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.001090</td>\n",
              "      <td>0.000808</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34c</th>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34d</th>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000762</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34dd</th>\n",
              "      <td>0.000644</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb72846c-65e5-41c2-8dc2-c91a80fec48e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb72846c-65e5-41c2-8dc2-c91a80fec48e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb72846c-65e5-41c2-8dc2-c91a80fec48e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "lJNzrLk50wYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693e12b0-dd8a-4251-f644-d79a5ab140e7",
        "id": "2mPa1GB10wYv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "size    0.022213  0.011798  0.022721  0.012255  0.021895\n",
              "top     0.021259  0.010164  0.017172  0.004444  0.018694\n",
              "like    0.019795  0.011273  0.002535  0.014537  0.007059\n",
              "look    0.019710  0.013320  0.015692  0.014115  0.014237\n",
              "fit     0.018727  0.012213  0.016217  0.021485  0.012356\n",
              "love    0.016005  0.008420  0.015694  0.026922  0.014487\n",
              "order   0.014266  0.005811  0.006285  0.003325  0.000173\n",
              "wear    0.013798  0.007175  0.013121  0.025052  0.015832\n",
              "really  0.012971  0.002915  0.000124  0.004386  0.007195\n",
              "color   0.012467  0.013598  0.025503  0.011830  0.003072"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aad8137f-ef48-443a-b7d8-ed252988fe3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>size</th>\n",
              "      <td>0.022213</td>\n",
              "      <td>0.011798</td>\n",
              "      <td>0.022721</td>\n",
              "      <td>0.012255</td>\n",
              "      <td>0.021895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0.021259</td>\n",
              "      <td>0.010164</td>\n",
              "      <td>0.017172</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.018694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0.019795</td>\n",
              "      <td>0.011273</td>\n",
              "      <td>0.002535</td>\n",
              "      <td>0.014537</td>\n",
              "      <td>0.007059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>look</th>\n",
              "      <td>0.019710</td>\n",
              "      <td>0.013320</td>\n",
              "      <td>0.015692</td>\n",
              "      <td>0.014115</td>\n",
              "      <td>0.014237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fit</th>\n",
              "      <td>0.018727</td>\n",
              "      <td>0.012213</td>\n",
              "      <td>0.016217</td>\n",
              "      <td>0.021485</td>\n",
              "      <td>0.012356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>0.016005</td>\n",
              "      <td>0.008420</td>\n",
              "      <td>0.015694</td>\n",
              "      <td>0.026922</td>\n",
              "      <td>0.014487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order</th>\n",
              "      <td>0.014266</td>\n",
              "      <td>0.005811</td>\n",
              "      <td>0.006285</td>\n",
              "      <td>0.003325</td>\n",
              "      <td>0.000173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wear</th>\n",
              "      <td>0.013798</td>\n",
              "      <td>0.007175</td>\n",
              "      <td>0.013121</td>\n",
              "      <td>0.025052</td>\n",
              "      <td>0.015832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>really</th>\n",
              "      <td>0.012971</td>\n",
              "      <td>0.002915</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.004386</td>\n",
              "      <td>0.007195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color</th>\n",
              "      <td>0.012467</td>\n",
              "      <td>0.013598</td>\n",
              "      <td>0.025503</td>\n",
              "      <td>0.011830</td>\n",
              "      <td>0.003072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aad8137f-ef48-443a-b7d8-ed252988fe3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aad8137f-ef48-443a-b7d8-ed252988fe3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aad8137f-ef48-443a-b7d8-ed252988fe3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d786a3-343c-4d73-dc00-c8a753dcb2c1",
        "id": "3hgZd0k20wYw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
              "topic                                                    \n",
              "0      150.222153  -72.269554       1        1  37.462092\n",
              "3       51.163364 -159.968018       2        1  25.320230\n",
              "2      -73.144554   21.523815       3        1  15.093366\n",
              "1      -66.410133 -110.606438       4        1  11.582280\n",
              "4       54.417324   12.443444       5        1  10.542032, topic_info=        Term        Freq       Total Category  logprob  loglift\n",
              "255    dress  247.000000  247.000000  Default  30.0000  30.0000\n",
              "832  sweater   67.000000   67.000000  Default  29.0000  29.0000\n",
              "760    small  116.000000  116.000000  Default  28.0000  28.0000\n",
              "191    color  167.000000  167.000000  Default  27.0000  27.0000\n",
              "880      top  185.000000  185.000000  Default  26.0000  26.0000\n",
              "..       ...         ...         ...      ...      ...      ...\n",
              "760    small    8.772011  116.183692   Topic5  -5.0112  -0.3338\n",
              "429     like    9.294139  168.962252   Topic5  -4.9534  -0.6505\n",
              "438   little    7.244377   91.273489   Topic5  -5.2026  -0.2838\n",
              "272     even    6.674547   45.543641   Topic5  -5.2845   0.3294\n",
              "222     cute    6.815503   76.457772   Topic5  -5.2636  -0.1677\n",
              "\n",
              "[379 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "5         4  0.692792      34aa\n",
              "11        3  0.686489       36b\n",
              "21        5  0.696249    actual\n",
              "22        1  0.432187  actually\n",
              "22        3  0.504218  actually\n",
              "...     ...       ...       ...\n",
              "987       1  0.825435       xsp\n",
              "988       4  0.692792  xspetite\n",
              "995       5  0.696326     yikes\n",
              "999       2  0.724341    zipper\n",
              "999       5  0.217302    zipper\n",
              "\n",
              "[662 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 3, 2, 5])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1351398900899381286176575023\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1351398900899381286176575023_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [37.46209170296543, 25.320229584768082, 15.093366483258922, 11.582280230150845, 10.542031998856723]}, \"tinfo\": {\"Term\": [\"dress\", \"sweater\", \"small\", \"color\", \"top\", \"shoulder\", \"size\", \"great\", \"pant\", \"side\", \"fabric\", \"shirt\", \"bra\", \"could\", \"show\", \"cut\", \"long\", \"low\", \"design\", \"neck\", \"wear\", \"jacket\", \"retailer\", \"skirt\", \"length\", \"perfect\", \"really\", \"piece\", \"time\", \"lovely\", \"skinny\", \"arm\", \"sloppy\", \"pant\", \"torso\", \"boxy\", \"cuff\", \"normally\", \"far\", \"crop\", \"height\", \"athletic\", \"believe\", \"adore\", \"jean\", \"petite\", \"sooo\", \"plum\", \"roomy\", \"flower\", \"plaid\", \"teal\", \"xsp\", \"denim\", \"bad\", \"wide\", \"roll\", \"body\", \"tall\", \"casual\", \"long\", \"leg\", \"sleeve\", \"big\", \"pretty\", \"order\", \"really\", \"cute\", \"usually\", \"lb\", \"like\", \"cardigan\", \"top\", \"length\", \"shirt\", \"size\", \"look\", \"since\", \"medium\", \"still\", \"fit\", \"super\", \"love\", \"little\", \"color\", \"wear\", \"great\", \"short\", \"small\", \"run\", \"think\", \"perfect\", \"large\", \"soft\", \"well\", \"last\", \"skort\", \"jogger\", \"piece\", \"bodice\", \"staple\", \"wrap\", \"figure\", \"notice\", \"lining\", \"match\", \"tights\", \"timeless\", \"pleat\", \"dress\", \"plan\", \"boot\", \"fully\", \"dinner\", \"specific\", \"brunch\", \"wrong\", \"holly\", \"particular\", \"modern\", \"pricey\", \"styling\", \"point\", \"zipper\", \"weather\", \"line\", \"vibrant\", \"lovely\", \"skirt\", \"slip\", \"great\", \"layer\", \"pattern\", \"booty\", \"buy\", \"wear\", \"love\", \"well\", \"sweater\", \"flattering\", \"fabric\", \"fit\", \"work\", \"receive\", \"waist\", \"material\", \"soft\", \"feel\", \"comfortable\", \"like\", \"bit\", \"large\", \"look\", \"color\", \"size\", \"beautiful\", \"short\", \"little\", \"extremely\", \"excite\", \"interesting\", \"collar\", \"natori\", \"unlike\", \"stay\", \"comment\", \"taupe\", \"clothing\", \"bunch\", \"leave\", \"week\", \"deal\", \"tt\", \"tulle\", \"portland\", \"panty\", \"push\", \"36b\", \"apparent\", \"weave\", \"stand\", \"birthday\", \"photograph\", \"swingy\", \"pleasant\", \"overwhelm\", \"wedge\", \"vintage\", \"feminine\", \"compare\", \"tent\", \"blouse\", \"adorable\", \"beautifully\", \"design\", \"previous\", \"small\", \"sweater\", \"winter\", \"orange\", \"amazing\", \"could\", \"actually\", \"color\", \"perfect\", \"coat\", \"shirt\", \"normal\", \"size\", \"problem\", \"arrive\", \"beautiful\", \"good\", \"top\", \"purchase\", \"comfortable\", \"look\", \"fit\", \"love\", \"bottom\", \"fabric\", \"gorgeous\", \"wear\", \"retailer\", \"large\", \"run\", \"little\", \"way\", \"think\", \"soft\", \"long\", \"order\", \"great\", \"neck\", \"slit\", \"cheap\", \"bow\", \"chested\", \"label\", \"elegant\", \"blazer\", \"stomach\", \"tank\", \"least\", \"salmon\", \"partially\", \"peplum\", \"liking\", \"cause\", \"camisole\", \"shed\", \"stet\", \"pin\", \"outstanding\", \"wearable\", \"beauty\", \"stitch\", \"tummy\", \"34aa\", \"xspetite\", \"necessary\", \"save\", \"bummer\", \"elastic\", \"full\", \"bra\", \"weird\", \"low\", \"gold\", \"side\", \"cup\", \"dry\", \"tie\", \"underneath\", \"mind\", \"show\", \"xl\", \"delicate\", \"nude\", \"waistband\", \"either\", \"wonderful\", \"weight\", \"wash\", \"part\", \"high\", \"cut\", \"model\", \"rather\", \"could\", \"length\", \"color\", \"photo\", \"look\", \"short\", \"much\", \"like\", \"fit\", \"size\", \"fabric\", \"small\", \"top\", \"little\", \"dress\", \"well\", \"love\", \"wear\", \"sweater\", \"order\", \"shoulder\", \"stiff\", \"broad\", \"amaze\", \"wrinkle\", \"idea\", \"dirty\", \"itch\", \"crease\", \"currently\", \"several\", \"skier\", \"location\", \"postmark\", \"boho\", \"billowy\", \"whimsical\", \"noticeable\", \"talk\", \"yikes\", \"tablecloth\", \"shame\", \"life\", \"actual\", \"smock\", \"surprisingly\", \"bill\", \"trouser\", \"lucky\", \"pale\", \"worth\", \"jumpsuit\", \"section\", \"swing\", \"snug\", \"touch\", \"pregnant\", \"rayon\", \"cling\", \"pull\", \"polka\", \"time\", \"typical\", \"brand\", \"probably\", \"jacket\", \"price\", \"print\", \"style\", \"size\", \"top\", \"nice\", \"reviewer\", \"sale\", \"fabric\", \"wear\", \"look\", \"love\", \"dress\", \"fit\", \"retailer\", \"want\", \"white\", \"really\", \"well\", \"small\", \"like\", \"little\", \"even\", \"cute\"], \"Freq\": [247.0, 67.0, 116.0, 167.0, 185.0, 17.0, 231.0, 133.0, 50.0, 29.0, 93.0, 65.0, 24.0, 53.0, 28.0, 35.0, 66.0, 19.0, 36.0, 13.0, 199.0, 35.0, 48.0, 44.0, 59.0, 75.0, 88.0, 25.0, 23.0, 26.0, 17.86334141261542, 31.561542402105008, 6.737416254975752, 43.94567259290485, 12.268637101780637, 12.22711501179496, 5.803803001473954, 11.350787665605539, 4.886199199079687, 4.884990738502349, 4.882203927583759, 4.873924616512907, 4.866021523887889, 4.860056405721401, 41.81533117103794, 52.96749239779318, 3.950633169468251, 3.9491381231090035, 9.216832706417552, 3.9460313471664263, 3.944202551841772, 3.944123462323789, 3.940868814718601, 7.634293354024836, 9.011606522668401, 22.879065346004616, 6.744490622801336, 15.478191898110973, 8.167167864835738, 22.540641000325678, 49.75119416528294, 16.511267987122594, 32.939641714738364, 26.676167941201328, 30.749726575416798, 66.74404672276259, 60.68502488742558, 52.06746323095686, 29.540698553197032, 20.104162864244536, 92.6131107758003, 11.233777471005373, 99.46338154453869, 35.620029928582724, 37.89507249604174, 103.92768257979863, 92.21395543394055, 16.532741494513807, 24.79963556117639, 22.743717106989724, 87.61727076205315, 25.522508986229035, 74.88170114385171, 39.96132040702989, 58.32813640380916, 64.55446570801989, 45.82092561899119, 32.61680717559779, 42.08426192734877, 27.582437250582856, 29.161014793774775, 29.6471875181803, 28.4720814157641, 28.777531561412665, 28.672633895956874, 6.6139773234413, 5.704351845360629, 5.696877299429003, 21.983015096466374, 4.790775544203927, 4.759626842686679, 4.744988160006444, 9.263451688782066, 8.447108868861541, 8.374940309107727, 3.8816969558745122, 3.8777646035407165, 3.8752712657611132, 3.8740661607489337, 200.67890425956304, 3.8684733388490353, 11.751012865009669, 2.972182624714997, 2.97216793354922, 2.966667443293438, 2.962757101231687, 2.959933195841907, 2.9590908192323684, 2.956911017798069, 2.956127185402117, 2.9431439912788866, 2.9351591946184667, 5.600137405741858, 10.27792300746153, 7.54227442682817, 18.341435346671307, 7.5159888827784815, 18.50112174235371, 29.496498380616764, 8.018062730364438, 70.28054923621424, 10.882595604610662, 17.42502327199645, 5.881160412290566, 44.802197970512246, 79.22025816890073, 85.13399166907378, 42.50660511957945, 31.020123473090155, 17.170501995783795, 36.380079990689005, 67.9416157411879, 25.195060714454453, 13.055007590639837, 20.18674467240954, 25.125086533220337, 28.425173075449617, 18.260711114597378, 24.04813853816892, 45.968707005775244, 21.26684211673109, 24.228769399419992, 44.63629933748933, 37.41076142580797, 38.75313669079739, 18.273315816506106, 16.918987055140803, 17.410953362780745, 7.366671505945518, 4.68794610765368, 3.787481597018081, 3.7877169453009336, 2.907994843872042, 2.9032016331619803, 2.9031255074210227, 2.902318425400506, 2.897663800795601, 2.8934414137649633, 2.8861261301454557, 5.417788362693011, 5.960198001100034, 4.585962177266732, 4.6133584648103865, 2.013228902325468, 2.013219339330722, 2.013212780422747, 2.0127350000845534, 2.0088335789760023, 2.0087860859538775, 2.008779343051152, 2.007875637436449, 2.0066379289863514, 2.006265563976241, 2.006196629089323, 2.0061570582288515, 2.005628779438782, 2.0054782488052014, 2.0039963473376177, 3.7549194764224563, 4.241080638436307, 4.679085959716329, 12.076992145507335, 4.6650038570429855, 4.662057783899595, 17.84558126184884, 3.5377810533175853, 42.72866032047818, 27.213210903917943, 8.014767802736214, 6.251486761653777, 6.547246102395324, 20.028089789530863, 6.90736047498263, 48.07387399107288, 25.35567184393641, 7.556577111112581, 19.501243547459403, 6.511999908768745, 42.8296005099149, 6.9376071711761504, 6.321544888516186, 16.011870852648613, 15.28206409503402, 32.37013048998771, 13.469290602026636, 15.640220095912841, 29.57920728488618, 30.568579504106655, 29.583914770505462, 10.790531009018311, 17.91670096756756, 10.640772764335248, 24.73345403096474, 12.143596491262443, 14.266514214695386, 12.210706884668909, 15.192200589076265, 10.88066997849092, 12.020905776056932, 12.209226336587394, 11.210617914376442, 11.84811029538106, 11.57829181753995, 12.541358061102896, 8.141023268583222, 5.47378124461194, 4.619193064938873, 4.601545908551185, 3.742344142066431, 3.7202000588991977, 6.385852089486029, 2.8608855672654667, 7.8521599236525494, 4.612312956964026, 1.982772703375093, 1.98277245988857, 1.9827721452910676, 1.9827716668042046, 1.982771040084907, 1.982770852541842, 1.982749024887145, 1.981714398040212, 1.9816789149504532, 1.9809609126984575, 1.9805203915379523, 1.979579909853018, 1.9761438186407354, 1.9733019657566346, 1.9730597904084202, 1.9730597904084202, 1.9725115614256032, 1.967963600674718, 1.9673295898921492, 4.396452987355844, 6.05552993304828, 14.614166424648502, 7.954200582456353, 11.864936503217416, 4.623881566723317, 15.898871773745135, 3.5456689860031068, 5.354200484219646, 6.87623115452263, 9.241982266951773, 5.105738378885443, 12.474853957620747, 3.363282513625775, 4.417264962787879, 2.8552717938579195, 2.8598366985562995, 5.446234662103468, 2.862020814009097, 7.6210335237631, 10.491907637718212, 7.83589935054501, 10.405546575941456, 10.934875692177249, 9.60359632290469, 5.976774792062078, 12.515922078483415, 12.677864824410932, 19.668971374422135, 8.254690021495177, 19.266989405926193, 12.313758281076305, 10.136941750929816, 16.30720785590007, 17.66589108141013, 17.066494951611546, 12.0631216323042, 12.92320679451544, 14.701668386370688, 11.464637528514837, 14.180237132731083, 11.261813410582963, 12.179696800085983, 10.379212066837463, 9.162933998975731, 8.405935616876928, 16.799657433355588, 4.588312699135637, 4.581038946940248, 4.563506391056979, 7.944575434459916, 3.703888126997753, 2.8408224572705256, 2.840810307978067, 2.8362493163476317, 2.832670046247784, 5.238257813763452, 1.9667209647719686, 1.9667199869143697, 1.966718349294075, 1.9667035860495565, 1.9666986149175592, 1.9655936125614972, 1.9654313847912395, 1.9647426346654728, 1.9642003754526274, 1.963469660358087, 1.9629937588753334, 1.9576746664026239, 1.9549698377245506, 1.9546911547828099, 1.9513597003443608, 1.9482897734304476, 1.9452483086463153, 1.940045358530855, 1.9400440795659974, 7.852408625668937, 6.695909596439738, 4.30296331200206, 3.713235636754008, 4.3222315455296165, 6.237649732215886, 2.8400545750483928, 2.8426222266463097, 2.823218844322517, 6.279857907963633, 2.818183764965998, 8.873628121026735, 2.7908401888423437, 4.988642623884933, 6.523166921412666, 9.786391681142359, 7.438142511478569, 9.088569560546446, 9.65036355612096, 28.827348667030353, 24.61181610508224, 12.133812975334049, 6.260526960891844, 7.929634383668782, 14.754388219353393, 20.8447491918398, 18.74382900140109, 19.07355758782089, 17.893934330303765, 16.26725871391051, 8.810295088958403, 8.734317918188458, 7.066328029218401, 9.473147426768175, 9.065280354769541, 8.772010535012244, 9.294139397764587, 7.244377363297803, 6.674547493346378, 6.8155027049227535], \"Total\": [247.0, 67.0, 116.0, 167.0, 185.0, 17.0, 231.0, 133.0, 50.0, 29.0, 93.0, 65.0, 24.0, 53.0, 28.0, 35.0, 66.0, 19.0, 36.0, 13.0, 199.0, 35.0, 48.0, 44.0, 59.0, 75.0, 88.0, 25.0, 23.0, 26.0, 19.700431807838584, 35.42394168894165, 7.638549750979651, 50.11099655821705, 14.115375605335103, 14.099257545781915, 6.707375170475481, 13.185644929937268, 5.777451011594003, 5.7774301299074375, 5.777238728764245, 5.777057925135365, 5.776751644351383, 5.776825756855504, 50.21140724553308, 63.99949596945358, 4.846574916185376, 4.846618358043835, 11.31336205892299, 4.846564487105979, 4.846207874847217, 4.846399794256986, 4.845927480028819, 9.46263624072124, 11.336050255023133, 28.84485074474486, 8.533501253484399, 19.612826709858403, 10.378211611312203, 28.947741618566063, 66.49113997500122, 21.39868887349642, 44.51141626766861, 36.20408286110736, 42.50401429198676, 97.74044632416194, 88.4768080266248, 76.45777202067349, 44.32496005768143, 28.722021234759733, 168.96225211115822, 15.009698932083355, 185.20059877374212, 59.50934726055368, 65.093047785189, 231.40426339915282, 204.44028046364335, 24.1859359262212, 41.40479529422707, 37.00578839073665, 220.06061580266837, 43.547230587365526, 220.85286197133783, 91.27348925069954, 167.52594798967712, 199.73213916656263, 133.127396578836, 71.4151473032904, 116.18369209975671, 53.46267581763474, 69.4741679272001, 75.86966120590823, 68.91097430009575, 76.11099583715009, 96.70835341015523, 7.525425979579445, 6.6108036770561025, 6.611082864039646, 25.752890856335174, 5.696377911234077, 5.696979530517517, 5.696850064707305, 11.162152127617702, 10.228928573247142, 10.225498522231511, 4.782034250561828, 4.782134104801625, 4.781714769373894, 4.781521729337066, 247.87248249100446, 4.781584226891752, 14.831696245886274, 3.867447331846538, 3.8674469549650325, 3.867246857806718, 3.8672433454457886, 3.867661458918839, 3.8671642871382943, 3.867005061957765, 3.8670678082395575, 3.867239426737222, 3.8666230950327747, 7.480454612152122, 13.8056432891687, 10.229683939178924, 25.634570028929687, 10.228547682039114, 26.57249744136237, 44.16447261921918, 11.08445221496859, 133.127396578836, 16.68143507675886, 28.429372168986166, 8.404419017334362, 87.8257432420228, 199.73213916656263, 220.85286197133783, 96.70835341015523, 67.86567972521675, 32.4006589493843, 93.10041950239483, 220.06061580266837, 57.08935655266099, 23.831825035532816, 45.24515658970885, 63.187132553900874, 76.11099583715009, 39.37216781523869, 61.213330951670414, 168.96225211115822, 53.99919552108706, 68.91097430009575, 204.44028046364335, 167.52594798967712, 231.40426339915282, 55.93874685318375, 71.4151473032904, 91.27348925069954, 8.282172666765108, 5.5979534827865205, 4.702967553600203, 4.703294464359782, 3.8081865723245585, 3.808099611439821, 3.808133268903027, 3.8081005520360947, 3.8080686721233046, 3.8082026868584125, 3.8083487456114606, 7.410724427980789, 8.31347883036256, 6.470261184848387, 6.53166242059365, 2.913406188624259, 2.9134061248945513, 2.9134061519242556, 2.913417082289106, 2.9133734327921905, 2.913581719522913, 2.9135817155407495, 2.913620209380965, 2.913550723900246, 2.913558504674424, 2.9134648628510336, 2.913561490706724, 2.9135728740333757, 2.913575152977327, 2.913775797601823, 5.576758116680505, 6.461597849381208, 7.346530527268818, 20.865850735899315, 7.347212149672508, 7.408836657523624, 36.56088152847453, 5.64406150175802, 116.18369209975671, 67.86567972521675, 15.572332602818905, 12.006150978147412, 12.747571490117988, 53.237907441447746, 13.88288428667433, 167.52594798967712, 75.86966120590823, 15.593749911231779, 65.093047785189, 12.894121554182357, 231.40426339915282, 14.578538053233185, 12.784380367019356, 55.93874685318375, 53.816875985855724, 185.20059877374212, 46.39245952455691, 61.213330951670414, 204.44028046364335, 220.06061580266837, 220.85286197133783, 32.991676746782304, 93.10041950239483, 34.8376381395199, 199.73213916656263, 48.268117782049366, 68.91097430009575, 53.46267581763474, 91.27348925069954, 44.65588584724995, 69.4741679272001, 76.11099583715009, 66.49113997500122, 97.74044632416194, 133.127396578836, 13.461880492549685, 9.055291679307189, 6.411909484634474, 5.530069726295345, 5.530550340284112, 4.648783648331747, 4.649723320027048, 8.187765873354246, 3.7677413748072808, 10.93320277000694, 6.42558813163224, 2.886326467275248, 2.8863264617364957, 2.88632647555616, 2.8863264795469163, 2.886326483047778, 2.8863264838629386, 2.886326821820519, 2.8863858027868314, 2.8863862417516035, 2.8863948280501, 2.886451222438797, 2.8863971366059213, 2.8862733416046473, 2.886798534263296, 2.8868706589773407, 2.8868706589773407, 2.886713410538852, 2.8868851480157307, 2.8871895052673, 6.452861445419019, 9.064889500375786, 24.097106253747082, 12.680437239864462, 19.889203068215828, 7.319895129986976, 29.874823971963412, 5.570709883417261, 9.113534393028996, 12.72481071305786, 18.232751118097443, 9.1273946431219, 28.172774866244247, 5.600956606077679, 8.244212713678913, 4.6628508362419065, 4.682142376753593, 11.067921429317899, 4.698200086106137, 18.186766313722774, 29.77828543200705, 20.11863740858142, 31.86273962087279, 35.58519952090148, 31.149033272621587, 13.752128884233306, 53.237907441447746, 59.50934726055368, 167.52594798967712, 28.118014910219024, 204.44028046364335, 71.4151473032904, 49.24537028538942, 168.96225211115822, 220.06061580266837, 231.40426339915282, 93.10041950239483, 116.18369209975671, 185.20059877374212, 91.27348925069954, 247.87248249100446, 96.70835341015523, 220.85286197133783, 199.73213916656263, 67.86567972521675, 97.74044632416194, 17.73279348478811, 5.494416625393727, 5.49468539943609, 5.4952971269512805, 9.889113700026368, 4.620567824765566, 3.7461605719453512, 3.7461608805764293, 3.746256690724106, 3.746609623096739, 7.29299369260562, 2.8720556058366467, 2.8720556541382445, 2.8720556905324126, 2.872056081176656, 2.872056228725941, 2.872107523071233, 2.8721041419001487, 2.872183135975229, 2.8722180978457565, 2.8722417949742134, 2.8722962940832923, 2.8723095250904693, 2.8725357329287022, 2.872197087097679, 2.8724190917026116, 2.8725523772612886, 2.873442452080119, 2.87319361044056, 2.873556421020684, 11.710468036774218, 10.010279933715832, 6.442321538820655, 5.55085428689035, 7.337257309844892, 12.608996217100806, 4.6410270694116, 4.6606294696736015, 4.642351510957073, 13.561784020767277, 4.661110227407721, 23.462066166914667, 4.680117044274041, 11.052663411702603, 18.239283656544703, 35.746762380598604, 23.378650844863422, 32.86589268567866, 38.1638868083345, 231.40426339915282, 185.20059877374212, 59.878092756302394, 19.08586215162208, 29.281726449672057, 93.10041950239483, 199.73213916656263, 204.44028046364335, 220.85286197133783, 247.87248249100446, 220.06061580266837, 48.268117782049366, 50.21681268540535, 32.870069604761696, 88.4768080266248, 96.70835341015523, 116.18369209975671, 168.96225211115822, 91.27348925069954, 45.54364056348352, 76.45777202067349], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.568, -4.9988, -6.5431, -4.6678, -5.9437, -5.9471, -6.6922, -6.0215, -6.8643, -6.8646, -6.8652, -6.8669, -6.8685, -6.8697, -4.7175, -4.4811, -7.0769, -7.0773, -6.2297, -7.0781, -7.0785, -7.0785, -7.0794, -6.4181, -6.2522, -5.3205, -6.542, -5.7113, -6.3506, -5.3354, -4.5437, -5.6467, -4.9561, -5.167, -5.0249, -4.2499, -4.3451, -4.4982, -5.065, -5.4498, -3.9223, -6.0318, -3.851, -4.8779, -4.8159, -3.8071, -3.9267, -5.6454, -5.2399, -5.3265, -3.9778, -5.2112, -4.1349, -4.7629, -4.3847, -4.2833, -4.626, -4.9659, -4.7111, -5.1336, -5.0779, -5.0614, -5.1018, -5.0912, -5.0948, -6.1699, -6.3178, -6.3191, -4.9688, -6.4923, -6.4989, -6.5019, -5.833, -5.9252, -5.9338, -6.7028, -6.7038, -6.7044, -6.7047, -2.7573, -6.7062, -5.5951, -6.9697, -6.9697, -6.9716, -6.9729, -6.9739, -6.9742, -6.9749, -6.9752, -6.9796, -6.9823, -6.3362, -5.729, -6.0385, -5.1499, -6.042, -5.1412, -4.6748, -5.9773, -3.8065, -5.6719, -5.2011, -6.2873, -4.2568, -3.6868, -3.6148, -4.3094, -4.6244, -5.2158, -4.465, -3.8404, -4.8324, -5.4899, -5.054, -4.8352, -4.7118, -5.1543, -4.879, -4.2311, -5.0019, -4.8715, -4.2605, -4.4371, -4.4018, -5.1536, -5.2306, -5.2019, -5.5447, -5.9967, -6.21, -6.2099, -6.4742, -6.4759, -6.4759, -6.4762, -6.4778, -6.4792, -6.4818, -5.852, -5.7566, -6.0187, -6.0127, -6.8419, -6.842, -6.842, -6.8422, -6.8441, -6.8442, -6.8442, -6.8446, -6.8452, -6.8454, -6.8454, -6.8455, -6.8457, -6.8458, -6.8465, -6.2186, -6.0969, -5.9986, -5.0504, -6.0016, -6.0022, -4.6599, -6.2782, -3.7868, -4.238, -5.4604, -5.7089, -5.6626, -4.5446, -5.6091, -3.6689, -4.3087, -5.5193, -4.5712, -5.668, -3.7845, -5.6047, -5.6977, -4.7684, -4.815, -4.0645, -4.9413, -4.7918, -4.1546, -4.1217, -4.1545, -5.163, -4.656, -5.177, -4.3335, -5.0449, -4.8838, -5.0394, -4.8209, -5.1547, -5.055, -5.0395, -5.1248, -5.0695, -5.0926, -4.7479, -5.18, -5.5769, -5.7467, -5.7505, -5.9572, -5.9631, -5.4228, -6.2258, -5.2161, -5.7482, -6.5924, -6.5924, -6.5924, -6.5924, -6.5924, -6.5924, -6.5924, -6.5929, -6.593, -6.5933, -6.5936, -6.594, -6.5958, -6.5972, -6.5973, -6.5973, -6.5976, -6.5999, -6.6002, -5.7961, -5.4759, -4.5949, -5.2032, -4.8033, -5.7457, -4.5107, -6.0112, -5.599, -5.3488, -5.0532, -5.6465, -4.7532, -6.064, -5.7914, -6.2277, -6.2261, -5.582, -6.2254, -5.246, -4.9263, -5.2182, -4.9346, -4.885, -5.0148, -5.489, -4.7499, -4.7371, -4.2979, -5.1661, -4.3185, -4.7662, -4.9607, -4.4853, -4.4053, -4.4398, -4.7868, -4.7179, -4.5889, -4.8376, -4.6251, -4.8555, -4.7771, -4.9371, -5.0617, -5.148, -4.3614, -5.6593, -5.6609, -5.6647, -5.1103, -5.8734, -6.1387, -6.1387, -6.1403, -6.1416, -5.5268, -6.5064, -6.5064, -6.5064, -6.5064, -6.5064, -6.507, -6.5071, -6.5074, -6.5077, -6.5081, -6.5083, -6.511, -6.5124, -6.5126, -6.5143, -6.5159, -6.5174, -6.5201, -6.5201, -5.122, -5.2813, -5.7235, -5.8709, -5.719, -5.3522, -6.139, -6.1381, -6.1449, -5.3455, -6.1467, -4.9997, -6.1565, -5.5756, -5.3074, -4.9018, -5.1762, -4.9758, -4.9158, -3.8215, -3.9796, -4.6868, -5.3485, -5.1122, -4.4913, -4.1457, -4.2519, -4.2345, -4.2983, -4.3936, -5.0069, -5.0155, -5.2275, -4.9343, -4.9784, -5.0112, -4.9534, -5.2026, -5.2845, -5.2636], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.884, 0.8664, 0.8563, 0.8506, 0.8416, 0.8394, 0.8371, 0.832, 0.8143, 0.814, 0.8135, 0.8118, 0.8103, 0.809, 0.7989, 0.7926, 0.7774, 0.7771, 0.7769, 0.7763, 0.7759, 0.7758, 0.7751, 0.7671, 0.7524, 0.7501, 0.7466, 0.7451, 0.7423, 0.7317, 0.6918, 0.7226, 0.6808, 0.6764, 0.6581, 0.6004, 0.6048, 0.5976, 0.5761, 0.6251, 0.3806, 0.6921, 0.3602, 0.4686, 0.4408, 0.1814, 0.1857, 0.6014, 0.4693, 0.4951, 0.0609, 0.4476, -0.0997, 0.1559, -0.0732, -0.1476, -0.0847, 0.1982, -0.0337, 0.32, 0.1137, 0.0422, 0.0979, 0.0092, -0.2339, 1.2445, 1.2261, 1.2247, 1.2153, 1.2004, 1.1938, 1.1907, 1.1871, 1.1822, 1.1739, 1.165, 1.1639, 1.1634, 1.1631, 1.1624, 1.1617, 1.1407, 1.1103, 1.1103, 1.1085, 1.1071, 1.1061, 1.1059, 1.1052, 1.105, 1.1005, 1.0979, 1.0841, 1.0785, 1.0688, 1.0388, 1.0654, 1.0115, 0.9699, 1.0497, 0.7348, 0.9464, 0.8841, 1.0166, 0.7005, 0.4488, 0.4203, 0.5515, 0.5907, 0.7386, 0.4339, 0.1983, 0.5556, 0.7717, 0.5665, 0.4513, 0.3886, 0.6053, 0.4393, 0.0719, 0.4417, 0.3283, -0.1482, -0.1256, -0.4134, 0.2548, -0.0665, -0.2832, 1.7738, 1.7135, 1.6744, 1.6744, 1.6212, 1.6196, 1.6196, 1.6193, 1.6177, 1.6162, 1.6136, 1.5777, 1.5581, 1.5467, 1.5432, 1.5213, 1.5213, 1.5213, 1.5211, 1.5192, 1.5191, 1.5191, 1.5186, 1.518, 1.5178, 1.5178, 1.5178, 1.5175, 1.5174, 1.5166, 1.4954, 1.4699, 1.4398, 1.3441, 1.4367, 1.4277, 1.1737, 1.4238, 0.8906, 0.9771, 1.2267, 1.2383, 1.2246, 0.9133, 1.1928, 0.6425, 0.7949, 1.1665, 0.6856, 1.2078, 0.204, 1.1483, 1.1867, 0.64, 0.632, 0.1467, 0.6542, 0.5264, -0.0423, -0.083, -0.1194, 0.7733, 0.243, 0.7049, -0.1979, 0.5109, 0.316, 0.4142, 0.0978, 0.4789, 0.1366, 0.0609, 0.1107, -0.2192, -0.5513, 2.0849, 2.0493, 1.9975, 1.9757, 1.9718, 1.9388, 1.9327, 1.9071, 1.8803, 1.8247, 1.8241, 1.7802, 1.7802, 1.7802, 1.7802, 1.7802, 1.7802, 1.7802, 1.7797, 1.7796, 1.7793, 1.779, 1.7786, 1.7769, 1.7753, 1.7751, 1.7751, 1.7749, 1.7725, 1.7721, 1.772, 1.7523, 1.6556, 1.6893, 1.6391, 1.6963, 1.5249, 1.7039, 1.6238, 1.5402, 1.4762, 1.5748, 1.3411, 1.6457, 1.5317, 1.6652, 1.6627, 1.4466, 1.66, 1.2859, 1.1125, 1.2128, 1.0366, 0.9757, 0.979, 1.3224, 0.7079, 0.6094, 0.0136, 0.9301, -0.2062, 0.3979, 0.5751, -0.1824, -0.3666, -0.4514, 0.1122, -0.0405, -0.3778, 0.0811, -0.7054, 0.0054, -0.742, -0.8015, 0.1533, -0.2977, 2.1957, 2.0696, 2.0679, 2.064, 2.0309, 2.0287, 1.9732, 1.9732, 1.9715, 1.9702, 1.9189, 1.8711, 1.8711, 1.8711, 1.8711, 1.8711, 1.8705, 1.8705, 1.8701, 1.8698, 1.8694, 1.8692, 1.8664, 1.865, 1.865, 1.8632, 1.8616, 1.8597, 1.8571, 1.857, 1.8501, 1.8477, 1.8462, 1.8478, 1.7206, 1.546, 1.7587, 1.7554, 1.7525, 1.4799, 1.7466, 1.2775, 1.7328, 1.4543, 1.2216, 0.9543, 1.1046, 0.9644, 0.8749, 0.167, 0.2316, 0.6535, 1.1351, 0.9434, 0.4077, -0.0101, -0.1396, -0.1994, -0.3787, -0.3549, 0.5489, 0.5007, 0.7126, 0.0155, -0.1174, -0.3338, -0.6505, -0.2838, 0.3294, -0.1677]}, \"token.table\": {\"Topic\": [4, 3, 5, 1, 3, 3, 5, 1, 5, 2, 3, 4, 5, 3, 1, 3, 4, 2, 3, 5, 1, 1, 2, 1, 2, 3, 4, 1, 3, 4, 4, 1, 1, 2, 4, 5, 5, 5, 3, 1, 2, 3, 4, 5, 3, 4, 1, 3, 5, 2, 1, 2, 3, 5, 5, 1, 2, 5, 2, 3, 1, 2, 3, 4, 4, 1, 4, 3, 4, 5, 1, 5, 5, 2, 4, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 1, 2, 4, 4, 4, 3, 5, 3, 2, 3, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 5, 1, 2, 3, 4, 5, 5, 1, 1, 2, 4, 5, 1, 4, 5, 1, 2, 4, 5, 3, 5, 2, 3, 4, 1, 3, 1, 2, 3, 2, 5, 1, 2, 4, 5, 2, 4, 5, 1, 4, 2, 4, 4, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 1, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 1, 2, 3, 4, 5, 2, 5, 3, 5, 1, 2, 3, 5, 1, 2, 5, 2, 1, 5, 4, 1, 2, 3, 5, 2, 1, 2, 3, 1, 2, 3, 4, 3, 4, 2, 3, 1, 2, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 4, 1, 2, 4, 5, 2, 5, 1, 2, 3, 4, 5, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 2, 4, 5, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 4, 2, 1, 2, 3, 4, 5, 3, 4, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 3, 2, 5, 5, 3, 4, 1, 2, 3, 1, 2, 3, 4, 4, 3, 5, 1, 5, 3, 1, 2, 3, 4, 4, 2, 1, 2, 3, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 3, 2, 3, 4, 1, 2, 3, 2, 1, 2, 5, 2, 5, 3, 5, 3, 5, 1, 3, 4, 5, 1, 3, 2, 3, 4, 5, 2, 1, 2, 3, 5, 1, 2, 4, 5, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 4, 2, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 5, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 4, 5, 4, 4, 1, 5, 2, 5, 5, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 5, 1, 3, 1, 2, 5, 2, 1, 2, 3, 5, 2, 5, 4, 1, 1, 2, 3, 4, 5, 5, 1, 3, 5, 1, 2, 3, 4, 1, 2, 3, 2, 3, 4, 5, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 5, 2, 3, 4, 1, 5, 3, 5, 5, 1, 3, 1, 4, 3, 1, 3, 5, 1, 2, 3, 4, 5, 1, 4, 5, 2, 1, 2, 4, 5, 2, 1, 2, 3, 4, 5, 1, 3, 2, 4, 5, 5, 1, 3, 3, 4, 1, 5, 1, 3, 4, 3, 1, 2, 3, 5, 2, 3, 3, 1, 2, 5, 2, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 3, 3, 3, 2, 3, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 1, 4, 1, 2, 3, 4, 2, 4, 5, 2, 3, 5, 2, 1, 4, 1, 4, 5, 2, 5], \"Freq\": [0.6927916890840166, 0.6864894069151962, 0.6962489542161044, 0.4321868479275002, 0.5042179892487502, 0.6805302335284913, 0.2722120934113965, 0.8655272307748549, 0.9098689087215809, 0.1568926286509093, 0.5491242002781825, 0.1568926286509093, 0.07844631432545465, 0.686440331018926, 0.9033438537414229, 0.05645899085883893, 0.028229495429419466, 0.3128818046058019, 0.4693227069087028, 0.15644090230290095, 0.8654924469850876, 0.7939273201450388, 0.17642829336556418, 0.35753392996971833, 0.3217805369727465, 0.28602714397577467, 0.03575339299697183, 0.13497395694160794, 0.6748697847080396, 0.13497395694160794, 0.6929053437018633, 0.8655383350068536, 0.7457722407603108, 0.1657271646134024, 0.027621194102233734, 0.05524238820446747, 0.6962449199644581, 0.6963651964736116, 0.6864476336703984, 0.3333382993265312, 0.3888946825476197, 0.11111276644217706, 0.07407517762811804, 0.09259397203514755, 0.12213343853105736, 0.7328006311863441, 0.19170078664073223, 0.5751023599221967, 0.19170078664073223, 0.8777507528317742, 0.7648056153201128, 0.050987041021340856, 0.050987041021340856, 0.050987041021340856, 0.6963652322487441, 0.13484634305093193, 0.8090780583055917, 0.06742317152546597, 0.7139101450825837, 0.23797004836086122, 0.3334174278084498, 0.24248540204250893, 0.3334174278084498, 0.09093202576594085, 0.9041477318495865, 0.8511086460428584, 0.07092572050357153, 0.2489925527496483, 0.6224813818741207, 0.12449627637482415, 0.4523796494794169, 0.4523796494794169, 0.9099702051209595, 0.7757463733263419, 0.6927151807497435, 0.7877429826921815, 0.28465457936526767, 0.5123782428574818, 0.06831709904766424, 0.09108946539688566, 0.04554473269844283, 0.6929223049373415, 0.7328594697184372, 0.13324717631244312, 0.06662358815622156, 0.7945352111768405, 0.20727005508961055, 0.6929223051330377, 0.7797989057677779, 0.9040691599135039, 0.21540807447255084, 0.6462242234176525, 0.7877731955687628, 0.4488977981465561, 0.5130260550246355, 0.8504676945725712, 0.3462150233799837, 0.22086130801826548, 0.2865227779696417, 0.11938449082068404, 0.02387689816413681, 0.261380972922915, 0.39207145938437254, 0.261380972922915, 0.06534524323072875, 0.032672621615364376, 0.7877943239697219, 0.619041929448311, 0.3095209647241555, 0.18783608298275484, 0.1127016497896529, 0.3756721659655097, 0.2441869078775813, 0.09391804149137742, 0.8007993705898824, 0.8654366885576005, 0.8945377062566584, 0.17951033547389947, 0.7180413418955979, 0.800723934915954, 0.5339298431877577, 0.3091172776350176, 0.14050785347046255, 0.6801139848273328, 0.13079115092833324, 0.09155380564983326, 0.09155380564983326, 0.7727663315522186, 0.15455326631044375, 0.12129720990104804, 0.2425944198020961, 0.4851888396041922, 0.845430363852837, 0.10567879548160462, 0.2461647428547524, 0.2461647428547524, 0.4923294857095048, 0.7757055325991212, 0.8008199174554133, 0.06051498677568764, 0.8109008227942143, 0.05648065432397513, 0.07261798413082517, 0.21945382699491578, 0.5486345674872894, 0.10972691349745789, 0.4517560078404119, 0.4517560078404119, 0.15497000957767576, 0.619880038310703, 0.8602662405247655, 0.3293544348763999, 0.2195696232509333, 0.17565569860074665, 0.10978481162546665, 0.1536987362756533, 0.8931835563433667, 0.8451888509991781, 0.12889308194461274, 0.3866792458338383, 0.19333962291691914, 0.12889308194461274, 0.16111635243076594, 0.865433560573021, 0.27938517512217187, 0.4571757411090085, 0.10159460913533522, 0.10159460913533522, 0.07619595685150142, 0.7172625952765815, 0.17931564881914538, 0.8062961243586668, 0.0895884582620741, 0.3998898198072431, 0.30900576985105144, 0.14087027743209699, 0.08179564496057244, 0.07270723996495329, 0.4012264077810379, 0.5246806870982803, 0.030863569829310607, 0.8253268909640595, 0.1103157407443902, 0.6618944444663412, 0.1103157407443902, 0.7757054570068651, 0.2732279581174216, 0.6830698952935541, 0.40879370266275006, 0.11148919163529547, 0.2787229790882387, 0.11148919163529547, 0.07432612775686365, 0.31575045231098986, 0.31575045231098986, 0.31575045231098986, 0.0574091731474527, 0.34553368564343184, 0.5258121303269615, 0.09013922234176483, 0.03755800930906868, 0.8654653606584651, 0.3138462077959283, 0.188307724677557, 0.12553848311837132, 0.3138462077959283, 0.06276924155918566, 0.7757622322841637, 0.8656944669355542, 0.8505268119355683, 0.8008198514790918, 0.5874657899479494, 0.05594912285218566, 0.05594912285218566, 0.2797456142609283, 0.8364633119048145, 0.0995789657029541, 0.05974737942177246, 0.9075669029405798, 0.2996919186940654, 0.699281143619486, 0.8604401285560862, 0.406321348441029, 0.348275441520882, 0.2031606742205145, 0.0290229534600735, 0.9301799019742921, 0.17984064237852662, 0.6594156887212643, 0.11989376158568442, 0.6963298243020501, 0.06963298243020502, 0.10444947364530753, 0.13926596486041004, 0.1556277774912377, 0.7781388874561885, 0.13493957435851808, 0.6746978717925904, 0.7944411968648947, 0.046731835109699686, 0.14019550532909908, 0.6049469815620534, 0.0336081656423363, 0.1008244969270089, 0.21845307667518593, 0.0672163312846726, 0.6963037870847174, 0.5504187996903381, 0.27225015898661886, 0.029592408585502047, 0.09469570747360655, 0.05326633545390368, 0.6929223059734919, 0.07801964291747106, 0.7021767862572396, 0.15603928583494212, 0.07801964291747106, 0.7823579439776946, 0.09779474299721183, 0.4382433533370527, 0.1862534251682474, 0.16434125750139475, 0.12051692216768949, 0.07669258683398422, 0.6963653357894615, 0.7519798881294347, 0.16543557538847564, 0.07519798881294347, 0.45000916547050435, 0.2201131787627467, 0.14674211917516447, 0.09293667547760416, 0.09293667547760416, 0.33959261080227005, 0.3848716255759061, 0.13583704432090804, 0.05433481772836321, 0.08603012806990842, 0.715025000639378, 0.2634302633934551, 0.35194974760886377, 0.6033424244723379, 0.6960895335185333, 0.836464105109672, 0.3323461462994266, 0.395650174165984, 0.14243406269975425, 0.1266080557331149, 0.6037947977365237, 0.09660716763784379, 0.16906254336622661, 0.07245537572838284, 0.07245537572838284, 0.21912057911368316, 0.5478014477842079, 0.10956028955684158, 0.38524470069340444, 0.28893352552005336, 0.32103725057783705, 0.775781586660545, 0.40612954850567523, 0.1624518194022701, 0.14214534197698633, 0.20306477425283762, 0.08122590970113505, 0.7877765290708347, 0.692829427645423, 0.9656897494517718, 0.28391017845521954, 0.26720957972255954, 0.1169041911286198, 0.13360478986127977, 0.20040718479191966, 0.31021888410091447, 0.5428830471766003, 0.15510944205045724, 0.8342405743859458, 0.07584005221690415, 0.782095597081721, 0.09776194963521513, 0.6963535795317034, 0.21446107437697165, 0.643383223130915, 0.24987192027322896, 0.24987192027322896, 0.49974384054645793, 0.6854889917096405, 0.11254296878814993, 0.12277414776889083, 0.08184943184592722, 0.6929058978916952, 0.6864424150240388, 0.6960016463813167, 0.8780507876925271, 0.09977849860142354, 0.6864816972666286, 0.3479360882071573, 0.149115466374496, 0.09941031091633067, 0.39764124366532266, 0.6929223102492513, 0.7757941745442601, 0.1758744431737589, 0.5979731067907802, 0.10552466590425533, 0.14069955453900712, 0.6929223069315553, 0.3954149725089823, 0.21088798533812386, 0.32951247709081855, 0.03954149725089823, 0.03954149725089823, 0.8281315219309924, 0.04687536916590523, 0.04687536916590523, 0.06250049222120697, 0.2489507179774617, 0.21338632969496718, 0.28451510625995624, 0.21338632969496718, 0.6864458004846175, 0.8542730259965371, 0.11649177627225506, 0.6929079591185621, 0.8253876233334513, 0.8365428297809537, 0.6864450969644278, 0.8365537639320902, 0.8253177173237254, 0.8020902887710729, 0.13368171479517882, 0.21454116105641866, 0.6436234831692559, 0.6864817036355989, 0.6963653269652463, 0.21546954694379367, 0.646408640831381, 0.729342875405639, 0.18821751623371327, 0.02352718952921416, 0.04705437905842832, 0.17717737478383583, 0.7087094991353433, 0.2566444077468343, 0.21387033978902856, 0.21387033978902856, 0.29941847570464, 0.7757471593971338, 0.30426680010299884, 0.3651201601235986, 0.030426680010299884, 0.2738401200926989, 0.3289602877494069, 0.16448014387470344, 0.1096534292498023, 0.383787002374308, 0.20578195077212622, 0.48015788513496116, 0.1371879671814175, 0.20578195077212622, 0.2949464461220416, 0.0737366115305104, 0.1474732230610208, 0.44241966918306236, 0.2371074979152026, 0.2802179520816031, 0.2802179520816031, 0.08622090833280095, 0.10777613541600119, 0.6864791217701575, 0.21814804276881622, 0.36358007128136033, 0.43629608553763244, 0.21456329161263127, 0.6436898748378939, 0.6894462103746287, 0.158233556479423, 0.04520958756554943, 0.1017215720224862, 0.16784278980044848, 0.5454890668514576, 0.12588209235033634, 0.04196069745011212, 0.12588209235033634, 0.4765050111101197, 0.2486113101444103, 0.08287043671480343, 0.18645848260830772, 0.2619740182695942, 0.10478960730783769, 0.31436882192351306, 0.31436882192351306, 0.8202963580912067, 0.11718519401302953, 0.7955194886476374, 0.08839105429418194, 0.5237298652149424, 0.24316029456408036, 0.22445565652068958, 0.5122648770652659, 0.06830198360870211, 0.06830198360870211, 0.06830198360870211, 0.27320793443480845, 0.6929223089195594, 0.6927882120196844, 0.15522354697357468, 0.6208941878942987, 0.13711790276384056, 0.6855895138192029, 0.6963069945533978, 0.6929222238036515, 0.5837797014114672, 0.307252474427088, 0.09217574232812639, 0.0307252474427088, 0.462086843563502, 0.2380447375933192, 0.1120210529850914, 0.16803157947763708, 0.02800526324627285, 0.9586758011129645, 0.4259431332899349, 0.4259431332899349, 0.10648578332248372, 0.20083800345169606, 0.23431100402697874, 0.03347300057528268, 0.5355680092045229, 0.7028878291854498, 0.20673171446630875, 0.0826926857865235, 0.4494299217841496, 0.1685362206690561, 0.18582198689152338, 0.073464506445486, 0.12532180511288787, 0.6963653475007802, 0.9136855565185125, 0.05076030869547291, 0.24906897666005634, 0.6566363930128758, 0.06792790272546992, 0.9076052312404922, 0.7413828353956452, 0.11233073263570383, 0.11233073263570383, 0.022466146527140764, 0.7217316512219427, 0.18043291280548568, 0.8834613266275341, 0.9164043212655967, 0.3614965167739574, 0.08607059923189461, 0.37010357669714683, 0.111891779001463, 0.07746353930870514, 0.6963310453117185, 0.13629070888085562, 0.13629070888085562, 0.5451628355234225, 0.38102247488719604, 0.36788376885660307, 0.1576644723671156, 0.0788322361835578, 0.8253251149882782, 0.7757456687679434, 0.6864312629218497, 0.8776580595412105, 0.787787555781676, 0.6929080644967772, 0.9100147187403544, 0.6215243884861374, 0.1621367969963837, 0.21618239599517824, 0.6929350630692808, 0.7962329951995311, 0.3144333820154648, 0.18341947284235446, 0.1572166910077324, 0.0786083455038662, 0.26202781834622063, 0.7758708118859386, 0.59705289290069, 0.32149001925421766, 0.09185429121549077, 0.6962772270165181, 0.45678463879705866, 0.3978446854038898, 0.13261489513462993, 0.1801524501123612, 0.7206098004494448, 0.6864678635742519, 0.6963202065715904, 0.6963344276168221, 0.7708457198232532, 0.1927114299558133, 0.18292901376407295, 0.7317160550562918, 0.7878009191276634, 0.8253549376467093, 0.6805933741704363, 0.27223734966817453, 0.4174213360912538, 0.23030142680896762, 0.17272607010672572, 0.08636303505336286, 0.08636303505336286, 0.23575989204471862, 0.5501064147710101, 0.15717326136314574, 0.8364466391654923, 0.21310996075234048, 0.17048796860187238, 0.2557319529028086, 0.38359792935421283, 0.8365199918697263, 0.5345555071393014, 0.07559370808030524, 0.17278561846926915, 0.08099325865746991, 0.13498876442911653, 0.8501367824363407, 0.07084473186969506, 0.1586169085598997, 0.3172338171197994, 0.47585072567969916, 0.6960292517959343, 0.1531003802105731, 0.7655019010528654, 0.6864816886190597, 0.6928089980170352, 0.21366986990709236, 0.6410096097212771, 0.3839245078627738, 0.1096927165322211, 0.4936172243949949, 0.7877945185540242, 0.6768195608289344, 0.13536391216578686, 0.09024260811052458, 0.11280326013815571, 0.7821247207995767, 0.19553118019989418, 0.6863946092372981, 0.4641380775942881, 0.44203626437551247, 0.06630543965632686, 0.213577443728518, 0.6407323311855541, 0.4181866366461623, 0.2787910910974415, 0.13939554554872075, 0.1792228442769267, 0.1679075852576043, 0.13432606820608345, 0.20148910230912517, 0.3358151705152086, 0.13432606820608345, 0.35829543399339664, 0.15675425237211105, 0.2463281108704602, 0.13436078774752375, 0.08957385849834916, 0.325435857600236, 0.39552973462182534, 0.1251676375385523, 0.05006705501542093, 0.10514081553238394, 0.692892360159191, 0.7820378466787814, 0.19550946166969535, 0.6864403319571244, 0.6864418781016299, 0.24057317529883906, 0.7217195258965172, 0.21994014389362945, 0.10997007194681473, 0.16495510792022208, 0.4398802877872589, 0.05498503597340736, 0.23658490186510842, 0.6308930716402891, 0.07886163395503613, 0.2998706831146889, 0.4446358404804008, 0.051701841916325667, 0.11374405221591648, 0.0930633154493862, 0.6963527597536942, 0.39549657656084686, 0.21295969507122525, 0.06084562716320721, 0.12169125432641442, 0.21295969507122525, 0.7973693538417871, 0.10400469832718962, 0.10400469832718962, 0.2568658210701151, 0.06421645526752877, 0.5137316421402301, 0.12843291053505754, 0.21284746959953313, 0.6385424087985994, 0.4028771979376592, 0.4379099977583252, 0.08758199955166504, 0.07006559964133204, 0.17078736680032158, 0.08539368340016079, 0.6831494672012863, 0.8776780050743519, 0.10112129664333151, 0.8089703731466521, 0.7756625112784861, 0.3570818595219558, 0.5356227892829337, 0.8254353818716684, 0.6927916890840166, 0.6963259515355242, 0.7243414733050186, 0.2173024419915056], \"Term\": [\"34aa\", \"36b\", \"actual\", \"actually\", \"actually\", \"adorable\", \"adorable\", \"adore\", \"amaze\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"apparent\", \"arm\", \"arm\", \"arm\", \"arrive\", \"arrive\", \"arrive\", \"athletic\", \"bad\", \"bad\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautifully\", \"beautifully\", \"beautifully\", \"beauty\", \"believe\", \"big\", \"big\", \"big\", \"big\", \"bill\", \"billowy\", \"birthday\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"blazer\", \"blazer\", \"blouse\", \"blouse\", \"blouse\", \"bodice\", \"body\", \"body\", \"body\", \"body\", \"boho\", \"boot\", \"boot\", \"boot\", \"booty\", \"booty\", \"bottom\", \"bottom\", \"bottom\", \"bottom\", \"bow\", \"boxy\", \"boxy\", \"bra\", \"bra\", \"bra\", \"brand\", \"brand\", \"broad\", \"brunch\", \"bummer\", \"bunch\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"camisole\", \"cardigan\", \"cardigan\", \"cardigan\", \"casual\", \"casual\", \"cause\", \"cheap\", \"chested\", \"cling\", \"cling\", \"clothing\", \"coat\", \"coat\", \"collar\", \"color\", \"color\", \"color\", \"color\", \"color\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comment\", \"compare\", \"compare\", \"could\", \"could\", \"could\", \"could\", \"could\", \"crease\", \"crop\", \"cuff\", \"cup\", \"cup\", \"currently\", \"cut\", \"cut\", \"cut\", \"cute\", \"cute\", \"cute\", \"cute\", \"deal\", \"deal\", \"delicate\", \"delicate\", \"delicate\", \"denim\", \"denim\", \"design\", \"design\", \"design\", \"dinner\", \"dirty\", \"dress\", \"dress\", \"dress\", \"dress\", \"dry\", \"dry\", \"dry\", \"either\", \"either\", \"elastic\", \"elastic\", \"elegant\", \"even\", \"even\", \"even\", \"even\", \"even\", \"excite\", \"extremely\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"far\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feminine\", \"feminine\", \"figure\", \"figure\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"flattering\", \"flattering\", \"flattering\", \"flower\", \"full\", \"full\", \"full\", \"fully\", \"gold\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"great\", \"great\", \"great\", \"great\", \"height\", \"high\", \"high\", \"high\", \"high\", \"high\", \"holly\", \"idea\", \"interesting\", \"itch\", \"jacket\", \"jacket\", \"jacket\", \"jacket\", \"jean\", \"jean\", \"jean\", \"jogger\", \"jumpsuit\", \"jumpsuit\", \"label\", \"large\", \"large\", \"large\", \"large\", \"last\", \"layer\", \"layer\", \"layer\", \"lb\", \"lb\", \"lb\", \"lb\", \"least\", \"least\", \"leave\", \"leave\", \"leg\", \"leg\", \"leg\", \"length\", \"length\", \"length\", \"length\", \"length\", \"life\", \"like\", \"like\", \"like\", \"like\", \"like\", \"liking\", \"line\", \"line\", \"line\", \"line\", \"lining\", \"lining\", \"little\", \"little\", \"little\", \"little\", \"little\", \"location\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lovely\", \"lovely\", \"low\", \"low\", \"lucky\", \"match\", \"material\", \"material\", \"material\", \"material\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"mind\", \"mind\", \"mind\", \"model\", \"model\", \"model\", \"modern\", \"much\", \"much\", \"much\", \"much\", \"much\", \"natori\", \"necessary\", \"neck\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"normal\", \"normal\", \"normal\", \"normally\", \"normally\", \"notice\", \"notice\", \"noticeable\", \"nude\", \"nude\", \"orange\", \"orange\", \"orange\", \"order\", \"order\", \"order\", \"order\", \"outstanding\", \"overwhelm\", \"pale\", \"pant\", \"pant\", \"panty\", \"part\", \"part\", \"part\", \"part\", \"partially\", \"particular\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"peplum\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"petite\", \"petite\", \"petite\", \"petite\", \"photo\", \"photo\", \"photo\", \"photo\", \"photograph\", \"piece\", \"piece\", \"pin\", \"plaid\", \"plan\", \"pleasant\", \"pleat\", \"plum\", \"point\", \"point\", \"polka\", \"polka\", \"portland\", \"postmark\", \"pregnant\", \"pregnant\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"previous\", \"previous\", \"price\", \"price\", \"price\", \"price\", \"pricey\", \"print\", \"print\", \"print\", \"print\", \"probably\", \"probably\", \"probably\", \"probably\", \"problem\", \"problem\", \"problem\", \"problem\", \"pull\", \"pull\", \"pull\", \"pull\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"push\", \"rather\", \"rather\", \"rather\", \"rayon\", \"rayon\", \"really\", \"really\", \"really\", \"really\", \"receive\", \"receive\", \"receive\", \"receive\", \"receive\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"reviewer\", \"reviewer\", \"reviewer\", \"reviewer\", \"roll\", \"roll\", \"roomy\", \"roomy\", \"run\", \"run\", \"run\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"salmon\", \"save\", \"section\", \"section\", \"several\", \"several\", \"shame\", \"shed\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"short\", \"short\", \"short\", \"short\", \"short\", \"shoulder\", \"show\", \"show\", \"show\", \"side\", \"side\", \"side\", \"side\", \"since\", \"since\", \"since\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skier\", \"skinny\", \"skinny\", \"skirt\", \"skirt\", \"skirt\", \"skort\", \"sleeve\", \"sleeve\", \"sleeve\", \"sleeve\", \"slip\", \"slip\", \"slit\", \"sloppy\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smock\", \"snug\", \"snug\", \"snug\", \"soft\", \"soft\", \"soft\", \"soft\", \"sooo\", \"specific\", \"stand\", \"staple\", \"stay\", \"stet\", \"stiff\", \"still\", \"still\", \"still\", \"stitch\", \"stomach\", \"style\", \"style\", \"style\", \"style\", \"style\", \"styling\", \"super\", \"super\", \"super\", \"surprisingly\", \"sweater\", \"sweater\", \"sweater\", \"swing\", \"swing\", \"swingy\", \"tablecloth\", \"talk\", \"tall\", \"tall\", \"tank\", \"tank\", \"taupe\", \"teal\", \"tent\", \"tent\", \"think\", \"think\", \"think\", \"think\", \"think\", \"tie\", \"tie\", \"tie\", \"tights\", \"time\", \"time\", \"time\", \"time\", \"timeless\", \"top\", \"top\", \"top\", \"top\", \"top\", \"torso\", \"torso\", \"touch\", \"touch\", \"touch\", \"trouser\", \"tt\", \"tt\", \"tulle\", \"tummy\", \"typical\", \"typical\", \"underneath\", \"underneath\", \"underneath\", \"unlike\", \"usually\", \"usually\", \"usually\", \"usually\", \"vibrant\", \"vibrant\", \"vintage\", \"waist\", \"waist\", \"waist\", \"waistband\", \"waistband\", \"want\", \"want\", \"want\", \"want\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wearable\", \"weather\", \"weather\", \"weave\", \"wedge\", \"week\", \"week\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weird\", \"weird\", \"weird\", \"well\", \"well\", \"well\", \"well\", \"well\", \"whimsical\", \"white\", \"white\", \"white\", \"white\", \"white\", \"wide\", \"wide\", \"wide\", \"winter\", \"winter\", \"winter\", \"winter\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"worth\", \"wrap\", \"wrinkle\", \"wrinkle\", \"wrong\", \"xl\", \"xl\", \"xsp\", \"xspetite\", \"yikes\", \"zipper\", \"zipper\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 3, 2, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1351398900899381286176575023\", ldavis_el1351398900899381286176575023_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1351398900899381286176575023\", ldavis_el1351398900899381286176575023_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1351398900899381286176575023\", ldavis_el1351398900899381286176575023_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "COPh__Y80wYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "gBra8Dma0wYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9450b21b-1e59-4a28-b62e-8711d3f26a00",
        "id": "F7qOlXNU0wYw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4\n",
              "Doc_0  0.96000  0.00978  0.00995  0.01028  0.01000\n",
              "Doc_1  0.42946  0.00821  0.00827  0.54601  0.00805\n",
              "Doc_2  0.96965  0.00728  0.00775  0.00768  0.00764\n",
              "Doc_3  0.01344  0.01282  0.01338  0.28124  0.67912\n",
              "Doc_4  0.01184  0.01150  0.95312  0.01189  0.01165"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6c94ceb-5dd9-4251-a0ec-b15dadb8ad63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.96000</td>\n",
              "      <td>0.00978</td>\n",
              "      <td>0.00995</td>\n",
              "      <td>0.01028</td>\n",
              "      <td>0.01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.42946</td>\n",
              "      <td>0.00821</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54601</td>\n",
              "      <td>0.00805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.96965</td>\n",
              "      <td>0.00728</td>\n",
              "      <td>0.00775</td>\n",
              "      <td>0.00768</td>\n",
              "      <td>0.00764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.01344</td>\n",
              "      <td>0.01282</td>\n",
              "      <td>0.01338</td>\n",
              "      <td>0.28124</td>\n",
              "      <td>0.67912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.01184</td>\n",
              "      <td>0.01150</td>\n",
              "      <td>0.95312</td>\n",
              "      <td>0.01189</td>\n",
              "      <td>0.01165</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6c94ceb-5dd9-4251-a0ec-b15dadb8ad63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6c94ceb-5dd9-4251-a0ec-b15dadb8ad63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6c94ceb-5dd9-4251-a0ec-b15dadb8ad63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "T0KxiMWW0wYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4a367c-aa6f-4377-fe88-41e0a8def1fb",
        "id": "xx5mOVKS0wYw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  dominant_topic\n",
              "Doc_0  0.96000  0.00978  0.00995  0.01028  0.01000               0\n",
              "Doc_1  0.42946  0.00821  0.00827  0.54601  0.00805               3\n",
              "Doc_2  0.96965  0.00728  0.00775  0.00768  0.00764               0\n",
              "Doc_3  0.01344  0.01282  0.01338  0.28124  0.67912               4\n",
              "Doc_4  0.01184  0.01150  0.95312  0.01189  0.01165               2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4298e9e-ff22-439b-8796-40ae60f0328b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "      <th>dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.96000</td>\n",
              "      <td>0.00978</td>\n",
              "      <td>0.00995</td>\n",
              "      <td>0.01028</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.42946</td>\n",
              "      <td>0.00821</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54601</td>\n",
              "      <td>0.00805</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.96965</td>\n",
              "      <td>0.00728</td>\n",
              "      <td>0.00775</td>\n",
              "      <td>0.00768</td>\n",
              "      <td>0.00764</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.01344</td>\n",
              "      <td>0.01282</td>\n",
              "      <td>0.01338</td>\n",
              "      <td>0.28124</td>\n",
              "      <td>0.67912</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.01184</td>\n",
              "      <td>0.01150</td>\n",
              "      <td>0.95312</td>\n",
              "      <td>0.01189</td>\n",
              "      <td>0.01165</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4298e9e-ff22-439b-8796-40ae60f0328b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4298e9e-ff22-439b-8796-40ae60f0328b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4298e9e-ff22-439b-8796-40ae60f0328b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "iw1ofuid0wYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfd230a-6bf6-41bc-a25c-2999040320fb",
        "id": "upx0YuU90wYw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "YfP4t2qq0wYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "Js1g4xNR0wYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "Ji5An-jD0wYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f6a8f5-6098-43fb-a245-7fb9fa342d9a",
        "id": "OoU__cJ10wYx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score for the model:  -2.05573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "eI4naMh20wYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f876fef6-e3a5-49d7-c8fe-2c25df39c636",
        "id": "e6h0REoI0wYx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score by topic (higher values are better):  [-1.81083 -2.30274 -1.94405 -2.01139 -2.20964]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "ut6dek020wYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294bbee2-27a8-4c30-d716-ae3d73aa4516",
        "id": "75MTnUib0wYx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log-Likelihood (higher values are better):  -79538.17305477532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "sstmysxP0wYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836f90f8-7b4b-47d0-ca99-4a77e70dc195",
        "id": "iRiLEln80wYx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (lower values are better):  583.2747027660083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "JKpcrhZC0wYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GenZ_dress**"
      ],
      "metadata": {
        "id": "q_LJ34hc0ua6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_GenZ_dress)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "OGBhwqrt0ua7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "KF8OTq0a0ua7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "oj5-uLMv0ua7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919acea1-ab4c-4785-eead-b2830d3eec30",
        "id": "DJl4Gblo0ua7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "dress look fit size like love top color wear small\n",
            "Topic 1:\n",
            "wear skirt size fit love look dress soft fall great\n",
            "Topic 2:\n",
            "dress great love fit size perfect wear color order large\n",
            "Topic 3:\n",
            "great fit top look quality wear shirt blouse material buy\n",
            "Topic 4:\n",
            "size dress like love fit look fabric even great well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "0pizxaAJ0ua7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c708cf84-fc97-4a54-aeb1-73270662a7c4",
        "id": "Q-gktgnD0ua7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "34b         0.000884  0.000149  0.000150  0.000213  0.000248\n",
              "34c         0.000612  0.000149  0.000150  0.000213  0.000248\n",
              "34d         0.000071  0.000745  0.000150  0.001052  0.001243\n",
              "36c         0.000339  0.000149  0.000150  0.000213  0.001245\n",
              "4p          0.000612  0.000149  0.000150  0.000213  0.000248\n",
              "able        0.000927  0.000149  0.001249  0.001063  0.003236\n",
              "absolute    0.000068  0.000745  0.000167  0.001039  0.000248\n",
              "absolutely  0.001932  0.001334  0.000837  0.002778  0.000248\n",
              "across      0.000611  0.000744  0.002551  0.000217  0.000248\n",
              "actually    0.001574  0.002089  0.000873  0.000217  0.000248"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6774fb4f-6b11-4630-99aa-1983b29dded2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34b</th>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34c</th>\n",
              "      <td>0.000612</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34d</th>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000745</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.001052</td>\n",
              "      <td>0.001243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36c</th>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.001245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4p</th>\n",
              "      <td>0.000612</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>able</th>\n",
              "      <td>0.000927</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>0.001063</td>\n",
              "      <td>0.003236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolute</th>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.000745</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.001039</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>0.001932</td>\n",
              "      <td>0.001334</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>0.002778</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>across</th>\n",
              "      <td>0.000611</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>0.002551</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>actually</th>\n",
              "      <td>0.001574</td>\n",
              "      <td>0.002089</td>\n",
              "      <td>0.000873</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6774fb4f-6b11-4630-99aa-1983b29dded2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6774fb4f-6b11-4630-99aa-1983b29dded2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6774fb4f-6b11-4630-99aa-1983b29dded2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "JDGEG9FP0ua7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f706ef1a-2593-442c-a889-db2cc51d2e37",
        "id": "hII8cjea0ua7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "dress  0.033344  0.010553  0.027919  0.006800  0.019327\n",
              "look   0.022567  0.012627  0.007476  0.016579  0.011093\n",
              "fit    0.020077  0.019382  0.015376  0.017858  0.012228\n",
              "size   0.019429  0.019597  0.014300  0.002418  0.024102\n",
              "like   0.017396  0.007289  0.005911  0.005471  0.015688\n",
              "love   0.017011  0.016835  0.017832  0.009648  0.013316\n",
              "top    0.016652  0.007307  0.002288  0.017349  0.005544\n",
              "color  0.014190  0.006704  0.011964  0.000215  0.004622\n",
              "wear   0.011739  0.027110  0.013131  0.013954  0.004287\n",
              "small  0.010917  0.005789  0.003862  0.007112  0.004584"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e1ec572-577d-467d-867b-777d830d5cd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dress</th>\n",
              "      <td>0.033344</td>\n",
              "      <td>0.010553</td>\n",
              "      <td>0.027919</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.019327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>look</th>\n",
              "      <td>0.022567</td>\n",
              "      <td>0.012627</td>\n",
              "      <td>0.007476</td>\n",
              "      <td>0.016579</td>\n",
              "      <td>0.011093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fit</th>\n",
              "      <td>0.020077</td>\n",
              "      <td>0.019382</td>\n",
              "      <td>0.015376</td>\n",
              "      <td>0.017858</td>\n",
              "      <td>0.012228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>size</th>\n",
              "      <td>0.019429</td>\n",
              "      <td>0.019597</td>\n",
              "      <td>0.014300</td>\n",
              "      <td>0.002418</td>\n",
              "      <td>0.024102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0.017396</td>\n",
              "      <td>0.007289</td>\n",
              "      <td>0.005911</td>\n",
              "      <td>0.005471</td>\n",
              "      <td>0.015688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>0.017011</td>\n",
              "      <td>0.016835</td>\n",
              "      <td>0.017832</td>\n",
              "      <td>0.009648</td>\n",
              "      <td>0.013316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.007307</td>\n",
              "      <td>0.002288</td>\n",
              "      <td>0.017349</td>\n",
              "      <td>0.005544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color</th>\n",
              "      <td>0.014190</td>\n",
              "      <td>0.006704</td>\n",
              "      <td>0.011964</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.004622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wear</th>\n",
              "      <td>0.011739</td>\n",
              "      <td>0.027110</td>\n",
              "      <td>0.013131</td>\n",
              "      <td>0.013954</td>\n",
              "      <td>0.004287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>small</th>\n",
              "      <td>0.010917</td>\n",
              "      <td>0.005789</td>\n",
              "      <td>0.003862</td>\n",
              "      <td>0.007112</td>\n",
              "      <td>0.004584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e1ec572-577d-467d-867b-777d830d5cd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e1ec572-577d-467d-867b-777d830d5cd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e1ec572-577d-467d-867b-777d830d5cd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "98ae71d1-982c-4440-ec23-37620261ff0a",
        "id": "y0tg2qgB0ua8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
              "topic                                                    \n",
              "0      150.222153  -72.269554       1        1  42.008143\n",
              "1       51.163364 -159.968018       2        1  17.980008\n",
              "2      -73.144554   21.523815       3        1  17.898816\n",
              "3      -66.410133 -110.606438       4        1  12.028229\n",
              "4       54.417324   12.443444       5        1  10.084805, topic_info=       Term        Freq       Total Category  logprob  loglift\n",
              "693   skirt   37.000000   37.000000  Default  30.0000  30.0000\n",
              "687    size  134.000000  134.000000  Default  29.0000  29.0000\n",
              "312   great   88.000000   88.000000  Default  28.0000  28.0000\n",
              "936    wear  113.000000  113.000000  Default  27.0000  27.0000\n",
              "663   shirt   40.000000   40.000000  Default  26.0000  26.0000\n",
              "..      ...         ...         ...      ...      ...      ...\n",
              "408  little    4.191633   48.041246   Topic5  -5.2541  -0.1448\n",
              "839     top    4.446609   90.381742   Topic5  -5.1950  -0.7178\n",
              "478   order    4.146136   61.442373   Topic5  -5.2650  -0.4018\n",
              "631     run    3.870876   50.078402   Topic5  -5.3337  -0.2660\n",
              "757   store    3.753274   28.367440   Topic5  -5.3645   0.2715\n",
              "\n",
              "[388 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "11        2  0.282824  addition\n",
              "11        4  0.565647  addition\n",
              "14        1  0.317967     adore\n",
              "14        3  0.635935     adore\n",
              "16        5  0.754838    afraid\n",
              "...     ...       ...       ...\n",
              "980       4  0.534742     wrist\n",
              "982       5  0.539841   writing\n",
              "988       4  0.698650        xx\n",
              "988       5  0.232883        xx\n",
              "995       4  0.534742        yo\n",
              "\n",
              "[675 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1351398900899349284271169948\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1351398900899349284271169948_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [42.00814309873586, 17.980008039963298, 17.898815626234637, 12.028228635554063, 10.08480459951215]}, \"tinfo\": {\"Term\": [\"skirt\", \"size\", \"great\", \"wear\", \"shirt\", \"black\", \"perfect\", \"blouse\", \"quality\", \"material\", \"top\", \"dress\", \"fall\", \"like\", \"wash\", \"sleeve\", \"even\", \"summer\", \"buy\", \"petite\", \"fit\", \"worth\", \"sweater\", \"tee\", \"hip\", \"cute\", \"jean\", \"love\", \"color\", \"look\", \"part\", \"place\", \"someone\", \"feminine\", \"tall\", \"skin\", \"hope\", \"curvy\", \"turtleneck\", \"detergent\", \"frumpy\", \"hug\", \"surprise\", \"star\", \"vibrant\", \"cross\", \"weird\", \"plan\", \"amount\", \"necklace\", \"expect\", \"send\", \"print\", \"torso\", \"either\", \"lb\", \"wide\", \"ribbon\", \"clothing\", \"sad\", \"pretty\", \"model\", \"bra\", \"short\", \"chest\", \"without\", \"different\", \"cut\", \"low\", \"dress\", \"like\", \"top\", \"shape\", \"bust\", \"look\", \"color\", \"small\", \"really\", \"size\", \"could\", \"fit\", \"good\", \"love\", \"medium\", \"much\", \"design\", \"run\", \"order\", \"beautiful\", \"shirt\", \"well\", \"big\", \"wear\", \"little\", \"long\", \"material\", \"perfect\", \"think\", \"fabric\", \"great\", \"wool\", \"scarf\", \"skirt\", \"hd\", \"inner\", \"gray\", \"often\", \"flat\", \"cozy\", \"paris\", \"remind\", \"sheath\", \"jump\", \"elevate\", \"swingy\", \"outfit\", \"slack\", \"occasion\", \"cashmere\", \"crotch\", \"layered\", \"outside\", \"already\", \"walk\", \"wasnt\", \"stand\", \"point\", \"bummer\", \"money\", \"generally\", \"photo\", \"versatile\", \"comfy\", \"pocket\", \"fall\", \"twice\", \"pant\", \"summer\", \"wear\", \"heel\", \"highly\", \"though\", \"usual\", \"regret\", \"soft\", \"nothing\", \"retailer\", \"realize\", \"structure\", \"sweater\", \"always\", \"nice\", \"size\", \"fit\", \"much\", \"love\", \"jean\", \"many\", \"compliment\", \"show\", \"look\", \"great\", \"dress\", \"order\", \"top\", \"like\", \"color\", \"bit\", \"fabric\", \"large\", \"small\", \"long\", \"little\", \"maeve\", \"currently\", \"suggest\", \"state\", \"town\", \"best\", \"cool\", \"emerson\", \"press\", \"bend\", \"previously\", \"gauze\", \"resemble\", \"gathering\", \"thankfully\", \"strap\", \"name\", \"bc\", \"flowing\", \"sock\", \"road\", \"denim\", \"build\", \"excellent\", \"delicate\", \"swing\", \"issue\", \"purple\", \"crazy\", \"adore\", \"layer\", \"boot\", \"tank\", \"black\", \"glad\", \"great\", \"legging\", \"slip\", \"jacket\", \"perfect\", \"comfortable\", \"easy\", \"fall\", \"super\", \"large\", \"dress\", \"order\", \"length\", \"love\", \"color\", \"fabric\", \"summer\", \"fit\", \"wear\", \"size\", \"buy\", \"bit\", \"really\", \"cute\", \"run\", \"medium\", \"little\", \"well\", \"sweater\", \"feel\", \"look\", \"like\", \"jersey\", \"dressy\", \"blouse\", \"knot\", \"hte\", \"poncho\", \"old\", \"jogger\", \"draped\", \"poor\", \"hand\", \"pic\", \"skim\", \"striped\", \"airy\", \"volume\", \"tucked\", \"reality\", \"boxy\", \"xx\", \"last\", \"thicker\", \"visual\", \"waste\", \"wrinkling\", \"wrist\", \"ratio\", \"sleek\", \"yo\", \"water\", \"wash\", \"rise\", \"addition\", \"recently\", \"brown\", \"hang\", \"quality\", \"unflattering\", \"shirt\", \"although\", \"material\", \"flower\", \"black\", \"sleeve\", \"great\", \"top\", \"buy\", \"day\", \"high\", \"casual\", \"perfect\", \"fit\", \"look\", \"petite\", \"cute\", \"wear\", \"return\", \"around\", \"jean\", \"love\", \"style\", \"small\", \"comfortable\", \"feel\", \"bit\", \"purchase\", \"dress\", \"work\", \"like\", \"large\", \"ruffle\", \"romper\", \"rock\", \"scratchy\", \"afraid\", \"mostly\", \"catch\", \"collar\", \"tee\", \"racier\", \"shelf\", \"supportive\", \"weddi\", \"smock\", \"strangely\", \"straighten\", \"shel\", \"shopper\", \"princess\", \"shaped\", \"superb\", \"specifically\", \"writing\", \"shopping\", \"streak\", \"register\", \"upcoming\", \"realistically\", \"stud\", \"worth\", \"lie\", \"anything\", \"trend\", \"please\", \"vest\", \"aqua\", \"bag\", \"shift\", \"femininity\", \"etc\", \"dye\", \"cheap\", \"horrible\", \"put\", \"lining\", \"lovely\", \"eye\", \"remove\", \"hip\", \"due\", \"probably\", \"size\", \"even\", \"like\", \"button\", \"dress\", \"however\", \"might\", \"complaint\", \"petite\", \"take\", \"slip\", \"love\", \"fabric\", \"review\", \"price\", \"fit\", \"look\", \"well\", \"bit\", \"great\", \"think\", \"cute\", \"little\", \"top\", \"order\", \"run\", \"store\"], \"Freq\": [37.0, 134.0, 88.0, 113.0, 40.0, 30.0, 53.0, 16.0, 37.0, 38.0, 90.0, 188.0, 24.0, 94.0, 13.0, 24.0, 30.0, 19.0, 47.0, 28.0, 143.0, 11.0, 28.0, 9.0, 14.0, 42.0, 35.0, 126.0, 77.0, 128.0, 11.076729623440686, 8.407540103930486, 8.39596096976811, 7.485031256018752, 5.676833504202373, 5.663512084750045, 4.769854004906513, 4.761092118895703, 4.758441907327415, 3.8637383131478558, 3.863710602488552, 3.863616585785055, 3.860104974311108, 3.8596327690331504, 3.859638669688384, 3.8583214583039407, 3.8572974495569694, 3.855721350813923, 3.8554749025604385, 3.8541499774973387, 11.123194236803037, 3.8372068328519044, 10.17671160185666, 6.591208314492644, 6.5894384879601855, 9.291619291673754, 9.311784910947866, 2.954619471682326, 2.954610668441801, 2.9546081460818225, 28.82269665642745, 19.46471157982073, 15.674657298998836, 31.89560045852462, 15.982633871857024, 15.122284898093248, 13.317302592725603, 13.163156566171974, 8.36774891348714, 111.40083243674486, 58.11923921279432, 55.63236848005353, 15.226085861668842, 10.037599926499068, 75.39560053133921, 47.40743289674526, 36.47376581066374, 28.99913760845751, 64.9118405833006, 19.43895970983895, 67.07472741605052, 18.147833938162986, 56.83377726242728, 15.626419983591145, 20.084254835339973, 20.633620802915047, 26.111552024801114, 30.126732537039985, 21.300840429747463, 21.78292100610801, 26.048537159777794, 19.20985028239455, 39.22020582001512, 22.43274404999816, 18.243173054245734, 19.409843074639298, 22.02886633526507, 18.343581967566887, 18.8200446119755, 19.169093114384985, 5.321684189298924, 3.616733887338146, 30.112022776281506, 2.769016679426663, 2.7690151553286753, 2.7667321276429093, 2.7521981195746594, 5.325840078088383, 6.099014702873085, 1.9170015466524506, 1.9169999011834937, 1.9169986020093142, 1.9169892874684766, 1.9169849953370686, 1.9169780821038098, 1.9169667997722004, 1.9162790414199395, 1.913055580610885, 1.912528205901068, 1.9115003725370217, 1.909493876414378, 1.9068465280401643, 6.566581425198863, 1.9020458833528235, 1.9013526359576174, 1.8940209491686577, 1.894380433993564, 1.8936162129951808, 1.8936003175249343, 3.63002283311326, 7.019391315391128, 5.178595493439967, 7.983775544673527, 7.79952327686131, 13.213213331361457, 3.421087568259607, 11.35762705891042, 10.055460450507928, 38.766280576717364, 4.481301961830281, 3.601030245084835, 7.844877914198111, 8.035350443116934, 2.769368212295408, 14.15862053589558, 2.766418403708204, 9.602757335910676, 2.7528388059463214, 2.7673645890022054, 10.6597007983633, 4.468965211575072, 12.113699635254582, 28.0224654812238, 27.715452069710683, 10.808165616554879, 24.072800668457216, 10.654506561399874, 7.139441156505563, 5.657758104458016, 6.771079835364706, 18.056160060141472, 13.07416077064999, 15.089747752819923, 9.410327414468869, 10.449035352137223, 10.422802583019445, 9.586815116338476, 8.325719602403264, 8.314202710213012, 8.158869271139082, 8.277716413099197, 7.511340009178495, 7.54473180861151, 3.629018854787729, 2.7752540657686486, 2.7728842063184023, 2.77180701334658, 2.762768220334553, 7.903967395256292, 4.479244200751993, 1.921350760664034, 1.921348049430412, 1.9213466454943535, 1.921346121397376, 1.921343665572074, 1.9213393895962483, 1.9213390000607988, 1.9213203771557055, 1.9185500643483757, 1.9185226243908458, 1.9163687755044125, 1.913954601520868, 1.9131576242116592, 1.9018787101930332, 5.329389237405465, 3.6490323093416652, 2.77553714883976, 4.451899479626642, 2.7789584442207826, 2.7797438539410577, 5.327887456566731, 2.773235520838741, 3.6345558554838524, 8.245639862816445, 5.894976460891032, 6.204097404905977, 14.643191502719104, 5.220605912901651, 32.34033393423048, 7.393020262767645, 6.022222535507046, 8.736860781478311, 18.74031807982522, 13.605202095303744, 6.7017652403261705, 9.227295168724169, 7.306584813971851, 14.8384036584488, 39.7430845551061, 16.6699951935555, 11.586284405277555, 25.383828996534994, 17.030717730728092, 13.230778281145016, 7.237036118512532, 21.887677557440735, 18.692581608215264, 20.35565321352681, 11.248115841853705, 10.744579377946287, 11.02478555834014, 10.157198821783476, 10.896990723760231, 7.941061299175376, 10.232485600573321, 10.444608893628429, 8.349826548574462, 8.209598909880121, 10.64216278741107, 8.414254416173609, 4.268364006764622, 2.640874665112642, 12.261595896348629, 1.831032933303149, 1.8310329521969109, 1.8310306601408923, 1.8310298417099409, 1.8310276536274828, 1.8310219617111576, 1.831008465678789, 1.829012619659423, 1.8274267929017816, 1.8240677372631224, 1.8207460238843287, 1.8182076879505156, 1.8159768102112626, 1.8162596839125749, 1.8132338154054293, 4.244935975261545, 2.6421226454578637, 2.6426792640438195, 3.0740106581725217, 1.017232921542567, 1.017232921542567, 1.017232921542567, 1.0172326481341798, 1.0172325911351274, 1.0172325911351274, 1.0172325911351274, 1.0172316930409717, 7.243884076298857, 1.8346661708228569, 1.8332169426072618, 1.8349796757539338, 1.833573361072864, 3.951108504708874, 13.916653057817527, 3.416893898208356, 12.929781172110468, 3.329664080724282, 11.585231912100237, 2.8083956186157333, 9.177099339901229, 7.828923285525038, 17.194490751973152, 16.59642756730442, 10.798816413726104, 5.7044510803155335, 5.686619459287516, 5.079935062367712, 10.210510081686328, 17.0834954246009, 15.859839047849784, 6.824739628067932, 8.485402549870468, 13.348051561558595, 5.930073427722225, 4.353151490513999, 6.388102298002008, 9.229792187722497, 5.113069734801161, 6.803447600509025, 5.763993817126721, 5.170344275471901, 5.748288038772599, 5.119082795118786, 6.5051214089571, 5.18614016479859, 5.233734162838315, 5.149374528564451, 3.360264158488502, 4.9694761361522195, 1.791294767559189, 1.7912877531092462, 1.7839144778304514, 1.7809522761643541, 2.592441070530611, 2.5867472477584768, 5.788082334883773, 0.9951566143741998, 0.9951566143741998, 0.9951566143741998, 0.9951566143741998, 0.9951544446520743, 0.9951544446520743, 0.9951533239806176, 0.9951528461387406, 0.9951523011450705, 0.9951520537681093, 0.9951520537681093, 0.9951520537681093, 0.9951500963456983, 0.9951500963456983, 0.9951447710047706, 0.9951426922175854, 0.9951258411437545, 0.993058248648007, 0.9890707125916549, 0.9732169340346745, 5.7886706195928594, 1.7922222030578496, 4.184495344841538, 1.7921525733607013, 1.7909176891087553, 1.786190754843121, 1.792783797106626, 1.7921691502534955, 1.797671689307034, 1.7957156788567565, 1.795481770895229, 1.7944564498859779, 2.458386873931933, 1.71915195436628, 4.832611369457912, 3.167075478328631, 4.13967417356828, 2.5942301014982183, 1.6617234420665936, 4.881864631687623, 3.3721239742209796, 3.7393983820363075, 19.33117485888646, 6.6936888599213, 12.582231695856631, 4.193111421558428, 15.500886561478266, 4.65024423411422, 3.389457860236657, 2.5959338819685565, 5.2794530173240615, 3.3869174435680707, 3.3916089904228537, 10.68007187608873, 6.826678619102935, 4.791589097934541, 3.9186495719042385, 9.807204850134195, 8.897218123807193, 6.035535610464272, 5.409372466596593, 6.225565192155583, 4.542054380114118, 4.729952501907894, 4.191632887635291, 4.446608688835345, 4.14613616453813, 3.8708759169447395, 3.753273570716122], \"Total\": [37.0, 134.0, 88.0, 113.0, 40.0, 30.0, 53.0, 16.0, 37.0, 38.0, 90.0, 188.0, 24.0, 94.0, 13.0, 24.0, 30.0, 19.0, 47.0, 28.0, 143.0, 11.0, 28.0, 9.0, 14.0, 42.0, 35.0, 126.0, 77.0, 128.0, 11.96121136943236, 9.238260996362602, 9.237435432725901, 8.327539844235636, 6.510532562132072, 6.509677923734438, 5.601727945854575, 5.601176387066302, 5.600562592152235, 4.692785002299627, 4.692782328921622, 4.692773627035752, 4.692376699571827, 4.6923548137897875, 4.6925346084978035, 4.692454970990687, 4.692383233134302, 4.6922881628990645, 4.6922822624805045, 4.692162832919275, 13.59224096890493, 4.690276208446018, 12.700364183963169, 8.27406930465362, 8.27209661813523, 11.773008305254898, 11.854962147202432, 3.783652858764664, 3.783651957363224, 3.783651653301179, 36.93938576702249, 25.215347155841737, 20.606660020573862, 43.65366985492132, 21.521096295616683, 20.61077440080297, 18.07313820928078, 17.878625503431564, 10.93927118371435, 188.23967271510625, 94.77226207068232, 90.3817416940512, 21.421251667761354, 13.535254775061205, 128.85098055054874, 77.93747782329191, 60.728525247003674, 48.558490394552436, 134.93417271191774, 31.016321466744266, 143.56855731793704, 28.606201734129268, 126.20027099123072, 24.193359076939135, 33.76533308831112, 35.171302886319936, 50.078401744569724, 61.442372514518766, 38.6379582801469, 40.01014681544847, 54.05986973671622, 33.4883007163401, 113.46521724362253, 48.04124602502742, 32.6945351537197, 38.17755217328383, 53.97077438949483, 34.93962674231165, 51.8484178194232, 88.0036437633942, 6.168567988608356, 4.4643237291020235, 37.52021840394084, 3.6123003071296766, 3.6123001990300336, 3.6123472724508963, 3.6123360387757013, 7.02234866905207, 8.684275980716254, 2.7602858769493506, 2.7602857555312075, 2.760285691044742, 2.760285444889664, 2.7602853435637145, 2.7602851852471133, 2.7602848737654435, 2.7602536042617856, 2.760545857913266, 2.7605840741773093, 2.760297843521092, 2.7607642783172435, 2.7603075606485534, 9.521381086556387, 2.76128302630743, 2.7613292070919986, 2.7593715660961227, 2.76179556241854, 2.761846476027683, 2.761846073881117, 5.372689503196991, 10.434186202563403, 7.940315880482765, 12.993956628106233, 12.952971567821379, 24.036381087081125, 5.318586032617157, 21.693390532821184, 19.73370207354791, 113.46521724362253, 7.932825842713038, 6.074277383202425, 16.837347463448477, 17.577833170151926, 4.426117893219047, 38.208350531659335, 4.466719321398381, 23.512757707119615, 4.467346741669068, 4.52123371111965, 28.920821231613616, 8.801193483008369, 37.71238163424943, 134.93417271191774, 143.56855731793704, 33.76533308831112, 126.20027099123072, 35.539109503900235, 18.651599506921414, 13.219230964609837, 19.2969992522758, 128.85098055054874, 88.0036437633942, 188.23967271510625, 61.442372514518766, 90.3817416940512, 94.77226207068232, 77.93747782329191, 44.80854160196793, 51.8484178194232, 46.91957128236691, 60.728525247003674, 32.6945351537197, 48.04124602502742, 4.472052107010557, 3.618092183087334, 3.6182429342906013, 3.6183164878522907, 3.618342847650748, 10.372030265138344, 6.1221160051494685, 2.764147938938371, 2.764147827377879, 2.7641477670713757, 2.764147759669659, 2.7641476288597326, 2.7641475373458513, 2.7641475738787813, 2.7641470247827, 2.764016497543019, 2.764015762995009, 2.763914558436349, 2.764622513208499, 2.7646728760108523, 2.764855154174161, 7.807693048784211, 5.37986887492436, 4.431906930652535, 7.1381755206252615, 4.470113509067865, 4.4713965256361385, 8.621562329477346, 4.52703582656647, 6.28995277014277, 14.759736870352139, 10.441260571726081, 11.292509791777109, 30.779994498099693, 9.438334480903261, 88.0036437633942, 14.92018239009198, 11.921540636864616, 19.76297100793591, 53.97077438949483, 37.217809882197514, 14.593957029560592, 24.036381087081125, 17.40478272800941, 46.91957128236691, 188.23967271510625, 61.442372514518766, 36.99520663702946, 126.20027099123072, 77.93747782329191, 51.8484178194232, 19.73370207354791, 143.56855731793704, 113.46521724362253, 134.93417271191774, 47.294759520211926, 44.80854160196793, 48.558490394552436, 42.12738977098956, 50.078401744569724, 24.193359076939135, 48.04124602502742, 54.05986973671622, 28.920821231613616, 27.793151171200606, 128.85098055054874, 94.77226207068232, 5.125741323617339, 3.497857517939334, 16.514494094992962, 2.683861257973196, 2.683861298815212, 2.683861336995837, 2.683861397135495, 2.6838614741050595, 2.683861518072097, 2.683861910936103, 2.683955622719326, 2.6842824644759524, 2.684671105027227, 2.685062804738074, 2.684798305568635, 2.6846607199262795, 2.685587670818515, 2.6859420138118746, 6.772967831130661, 4.293993223651547, 4.40650818519254, 5.265648015837323, 1.8700598655726066, 1.8700598655726066, 1.8700598655726066, 1.8700598733351579, 1.870059872537638, 1.870059872537638, 1.870059872537638, 1.8700598814897056, 13.754130064722636, 3.537626129992322, 3.53577215866486, 3.592525583977629, 3.5926922351428305, 8.572292289871573, 37.47207208037872, 7.7909481063423645, 40.01014681544847, 7.636679368138598, 38.17755217328383, 6.2049588627282155, 30.779994498099693, 24.866122802811255, 88.0036437633942, 90.3817416940512, 47.294759520211926, 17.12226803469195, 18.821697199452927, 15.541385512560952, 53.97077438949483, 143.56855731793704, 128.85098055054874, 28.337240274248842, 42.12738977098956, 113.46521724362253, 26.37323440967844, 14.757156409940393, 35.539109503900235, 126.20027099123072, 25.801905167299836, 60.728525247003674, 37.217809882197514, 27.793151171200606, 44.80854160196793, 28.8033941410605, 188.23967271510625, 33.287344687291615, 94.77226207068232, 46.91957128236691, 4.242025307489331, 6.648506638900249, 2.648532122730519, 2.6485325622043026, 2.649576433296043, 2.6499957656243325, 4.297076798868631, 4.297474769079379, 9.964006568112303, 1.8523955059845676, 1.8523955059845676, 1.8523955059845676, 1.8523955059845676, 1.852395652102337, 1.852395652102337, 1.852395702807906, 1.8523957172235916, 1.8523957981935988, 1.8523957826756685, 1.8523957826756685, 1.8523957826756685, 1.8523959254226092, 1.8523959254226092, 1.8523962728503112, 1.8523962885866974, 1.8523974228582198, 1.852547761386977, 1.8532561183006588, 1.8555046723251074, 11.051915678702615, 3.4623140027314765, 8.368537139448001, 3.462315754133603, 3.462389201650715, 3.463246945008639, 3.502369120297826, 3.5024136277242714, 3.556751586721349, 3.5569679171877557, 3.5569989591454503, 3.557210931521082, 5.1858990172243535, 3.5676144408563, 12.85736687430482, 7.831085339885339, 11.099337884756086, 6.1697420112994354, 3.5760498403872116, 14.688048018016584, 9.449774252139807, 11.172727236013992, 134.93417271191774, 30.39001029281434, 94.77226207068232, 16.582942575351943, 188.23967271510625, 20.610417993237824, 11.512814249809695, 7.024906960833963, 28.337240274248842, 11.877473845660198, 11.921540636864616, 126.20027099123072, 51.8484178194232, 25.29016729011122, 16.565324184950367, 143.56855731793704, 128.85098055054874, 54.05986973671622, 44.80854160196793, 88.0036437633942, 34.93962674231165, 42.12738977098956, 48.04124602502742, 90.3817416940512, 61.442372514518766, 50.078401744569724, 28.36743999255194], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.7092, -5.9849, -5.9862, -6.1011, -6.3776, -6.38, -6.5517, -6.5535, -6.5541, -6.7624, -6.7624, -6.7624, -6.7633, -6.7634, -6.7634, -6.7638, -6.764, -6.7644, -6.7645, -6.7648, -5.705, -6.7693, -5.7939, -6.2283, -6.2285, -5.8849, -5.8827, -7.0306, -7.0306, -7.0306, -4.7528, -5.1454, -5.362, -4.6515, -5.3425, -5.3978, -5.5249, -5.5366, -5.9896, -3.4009, -4.0515, -4.0952, -5.391, -5.8077, -3.7912, -4.2552, -4.5174, -4.7467, -3.941, -5.1467, -3.9082, -5.2154, -4.0739, -5.365, -5.1141, -5.0871, -4.8516, -4.7086, -5.0553, -5.0329, -4.854, -5.1586, -4.4448, -5.0035, -5.2102, -5.1482, -5.0216, -5.2047, -5.1791, -5.1607, -5.5936, -5.9798, -3.8605, -6.2469, -6.2469, -6.2477, -6.253, -5.5928, -5.4573, -6.6146, -6.6146, -6.6146, -6.6146, -6.6146, -6.6146, -6.6147, -6.615, -6.6167, -6.617, -6.6175, -6.6186, -6.6199, -5.3834, -6.6225, -6.6228, -6.6267, -6.6265, -6.6269, -6.6269, -5.9762, -5.3167, -5.6209, -5.188, -5.2113, -4.6842, -6.0354, -4.8355, -4.9573, -3.6078, -5.7655, -5.9842, -5.2055, -5.1815, -6.2468, -4.6151, -6.2478, -5.0033, -6.2528, -6.2475, -4.8989, -5.7682, -4.7711, -3.9324, -3.9434, -4.8851, -4.0843, -4.8994, -5.2998, -5.5324, -5.3527, -4.3719, -4.6948, -4.5514, -5.0236, -4.9189, -4.9214, -5.005, -5.146, -5.1474, -5.1663, -5.1518, -5.249, -5.2445, -5.9719, -6.2401, -6.241, -6.2414, -6.2446, -5.1935, -5.7614, -6.6078, -6.6078, -6.6078, -6.6078, -6.6078, -6.6078, -6.6078, -6.6079, -6.6093, -6.6093, -6.6104, -6.6117, -6.6121, -6.618, -5.5876, -5.9664, -6.24, -5.7675, -6.2388, -6.2385, -5.5879, -6.2409, -5.9704, -5.1512, -5.4868, -5.4357, -4.5769, -5.6083, -3.7846, -5.2603, -5.4654, -5.0933, -4.3302, -4.6504, -5.3585, -5.0387, -5.2721, -4.5637, -3.5784, -4.4473, -4.811, -4.0268, -4.4259, -4.6783, -5.2817, -4.1749, -4.3327, -4.2475, -4.8407, -4.8865, -4.8607, -4.9427, -4.8724, -5.1888, -4.9353, -4.9148, -5.1386, -5.1556, -4.896, -5.1309, -5.4122, -5.8923, -4.3569, -6.2585, -6.2585, -6.2585, -6.2585, -6.2585, -6.2585, -6.2585, -6.2596, -6.2605, -6.2623, -6.2641, -6.2655, -6.2668, -6.2666, -6.2683, -5.4177, -5.8918, -5.8916, -5.7404, -6.8463, -6.8463, -6.8463, -6.8463, -6.8463, -6.8463, -6.8463, -6.8463, -4.8832, -6.2565, -6.2573, -6.2564, -6.2571, -5.4894, -4.2303, -5.6347, -4.3039, -5.6605, -4.4137, -5.8308, -4.6467, -4.8056, -4.0188, -4.0542, -4.484, -5.1221, -5.1253, -5.2381, -4.54, -4.0253, -4.0996, -4.9428, -4.725, -4.272, -5.0834, -5.3925, -5.009, -4.641, -5.2316, -4.946, -5.1118, -5.2205, -5.1145, -5.2304, -4.9908, -5.2174, -5.2083, -5.2245, -5.4751, -5.0838, -6.1042, -6.1042, -6.1084, -6.11, -5.7346, -5.7368, -4.9314, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.692, -6.6921, -6.6941, -6.6982, -6.7143, -4.9313, -6.1037, -5.2558, -6.1037, -6.1044, -6.1071, -6.1034, -6.1037, -6.1007, -6.1018, -6.1019, -6.1025, -5.7877, -6.1453, -5.1118, -5.5344, -5.2665, -5.7339, -6.1793, -5.1016, -5.4716, -5.3682, -3.7254, -4.786, -4.1549, -5.2537, -3.9463, -5.1502, -5.4665, -5.7332, -5.0233, -5.4672, -5.4659, -4.3188, -4.7663, -5.1203, -5.3214, -4.404, -4.5014, -4.8895, -4.999, -4.8585, -5.1738, -5.1332, -5.2541, -5.195, -5.265, -5.3337, -5.3645], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7905, 0.7731, 0.7718, 0.7606, 0.7303, 0.7281, 0.7065, 0.7048, 0.7044, 0.6729, 0.6729, 0.6729, 0.6721, 0.6719, 0.6719, 0.6716, 0.6713, 0.6709, 0.6709, 0.6706, 0.6668, 0.6666, 0.6458, 0.6399, 0.6399, 0.6306, 0.6258, 0.62, 0.62, 0.62, 0.6192, 0.6085, 0.5937, 0.5535, 0.5698, 0.5577, 0.5619, 0.5611, 0.5993, 0.3427, 0.3783, 0.382, 0.5259, 0.5683, 0.3314, 0.3702, 0.3575, 0.3518, 0.1355, 0.4001, 0.1063, 0.4122, 0.0696, 0.4302, 0.3478, 0.334, 0.2161, 0.1546, 0.2718, 0.2593, 0.1372, 0.3115, -0.195, 0.1058, 0.2839, 0.1908, -0.0288, 0.223, -0.1461, -0.6568, 1.5682, 1.5054, 1.496, 1.4501, 1.4501, 1.4492, 1.444, 1.4394, 1.3625, 1.3513, 1.3513, 1.3513, 1.3513, 1.3513, 1.3513, 1.3513, 1.351, 1.3492, 1.3489, 1.3485, 1.3472, 1.346, 1.3444, 1.3431, 1.3428, 1.3396, 1.3389, 1.3385, 1.3385, 1.3238, 1.3195, 1.2885, 1.2288, 1.2086, 1.1176, 1.2747, 1.0688, 1.0417, 0.642, 1.1448, 1.1931, 0.9522, 0.9331, 1.247, 0.7232, 1.2368, 0.8204, 1.2317, 1.225, 0.7178, 1.0382, 0.5803, 0.1441, 0.0711, 0.5768, 0.0591, 0.5113, 0.7556, 0.8673, 0.6686, -0.2493, -0.1908, -0.8078, -0.1604, -0.4416, -0.4916, -0.3796, 0.0329, -0.1144, -0.0334, -0.2769, 0.2451, -0.1353, 1.5116, 1.4552, 1.4543, 1.4539, 1.4507, 1.4487, 1.408, 1.3567, 1.3567, 1.3567, 1.3567, 1.3567, 1.3567, 1.3567, 1.3567, 1.3553, 1.3553, 1.3542, 1.3527, 1.3523, 1.3463, 1.3386, 1.3322, 1.2524, 1.2483, 1.2451, 1.2451, 1.2391, 1.2304, 1.172, 1.1382, 1.1488, 1.1215, 0.9775, 1.1283, 0.7194, 1.0183, 1.0375, 0.9042, 0.6627, 0.7141, 0.9422, 0.763, 0.8525, 0.5692, 0.1652, 0.4159, 0.5595, 0.1167, 0.1995, 0.3547, 0.7173, -0.1605, -0.0829, -0.171, 0.2842, 0.2924, 0.2378, 0.2979, 0.1953, 0.6064, 0.1739, 0.0764, 0.4781, 0.501, -0.7734, -0.7011, 1.9349, 1.8369, 1.8201, 1.7355, 1.7355, 1.7355, 1.7355, 1.7355, 1.7355, 1.7355, 1.7344, 1.7334, 1.7314, 1.7295, 1.7282, 1.727, 1.7268, 1.725, 1.6507, 1.6323, 1.6066, 1.5797, 1.509, 1.509, 1.509, 1.509, 1.509, 1.509, 1.509, 1.509, 1.4767, 1.4613, 1.4611, 1.4461, 1.4453, 1.3434, 1.1274, 1.2937, 0.9883, 1.2878, 0.9254, 1.3252, 0.9078, 0.9622, 0.4851, 0.4231, 0.641, 1.0188, 0.921, 0.9997, 0.4529, -0.0108, 0.023, 0.6943, 0.5156, -0.0222, 0.6256, 0.8971, 0.4017, -0.4975, 0.4993, -0.0711, 0.2528, 0.4361, 0.0644, 0.3904, -1.2472, 0.2587, -0.7784, -0.0916, 2.0611, 2.0031, 1.9031, 1.9031, 1.8986, 1.8967, 1.7888, 1.7865, 1.751, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6728, 1.6706, 1.6662, 1.6488, 1.6474, 1.6357, 1.601, 1.6356, 1.6349, 1.632, 1.6245, 1.6241, 1.6118, 1.6106, 1.6105, 1.6099, 1.5477, 1.5641, 1.3156, 1.3888, 1.3079, 1.4278, 1.5277, 1.1926, 1.2637, 1.1996, 0.3511, 0.7812, 0.2749, 0.9192, -0.2027, 0.8053, 1.0713, 1.2986, 0.6138, 1.0394, 1.0371, -0.1754, 0.2667, 0.6306, 0.8526, -0.3896, -0.3788, 0.1017, 0.1799, -0.3546, 0.2539, 0.1074, -0.1448, -0.7178, -0.4018, -0.266, 0.2715]}, \"token.table\": {\"Topic\": [2, 4, 1, 3, 5, 4, 2, 3, 4, 1, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 3, 5, 1, 3, 4, 5, 3, 5, 3, 1, 2, 3, 4, 5, 3, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 4, 5, 2, 3, 3, 4, 5, 1, 3, 5, 1, 4, 1, 3, 2, 1, 2, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 2, 5, 1, 4, 5, 1, 3, 4, 1, 2, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 1, 3, 5, 1, 2, 3, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 3, 1, 2, 3, 1, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 4, 1, 3, 4, 5, 1, 5, 1, 2, 3, 5, 1, 2, 2, 3, 1, 5, 1, 2, 3, 4, 5, 3, 4, 1, 4, 1, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 5, 1, 2, 3, 4, 5, 2, 3, 1, 4, 3, 1, 3, 3, 1, 2, 2, 3, 4, 5, 1, 2, 3, 2, 1, 2, 3, 4, 5, 4, 1, 2, 4, 5, 2, 1, 2, 3, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 5, 1, 1, 5, 1, 2, 3, 4, 5, 4, 1, 2, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 2, 4, 1, 2, 3, 4, 5, 1, 4, 1, 3, 4, 5, 2, 1, 4, 1, 2, 3, 1, 2, 3, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 4, 5, 1, 3, 1, 5, 1, 2, 4, 2, 5, 1, 2, 3, 5, 3, 1, 1, 2, 3, 4, 5, 2, 3, 2, 2, 4, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 2, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 1, 1, 4, 5, 1, 2, 4, 5, 2, 4, 4, 3, 1, 2, 3, 3, 1, 3, 4, 5, 5, 1, 3, 5, 1, 4, 5, 1, 2, 4, 5, 3, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 5, 4, 2, 3, 1, 2, 3, 4, 5, 1, 4, 5, 2, 4, 2, 1, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 3, 4, 3, 5, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 1, 2, 3, 4, 5, 5, 2, 5, 5, 1, 5, 1, 2, 4, 5, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 2, 4, 1, 2, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 1, 5, 2, 1, 3, 1, 2, 3, 4, 5, 5, 5, 3, 5, 4, 1, 2, 5, 1, 2, 3, 4, 5, 3, 2, 3, 4, 1, 3, 4, 5, 5, 5, 1, 1, 2, 3, 2, 3, 2, 2, 3, 4, 5, 1, 1, 3, 4, 3, 4, 5, 3, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 3, 3, 4, 5, 4, 1, 2, 3, 1, 2, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 4, 4, 2, 1, 4, 5, 2, 4, 4, 1, 2, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 5, 2, 1, 2, 3, 4, 1, 2, 3, 5, 4, 4, 5, 4, 5, 4], \"Freq\": [0.2828236535403936, 0.5656473070807873, 0.31796741137606405, 0.6359348227521281, 0.7548376317312057, 0.7449349159122044, 0.7351874624452933, 0.10502678034932762, 0.10502678034932762, 0.13094696684165555, 0.3928409005249666, 0.2618939336833111, 0.22724190802772495, 0.4544838160554499, 0.11362095401386248, 0.11362095401386248, 0.8524636362957116, 0.238990395414786, 0.238990395414786, 0.477980790829572, 0.2855210189595791, 0.5710420379191582, 0.40658239523424794, 0.13552746507808264, 0.2710549301561653, 0.13552746507808264, 0.2855173906600404, 0.5710347813200808, 0.7236113699301456, 0.5435069795287372, 0.1811689931762457, 0.1035251389578547, 0.07764385421839103, 0.1035251389578547, 0.7235503194964888, 0.7713051153436153, 0.19282627883590384, 0.5673623203798228, 0.20902822329782944, 0.029861174756832778, 0.11944469902733111, 0.059722349513665555, 0.3347576034329406, 0.1785373884975683, 0.24548890918415642, 0.1339030413731762, 0.11158586781098019, 0.19493180872304672, 0.4873295218076168, 0.2923977130845701, 0.03248863478717445, 0.06055286914923967, 0.726634429790876, 0.181658607447719, 0.3830955058081407, 0.5746432587122111, 0.14764576252727643, 0.5905830501091057, 0.14764576252727643, 0.7764480019578848, 0.0970560002447356, 0.1455840003671034, 0.2783427954719434, 0.5566855909438868, 0.18587813629826802, 0.7435125451930721, 0.7241532132070448, 0.7388113608637101, 0.07388113608637102, 0.07388113608637102, 0.07388113608637102, 0.4824234277872252, 0.2412117138936126, 0.2412117138936126, 0.31715987462817286, 0.14800794149314733, 0.23258390806066012, 0.23258390806066012, 0.06343197492563457, 0.7244843649965729, 0.25737731019973065, 0.32172163774966334, 0.06434432754993266, 0.32172163774966334, 0.2327163434135708, 0.6981490302407125, 0.19283059633028288, 0.19283059633028288, 0.38566119266056575, 0.7434565498068426, 0.09293206872585533, 0.13939810308878298, 0.7928847668353353, 0.23269479257797335, 0.6980843777339201, 0.6030474851465346, 0.12830797556309248, 0.2181235584572572, 0.051323190225236986, 0.29555742357805037, 0.16121314013348204, 0.3761639936447914, 0.16121314013348204, 0.026868856688913673, 0.615670825212377, 0.3078354126061885, 0.4270519192248283, 0.14235063974160944, 0.4270519192248283, 0.302589463086672, 0.453884194630008, 0.226942097315004, 0.6533688673385962, 0.16334221683464906, 0.6125807027236232, 0.06448217923406559, 0.19344653770219677, 0.09672326885109839, 0.06448217923406559, 0.6909038834467277, 0.11515064724112128, 0.11515064724112128, 0.22089509301684718, 0.6626852790505415, 0.8524322608801735, 0.7245594908152228, 0.8291662700092087, 0.8926696205364143, 0.7271252478276266, 0.05593271137135589, 0.05593271137135589, 0.11186542274271177, 0.3323253606764145, 0.11868762881300518, 0.23737525762601036, 0.1899002061008083, 0.11868762881300518, 0.17521043321606744, 0.2336139109547566, 0.17521043321606744, 0.3504208664321349, 0.05840347773868915, 0.2801836399540946, 0.5603672799081892, 0.6403940278849185, 0.2561576111539674, 0.5970776819919305, 0.11372908228417723, 0.08529681171313293, 0.14216135285522152, 0.08529681171313293, 0.8523723115463124, 0.7192995399838384, 0.05533073384491065, 0.16599220153473196, 0.7451949314570684, 0.5896737834218102, 0.07968564640835273, 0.21249505708894062, 0.037186634990564606, 0.08499802283557624, 0.8576678680060608, 0.3174679013438527, 0.10582263378128424, 0.2116452675625685, 0.3174679013438527, 0.28111911810987117, 0.5622382362197423, 0.06852151188155917, 0.27408604752623666, 0.47965058317091414, 0.2055645356446775, 0.8462183558946393, 0.12088833655637704, 0.7245627719842417, 0.7235502745081517, 0.28113587085227726, 0.5622717417045545, 0.4606776985301079, 0.23033884926505396, 0.032905549895007706, 0.032905549895007706, 0.23033884926505396, 0.6769095215540306, 0.22563650718467687, 0.809285240393014, 0.147142770980548, 0.4862439944013408, 0.4862439944013408, 0.36645284078239154, 0.15429593296100697, 0.2507308910616363, 0.09643495810062934, 0.1350089413408811, 0.5408468085483605, 0.3744324059180958, 0.0416036006575662, 0.39578095813037034, 0.07196017420552188, 0.2878406968220875, 0.1799004355138047, 0.07196017420552188, 0.8405843899798852, 0.2811383243486294, 0.5622766486972588, 0.4666759996175654, 0.19502877595957957, 0.1532368953968125, 0.11841032826117331, 0.06965313427127842, 0.7120124954825033, 0.14240249909650066, 0.48348426901269587, 0.48348426901269587, 0.7234260700853833, 0.8523727971246389, 0.7235503700670751, 0.7235503556751203, 0.186126519949637, 0.744506079798548, 0.10595089652981854, 0.5297544826490926, 0.10595089652981854, 0.21190179305963708, 0.6292341838072371, 0.17478727327978807, 0.17478727327978807, 0.8304849378350514, 0.2159001512605913, 0.14772115612566775, 0.36362130738625903, 0.19317381954895013, 0.06817899513492358, 0.7451688034892481, 0.11665491168348643, 0.23330982336697287, 0.46661964673394574, 0.11665491168348643, 0.8304957353846893, 0.1260584840544033, 0.5042339362176133, 0.2521169681088066, 0.21252068597279655, 0.05313017149319914, 0.2656508574659957, 0.31878102895919486, 0.10626034298639828, 0.6585145438141247, 0.16462863595353117, 0.16462863595353117, 0.34041283047733256, 0.272330264381866, 0.34041283047733256, 0.8925817262689687, 0.28029934752702135, 0.5605986950540427, 0.3396340628461133, 0.04851915183515904, 0.14555745550547713, 0.19407660734063617, 0.24259575917579523, 0.7451949923354453, 0.8523743776932724, 0.8304957602376328, 0.22364377533207738, 0.6709313259962322, 0.15179903865645183, 0.20239871820860245, 0.4553971159693555, 0.25299839776075306, 0.3095181661429307, 0.3095181661429307, 0.19696610572731954, 0.16882809062341675, 0.7803749248073876, 0.7451949436648571, 0.7245627453866262, 0.7451950036755493, 0.36232215119128464, 0.17050454173707513, 0.31969601575701584, 0.10656533858567195, 0.04262613543426878, 0.2269370571829099, 0.6808111715487297, 0.20325565600197762, 0.5420150826719403, 0.06775188533399254, 0.13550377066798508, 0.7244370755257132, 0.7644605156681015, 0.16988011459291144, 0.26809323742960894, 0.20106992807220672, 0.4691631655018157, 0.4595189903057403, 0.18921370189059894, 0.3243663460981696, 0.027030528841514134, 0.28882417920820685, 0.5776483584164137, 0.6119934117088277, 0.10551610546703927, 0.08441288437363141, 0.052758052733519634, 0.13717093710715103, 0.383088661378823, 0.12769622045960768, 0.383088661378823, 0.4579398292154818, 0.1665235742601752, 0.208154467825219, 0.0832617871300876, 0.0832617871300876, 0.550550724008447, 0.24468921067042085, 0.12234460533521042, 0.030586151333802606, 0.06117230266760521, 0.582067747405129, 0.13969625937723096, 0.0853699362860856, 0.12417445277976086, 0.06984812968861548, 0.4516630554934447, 0.19017391810250303, 0.19809783135677397, 0.07131521928843863, 0.08716304579698056, 0.18019092857302912, 0.4504773214325728, 0.36038185714605825, 0.7313101454062004, 0.1828275363515501, 0.8944439609121391, 0.4825323424224391, 0.37530293299523043, 0.10722940942720868, 0.49767465220821466, 0.1047736109912031, 0.3143208329736093, 0.07858020824340232, 0.6613385081880192, 0.3306692540940096, 0.6080181481357357, 0.2605792063438867, 0.7535093561302881, 0.15863354865900803, 0.03965838716475201, 0.7241533186494626, 0.7547181870793688, 0.5923234918989619, 0.32577792054442906, 0.05923234918989619, 0.029616174594948096, 0.7235848748680278, 0.8524853340418626, 0.4242638440386699, 0.3181978830290024, 0.1590989415145012, 0.05303298050483374, 0.02651649025241687, 0.6716338735743081, 0.22387795785810274, 0.7244943945658006, 0.8304875204846016, 0.7451949650360539, 0.4882623956767137, 0.1464787187030141, 0.27668202421680443, 0.01627541318922379, 0.06510165275689515, 0.7245628953042442, 0.724556940144049, 0.2304849485116313, 0.5070668867255889, 0.09219397940465252, 0.09219397940465252, 0.04609698970232626, 0.7245626319728834, 0.9196392957415, 0.40762802181104524, 0.05558563933786981, 0.35204238247317543, 0.18528546445956603, 0.38818176694489653, 0.07057850308089028, 0.14115700616178056, 0.24702476078311597, 0.1764462577022257, 0.6708716773983088, 0.28751643317070374, 0.745078070757526, 0.8659638435361218, 0.8524625643469979, 0.28881790629523796, 0.5776358125904759, 0.1544047240070017, 0.6176188960280068, 0.07720236200350085, 0.1544047240070017, 0.7241665629473943, 0.7451949817342975, 0.7451948223753513, 0.7235503037105061, 0.7850699029730388, 0.13535687982293773, 0.08121412789376263, 0.7235503214339809, 0.5433035840117466, 0.06036706489019407, 0.18110119467058222, 0.24146825956077628, 0.5398414363455111, 0.7873789959997418, 0.07873789959997418, 0.07873789959997418, 0.35801464723012866, 0.2685109854225965, 0.35801464723012866, 0.48605382863689617, 0.20830878370152695, 0.17359065308460578, 0.10415439185076347, 0.5799412924157458, 0.3479647754494475, 0.311105690543366, 0.155552845271683, 0.0777764226358415, 0.3888821131792075, 0.26686541322160406, 0.05337308264432081, 0.21349233057728323, 0.3736115785102457, 0.08005962396648121, 0.539841516981272, 0.5347422372327671, 0.5395908261816229, 0.7446177131581522, 0.6715395453900126, 0.22384651513000417, 0.5972179069894105, 0.04118744186133866, 0.2265309302373626, 0.08237488372267732, 0.06178116279200798, 0.27835570732186804, 0.5567114146437361, 0.5398409583495403, 0.6777948695393079, 0.22593162317976928, 0.7245626638446014, 0.27963816071750297, 0.5592763214350059, 0.7235503796300289, 0.3827709242831528, 0.4253010269812809, 0.04253010269812809, 0.08506020539625618, 0.08506020539625618, 0.5687584528689931, 0.11375169057379861, 0.0379172301912662, 0.22750338114759722, 0.0379172301912662, 0.43495165033175326, 0.07908211824213696, 0.27678741384747935, 0.1977052956053424, 0.792884577941825, 0.28267543354056196, 0.5653508670811239, 0.7233651994320778, 0.755135262599001, 0.15040971669472727, 0.7520485834736365, 0.7072093593367949, 0.5191858983961948, 0.13978081879897553, 0.2196555723983901, 0.03993737679970729, 0.07987475359941458, 0.7928848305531894, 0.8959923703392765, 0.7551351372986156, 0.8528282391550838, 0.7002391938924262, 0.04668261292616174, 0.09336522585232349, 0.04668261292616174, 0.09336522585232349, 0.5398414363455111, 0.7245626807720106, 0.5398414554201304, 0.539841516981272, 0.2811554238798584, 0.5623108477597168, 0.5498605166703736, 0.07498097954596003, 0.3249175780324935, 0.049987319697306694, 0.5398414318231396, 0.5398412934945525, 0.7330426080178105, 0.09163032600222631, 0.06872274450166974, 0.06872274450166974, 0.06872274450166974, 0.36275070069116844, 0.36275070069116844, 0.15546458601050075, 0.05182152867016692, 0.05182152867016692, 0.481716370980196, 0.20750859057608442, 0.1482204218400603, 0.01482204218400603, 0.14080940074805728, 0.7449702111572868, 0.9217045866622463, 0.799568906476542, 0.1066091875302056, 0.0799568906476542, 0.724571103507313, 0.5347422372327671, 0.3217228541594573, 0.24129214061959295, 0.3217228541594573, 0.12064607030979647, 0.16776355178587077, 0.5032906553576123, 0.25164532767880615, 0.5928021445206465, 0.131733809893477, 0.08233363118342313, 0.11526708365679238, 0.0658669049467385, 0.53984147439834, 0.7234128917580299, 0.34023975961035624, 0.3664120488111529, 0.13086144600398317, 0.0785168676023899, 0.0785168676023899, 0.8660412360402564, 0.539841394744948, 0.7248027139851777, 0.8524504558446624, 0.829114868771664, 0.2820134633967835, 0.24676178047218558, 0.14100673169839176, 0.17625841462298972, 0.14100673169839176, 0.5398414596212763, 0.53984147439834, 0.7235846825725656, 0.5398412889085192, 0.7448615341402037, 0.22117856848244136, 0.6635357054473241, 0.5389369344712637, 0.3100546238011462, 0.19378413987571635, 0.1550273119005731, 0.19378413987571635, 0.11627048392542981, 0.8291317234585258, 0.5067472875961031, 0.3547231013172722, 0.10134945751922063, 0.344732829691935, 0.4021883013072576, 0.1723664148459675, 0.05745547161532251, 0.5398414363455111, 0.539841516981272, 0.8524464799181607, 0.31119448261593685, 0.380348812086145, 0.2766173178808327, 0.22370796579806004, 0.6711238973941801, 0.7245628135416562, 0.33677194763611484, 0.25257896072708613, 0.08419298690902871, 0.25257896072708613, 0.9215835943895683, 0.17710854689329952, 0.5313256406798985, 0.26566282033994926, 0.20072246905181468, 0.20072246905181468, 0.602167407155444, 0.7235505137999045, 0.3798202982775649, 0.5697304474163474, 0.5151743644187853, 0.1144831920930634, 0.1144831920930634, 0.1144831920930634, 0.14310399011632927, 0.41574244489495865, 0.4751342227370956, 0.05939177784213695, 0.619594167476481, 0.11064181562080017, 0.03319254468624005, 0.18809108655536028, 0.04425672624832007, 0.8460166022615934, 0.12085951460879904, 0.8291088286307047, 0.2888240331073548, 0.5776480662147097, 0.7447159598369912, 0.8927674528637943, 0.5640596921065066, 0.18801989736883554, 0.1283540830140983, 0.38506224904229497, 0.38506224904229497, 0.5397971490091644, 0.3982288335678577, 0.4551186669346945, 0.11377966673367362, 0.12593957407387182, 0.6296978703693592, 0.12593957407387182, 0.2887463746820704, 0.5774927493641407, 0.8524177941610321, 0.5347422392244128, 0.7449730929332924, 0.7243009792714121, 0.36352717158203124, 0.5089380402148437, 0.07270543431640625, 0.7242888659792336, 0.5347422392244128, 0.5347422346729301, 0.3437176691449207, 0.3437176691449207, 0.1674521977885511, 0.11457255638164023, 0.02643982070345544, 0.539841516981272, 0.8524452929920174, 0.4809482547151126, 0.1294860685771457, 0.184980097967351, 0.0924900489836755, 0.1109880587804106, 0.759175768614651, 0.16870572635881134, 0.7277746924160025, 0.0485183128277335, 0.097036625655467, 0.097036625655467, 0.8105608966673661, 0.4506217044619565, 0.15020723482065218, 0.24033157571304348, 0.15020723482065218, 0.27144615351898616, 0.09048205117299538, 0.09048205117299538, 0.5428923070379723, 0.5347422392244128, 0.534742237004717, 0.539841394744948, 0.6986503806004718, 0.23288346020015727, 0.5347422372327671], \"Term\": [\"addition\", \"addition\", \"adore\", \"adore\", \"afraid\", \"airy\", \"already\", \"already\", \"already\", \"although\", \"although\", \"although\", \"always\", \"always\", \"always\", \"always\", \"amount\", \"anything\", \"anything\", \"anything\", \"aqua\", \"aqua\", \"around\", \"around\", \"around\", \"around\", \"bag\", \"bag\", \"bc\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"bend\", \"best\", \"best\", \"big\", \"big\", \"big\", \"big\", \"big\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"black\", \"black\", \"black\", \"black\", \"blouse\", \"blouse\", \"blouse\", \"boot\", \"boot\", \"boxy\", \"boxy\", \"boxy\", \"bra\", \"bra\", \"bra\", \"brown\", \"brown\", \"build\", \"build\", \"bummer\", \"bust\", \"bust\", \"bust\", \"bust\", \"button\", \"button\", \"button\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"cashmere\", \"casual\", \"casual\", \"casual\", \"casual\", \"catch\", \"catch\", \"cheap\", \"cheap\", \"cheap\", \"chest\", \"chest\", \"chest\", \"clothing\", \"collar\", \"collar\", \"color\", \"color\", \"color\", \"color\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfy\", \"comfy\", \"complaint\", \"complaint\", \"complaint\", \"compliment\", \"compliment\", \"compliment\", \"cool\", \"cool\", \"could\", \"could\", \"could\", \"could\", \"could\", \"cozy\", \"cozy\", \"cozy\", \"crazy\", \"crazy\", \"cross\", \"crotch\", \"currently\", \"curvy\", \"cut\", \"cut\", \"cut\", \"cut\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"day\", \"day\", \"day\", \"day\", \"day\", \"delicate\", \"delicate\", \"denim\", \"denim\", \"design\", \"design\", \"design\", \"design\", \"design\", \"detergent\", \"different\", \"different\", \"different\", \"draped\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"dressy\", \"due\", \"due\", \"due\", \"due\", \"dye\", \"dye\", \"easy\", \"easy\", \"easy\", \"easy\", \"either\", \"either\", \"elevate\", \"emerson\", \"etc\", \"etc\", \"even\", \"even\", \"even\", \"even\", \"even\", \"excellent\", \"excellent\", \"expect\", \"expect\", \"eye\", \"eye\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fall\", \"fall\", \"fall\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feminine\", \"femininity\", \"femininity\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"flat\", \"flat\", \"flower\", \"flower\", \"flowing\", \"frumpy\", \"gathering\", \"gauze\", \"generally\", \"generally\", \"glad\", \"glad\", \"glad\", \"glad\", \"good\", \"good\", \"good\", \"gray\", \"great\", \"great\", \"great\", \"great\", \"great\", \"hand\", \"hang\", \"hang\", \"hang\", \"hang\", \"hd\", \"heel\", \"heel\", \"heel\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highly\", \"highly\", \"highly\", \"hip\", \"hip\", \"hip\", \"hope\", \"horrible\", \"horrible\", \"however\", \"however\", \"however\", \"however\", \"however\", \"hte\", \"hug\", \"inner\", \"issue\", \"issue\", \"jacket\", \"jacket\", \"jacket\", \"jacket\", \"jean\", \"jean\", \"jean\", \"jean\", \"jersey\", \"jogger\", \"jump\", \"knot\", \"large\", \"large\", \"large\", \"large\", \"large\", \"last\", \"last\", \"layer\", \"layer\", \"layer\", \"layer\", \"layered\", \"lb\", \"lb\", \"legging\", \"legging\", \"legging\", \"length\", \"length\", \"length\", \"length\", \"lie\", \"lie\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lining\", \"lining\", \"lining\", \"little\", \"little\", \"little\", \"little\", \"little\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lovely\", \"lovely\", \"lovely\", \"low\", \"low\", \"maeve\", \"many\", \"many\", \"many\", \"material\", \"material\", \"material\", \"material\", \"medium\", \"medium\", \"might\", \"might\", \"model\", \"model\", \"model\", \"money\", \"mostly\", \"much\", \"much\", \"much\", \"much\", \"name\", \"necklace\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nothing\", \"nothing\", \"occasion\", \"often\", \"old\", \"order\", \"order\", \"order\", \"order\", \"order\", \"outfit\", \"outside\", \"pant\", \"pant\", \"pant\", \"pant\", \"pant\", \"paris\", \"part\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"petite\", \"petite\", \"petite\", \"petite\", \"petite\", \"photo\", \"photo\", \"pic\", \"place\", \"plan\", \"please\", \"please\", \"pocket\", \"pocket\", \"pocket\", \"pocket\", \"point\", \"poncho\", \"poor\", \"press\", \"pretty\", \"pretty\", \"pretty\", \"previously\", \"price\", \"price\", \"price\", \"price\", \"princess\", \"print\", \"print\", \"print\", \"probably\", \"probably\", \"probably\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purple\", \"purple\", \"put\", \"put\", \"put\", \"put\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"racier\", \"ratio\", \"realistically\", \"reality\", \"realize\", \"realize\", \"really\", \"really\", \"really\", \"really\", \"really\", \"recently\", \"recently\", \"register\", \"regret\", \"regret\", \"remind\", \"remove\", \"remove\", \"resemble\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"return\", \"return\", \"return\", \"return\", \"return\", \"review\", \"review\", \"review\", \"review\", \"ribbon\", \"rise\", \"rise\", \"road\", \"rock\", \"romper\", \"romper\", \"ruffle\", \"run\", \"run\", \"run\", \"run\", \"run\", \"sad\", \"scarf\", \"scratchy\", \"send\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shaped\", \"sheath\", \"shel\", \"shelf\", \"shift\", \"shift\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"shopper\", \"shopping\", \"short\", \"short\", \"short\", \"short\", \"short\", \"show\", \"show\", \"show\", \"show\", \"show\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skim\", \"skin\", \"skirt\", \"skirt\", \"skirt\", \"slack\", \"sleek\", \"sleeve\", \"sleeve\", \"sleeve\", \"sleeve\", \"slip\", \"slip\", \"slip\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smock\", \"sock\", \"soft\", \"soft\", \"soft\", \"soft\", \"soft\", \"someone\", \"specifically\", \"stand\", \"star\", \"state\", \"store\", \"store\", \"store\", \"store\", \"store\", \"straighten\", \"strangely\", \"strap\", \"streak\", \"striped\", \"structure\", \"structure\", \"stud\", \"style\", \"style\", \"style\", \"style\", \"style\", \"suggest\", \"summer\", \"summer\", \"summer\", \"super\", \"super\", \"super\", \"super\", \"superb\", \"supportive\", \"surprise\", \"sweater\", \"sweater\", \"sweater\", \"swing\", \"swing\", \"swingy\", \"take\", \"take\", \"take\", \"take\", \"tall\", \"tank\", \"tank\", \"tank\", \"tee\", \"tee\", \"tee\", \"thankfully\", \"thicker\", \"thicker\", \"think\", \"think\", \"think\", \"think\", \"think\", \"though\", \"though\", \"though\", \"top\", \"top\", \"top\", \"top\", \"top\", \"torso\", \"torso\", \"town\", \"trend\", \"trend\", \"tucked\", \"turtleneck\", \"twice\", \"twice\", \"unflattering\", \"unflattering\", \"unflattering\", \"upcoming\", \"usual\", \"usual\", \"usual\", \"versatile\", \"versatile\", \"versatile\", \"vest\", \"vest\", \"vibrant\", \"visual\", \"volume\", \"walk\", \"wash\", \"wash\", \"wash\", \"wasnt\", \"waste\", \"water\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"weddi\", \"weird\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wide\", \"wide\", \"without\", \"without\", \"without\", \"without\", \"wool\", \"work\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"worth\", \"worth\", \"wrinkling\", \"wrist\", \"writing\", \"xx\", \"xx\", \"yo\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1351398900899349284271169948\", ldavis_el1351398900899349284271169948_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1351398900899349284271169948\", ldavis_el1351398900899349284271169948_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1351398900899349284271169948\", ldavis_el1351398900899349284271169948_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "4UwjSJkB0ua8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "Z5SMYmR50ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "32db9e89-622d-4d0e-aee4-ac85ad8659ff",
        "id": "sBJf0bw10ua8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4\n",
              "Doc_0  0.93357  0.01668  0.01683  0.01659  0.01634\n",
              "Doc_1  0.03655  0.03736  0.03770  0.85327  0.03512\n",
              "Doc_2  0.96710  0.00853  0.00824  0.00798  0.00815\n",
              "Doc_3  0.96244  0.00936  0.00951  0.00933  0.00936\n",
              "Doc_4  0.00735  0.00720  0.00704  0.97124  0.00717"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7fe3e73-2be7-474a-a68c-4ae758de8925\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.93357</td>\n",
              "      <td>0.01668</td>\n",
              "      <td>0.01683</td>\n",
              "      <td>0.01659</td>\n",
              "      <td>0.01634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.03655</td>\n",
              "      <td>0.03736</td>\n",
              "      <td>0.03770</td>\n",
              "      <td>0.85327</td>\n",
              "      <td>0.03512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.96710</td>\n",
              "      <td>0.00853</td>\n",
              "      <td>0.00824</td>\n",
              "      <td>0.00798</td>\n",
              "      <td>0.00815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.96244</td>\n",
              "      <td>0.00936</td>\n",
              "      <td>0.00951</td>\n",
              "      <td>0.00933</td>\n",
              "      <td>0.00936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.00735</td>\n",
              "      <td>0.00720</td>\n",
              "      <td>0.00704</td>\n",
              "      <td>0.97124</td>\n",
              "      <td>0.00717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7fe3e73-2be7-474a-a68c-4ae758de8925')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7fe3e73-2be7-474a-a68c-4ae758de8925 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7fe3e73-2be7-474a-a68c-4ae758de8925');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "HCQ-4h5X0ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e7dcc92f-a792-456c-baa7-3e41a73cc5b6",
        "id": "YxOETuj90ua8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  dominant_topic\n",
              "Doc_0  0.93357  0.01668  0.01683  0.01659  0.01634               0\n",
              "Doc_1  0.03655  0.03736  0.03770  0.85327  0.03512               3\n",
              "Doc_2  0.96710  0.00853  0.00824  0.00798  0.00815               0\n",
              "Doc_3  0.96244  0.00936  0.00951  0.00933  0.00936               0\n",
              "Doc_4  0.00735  0.00720  0.00704  0.97124  0.00717               3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1997fb47-5185-44f9-9903-9eda5fd2e6e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "      <th>dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.93357</td>\n",
              "      <td>0.01668</td>\n",
              "      <td>0.01683</td>\n",
              "      <td>0.01659</td>\n",
              "      <td>0.01634</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.03655</td>\n",
              "      <td>0.03736</td>\n",
              "      <td>0.03770</td>\n",
              "      <td>0.85327</td>\n",
              "      <td>0.03512</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.96710</td>\n",
              "      <td>0.00853</td>\n",
              "      <td>0.00824</td>\n",
              "      <td>0.00798</td>\n",
              "      <td>0.00815</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.96244</td>\n",
              "      <td>0.00936</td>\n",
              "      <td>0.00951</td>\n",
              "      <td>0.00933</td>\n",
              "      <td>0.00936</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.00735</td>\n",
              "      <td>0.00720</td>\n",
              "      <td>0.00704</td>\n",
              "      <td>0.97124</td>\n",
              "      <td>0.00717</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1997fb47-5185-44f9-9903-9eda5fd2e6e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1997fb47-5185-44f9-9903-9eda5fd2e6e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1997fb47-5185-44f9-9903-9eda5fd2e6e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "xe1MUs_o0ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f998e035-182a-4e9a-de46-962e3fef22f1",
        "id": "XLXFKwO-0ua8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "Sl0TqnkA0ua9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "NFOxDegB0ua9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "1X-S6ce60ua9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a43abe-6434-4466-d92c-bcf410d0d162",
        "id": "4K4JfDeX0ua9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score for the model:  -2.5455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "q86CDjL10ua9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bbba88c-0432-4912-e9e1-196cb4ac2525",
        "id": "lZjKbr-o0ua9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score by topic (higher values are better):  [-1.80807 -2.4549  -1.71623 -2.51033 -4.23798]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "WwFV0MIq0ua9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0105ee19-965c-4e2d-80d1-9976ffa4e26b",
        "id": "xuHozlFc0ua9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log-Likelihood (higher values are better):  -51603.49809964042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "v6YyfawR0ua-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4788670-0761-452c-f440-37eb351b2743",
        "id": "BzP-a5-j0ua-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (lower values are better):  657.5741530459667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "d8fo8ErX0ua-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GenZ_bottoms**"
      ],
      "metadata": {
        "id": "AjKWxZvOzs-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_GenZ_bottoms)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "nPBq2SrDzs-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "Mvn-J5Cuzs-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "ifYcZwkpzs-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f545378-88e1-4b31-80a3-07b80196ee1b",
        "id": "WvofT1yRzs-r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "top size wear dress fit work like great color look\n",
            "Topic 1:\n",
            "size shirt wear look like dress white small arm cut\n",
            "Topic 2:\n",
            "dress fit love wear size like top perfect look color\n",
            "Topic 3:\n",
            "look love like color wear dress fit great really sweater\n",
            "Topic 4:\n",
            "fit dress love length wear size bit like perfect well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "1-ePFR_Mzs-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "04374c8f-6ea8-4ba2-e4a0-b632e3a73d32",
        "id": "IFnTDWVOzs-r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "0p      0.000176  0.000321  0.000992  0.000154  0.000344\n",
              "120lbs  0.000176  0.000321  0.000198  0.000154  0.001718\n",
              "128lbs  0.000176  0.000321  0.000198  0.000770  0.000344\n",
              "130lbs  0.000176  0.000321  0.000198  0.000154  0.001718\n",
              "140lbs  0.000176  0.001607  0.000991  0.000154  0.000344\n",
              "155lbs  0.000176  0.000321  0.000198  0.000770  0.000344\n",
              "20s     0.000879  0.000321  0.000198  0.000154  0.000344\n",
              "25p     0.000176  0.000321  0.000198  0.001386  0.000344\n",
              "26p     0.000176  0.000321  0.000198  0.001386  0.000344\n",
              "32a     0.000176  0.000321  0.000198  0.000154  0.001718"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35c32386-7236-4508-8b6f-df4cc7d3ae71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0p</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120lbs</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.001718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128lbs</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000770</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130lbs</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.001718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140lbs</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.001607</td>\n",
              "      <td>0.000991</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155lbs</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000770</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20s</th>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25p</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.001386</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26p</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.001386</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32a</th>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.001718</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35c32386-7236-4508-8b6f-df4cc7d3ae71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35c32386-7236-4508-8b6f-df4cc7d3ae71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35c32386-7236-4508-8b6f-df4cc7d3ae71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "pb4XaJDyzs-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "629cb662-aefb-4805-9431-bc93e6c2fc7d",
        "id": "PL4uJPtYzs-r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "top    0.026450  0.003203  0.013828  0.010465  0.005127\n",
              "size   0.019982  0.015784  0.014108  0.008337  0.009953\n",
              "wear   0.016738  0.012337  0.016775  0.014853  0.010446\n",
              "dress  0.014766  0.009690  0.023051  0.014681  0.013517\n",
              "fit    0.014228  0.006733  0.021235  0.014215  0.020538\n",
              "work   0.011625  0.002891  0.001167  0.002312  0.004461\n",
              "like   0.011125  0.009965  0.014087  0.018703  0.009028\n",
              "great  0.011056  0.000322  0.007344  0.014031  0.004466\n",
              "color  0.009319  0.004162  0.010527  0.014909  0.003157\n",
              "look   0.009143  0.010168  0.012191  0.020428  0.007998"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-045750e9-28f4-4bb3-9b1f-b2d00badaa1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0.026450</td>\n",
              "      <td>0.003203</td>\n",
              "      <td>0.013828</td>\n",
              "      <td>0.010465</td>\n",
              "      <td>0.005127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>size</th>\n",
              "      <td>0.019982</td>\n",
              "      <td>0.015784</td>\n",
              "      <td>0.014108</td>\n",
              "      <td>0.008337</td>\n",
              "      <td>0.009953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wear</th>\n",
              "      <td>0.016738</td>\n",
              "      <td>0.012337</td>\n",
              "      <td>0.016775</td>\n",
              "      <td>0.014853</td>\n",
              "      <td>0.010446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dress</th>\n",
              "      <td>0.014766</td>\n",
              "      <td>0.009690</td>\n",
              "      <td>0.023051</td>\n",
              "      <td>0.014681</td>\n",
              "      <td>0.013517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fit</th>\n",
              "      <td>0.014228</td>\n",
              "      <td>0.006733</td>\n",
              "      <td>0.021235</td>\n",
              "      <td>0.014215</td>\n",
              "      <td>0.020538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>work</th>\n",
              "      <td>0.011625</td>\n",
              "      <td>0.002891</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.002312</td>\n",
              "      <td>0.004461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0.011125</td>\n",
              "      <td>0.009965</td>\n",
              "      <td>0.014087</td>\n",
              "      <td>0.018703</td>\n",
              "      <td>0.009028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>great</th>\n",
              "      <td>0.011056</td>\n",
              "      <td>0.000322</td>\n",
              "      <td>0.007344</td>\n",
              "      <td>0.014031</td>\n",
              "      <td>0.004466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color</th>\n",
              "      <td>0.009319</td>\n",
              "      <td>0.004162</td>\n",
              "      <td>0.010527</td>\n",
              "      <td>0.014909</td>\n",
              "      <td>0.003157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>look</th>\n",
              "      <td>0.009143</td>\n",
              "      <td>0.010168</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.020428</td>\n",
              "      <td>0.007998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-045750e9-28f4-4bb3-9b1f-b2d00badaa1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-045750e9-28f4-4bb3-9b1f-b2d00badaa1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-045750e9-28f4-4bb3-9b1f-b2d00badaa1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "080a8641-8d07-4fa2-bf47-7f427d3d4c7e",
        "id": "KD5euz64zs-r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
              "topic                                                    \n",
              "3      150.222153  -72.269554       1        1  29.658073\n",
              "0       51.163364 -159.968018       2        1  25.484334\n",
              "2      -73.144554   21.523815       3        1  22.105802\n",
              "1      -66.410133 -110.606438       4        1  11.925791\n",
              "4       54.417324   12.443444       5        1  10.826000, topic_info=        Term       Freq      Total Category  logprob  loglift\n",
              "539  perfect  21.000000  21.000000  Default  30.0000  30.0000\n",
              "697    shirt  15.000000  15.000000  Default  29.0000  29.0000\n",
              "614   really  27.000000  27.000000  Default  28.0000  28.0000\n",
              "474     love  57.000000  57.000000  Default  27.0000  27.0000\n",
              "531     pant  13.000000  13.000000  Default  26.0000  26.0000\n",
              "..       ...        ...        ...      ...      ...      ...\n",
              "466   little   2.559278  20.059564   Topic5  -5.2624   0.1642\n",
              "437     jean   2.544187  23.930117   Topic5  -5.2683  -0.0181\n",
              "863      top   2.531626  63.116616   Topic5  -5.2732  -0.9929\n",
              "739    small   2.296226  38.290171   Topic5  -5.3708  -0.5907\n",
              "677     seem   2.211368  11.177330   Topic5  -5.4085   0.6029\n",
              "\n",
              "[372 rows x 6 columns], token_table=      Topic      Freq    Term\n",
              "term                         \n",
              "0         3  0.569095      0p\n",
              "1         5  0.611391  120lbs\n",
              "7         1  0.762145     25p\n",
              "8         1  0.762145     26p\n",
              "9         5  0.611391     32a\n",
              "...     ...       ...     ...\n",
              "985       3  0.237579   wrong\n",
              "988       2  0.880008     xsp\n",
              "991       2  0.771679    xxsp\n",
              "994       3  0.321147     yes\n",
              "994       5  0.642294     yes\n",
              "\n",
              "[613 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2, 5])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1351398900902007847201117872\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1351398900902007847201117872_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [29.65807252666428, 25.484333874115833, 22.105801951829243, 11.925791237650401, 10.82600040974024]}, \"tinfo\": {\"Term\": [\"perfect\", \"shirt\", \"really\", \"love\", \"pant\", \"wash\", \"length\", \"fit\", \"sweater\", \"white\", \"bit\", \"purchase\", \"cut\", \"size\", \"others\", \"top\", \"much\", \"work\", \"arm\", \"pretty\", \"however\", \"stain\", \"need\", \"design\", \"gorgeous\", \"long\", \"little\", \"pair\", \"hip\", \"lovely\", \"coat\", \"bad\", \"thing\", \"pilcro\", \"stay\", \"inside\", \"typical\", \"sweater\", \"saw\", \"moss\", \"faux\", \"beige\", \"chunky\", \"plan\", \"couple\", \"beach\", \"draw\", \"break\", \"itchy\", \"fade\", \"hei\", \"25p\", \"26p\", \"early\", \"bring\", \"effect\", \"hard\", \"versatile\", \"pic\", \"hope\", \"really\", \"online\", \"super\", \"green\", \"first\", \"cute\", \"pair\", \"wash\", \"look\", \"love\", \"still\", \"great\", \"could\", \"color\", \"sale\", \"jean\", \"store\", \"think\", \"like\", \"model\", \"jacket\", \"much\", \"small\", \"large\", \"soft\", \"retailer\", \"wear\", \"dress\", \"buy\", \"fit\", \"good\", \"top\", \"order\", \"well\", \"size\", \"comfortable\", \"xsp\", \"coral\", \"navy\", \"sm\", \"suit\", \"neutral\", \"reviewer\", \"warm\", \"flowy\", \"xxsp\", \"pm\", \"alteration\", \"generally\", \"barely\", \"baby\", \"happen\", \"cocktail\", \"silk\", \"deep\", \"lay\", \"warmer\", \"date\", \"rich\", \"arrive\", \"winner\", \"center\", \"bell\", \"portion\", \"rack\", \"taller\", \"bra\", \"cozy\", \"sure\", \"jumpsuit\", \"ivory\", \"med\", \"work\", \"extra\", \"cami\", \"top\", \"little\", \"chest\", \"pull\", \"size\", \"oversized\", \"comfortable\", \"wrong\", \"night\", \"room\", \"long\", \"keep\", \"wear\", \"arm\", \"want\", \"beautiful\", \"great\", \"dress\", \"fit\", \"order\", \"fabric\", \"small\", \"like\", \"color\", \"well\", \"much\", \"look\", \"length\", \"pant\", \"love\", \"cute\", \"quality\", \"buy\", \"style\", \"short\", \"tee\", \"skin\", \"pound\", \"open\", \"mid\", \"totally\", \"surprise\", \"brown\", \"seam\", \"orange\", \"cause\", \"blazer\", \"forward\", \"linen\", \"ease\", \"disappointed\", \"hip\", \"hold\", \"comfy\", \"around\", \"nicely\", \"perfect\", \"recommend\", \"usual\", \"eyelet\", \"quintessential\", \"vary\", \"0p\", \"closely\", \"dd\", \"pretty\", \"flatter\", \"shape\", \"purchase\", \"similar\", \"add\", \"lb\", \"skirt\", \"dress\", \"definitely\", \"waist\", \"fit\", \"love\", \"shoulder\", \"big\", \"think\", \"wear\", \"run\", \"34c\", \"order\", \"size\", \"like\", \"top\", \"color\", \"look\", \"blue\", \"large\", \"great\", \"buy\", \"jean\", \"small\", \"quality\", \"base\", \"32dd\", \"customer\", \"narrow\", \"iron\", \"amazing\", \"extremely\", \"bralette\", \"product\", \"ankle\", \"others\", \"clo\", \"clothing\", \"crop\", \"balloon\", \"comical\", \"experience\", \"rating\", \"recently\", \"sit\", \"squish\", \"tiny\", \"defeat\", \"purpose\", \"snuggly\", \"summery\", \"ace\", \"bandage\", \"exceptionally\", \"squeeze\", \"shirt\", \"superb\", \"elegant\", \"kind\", \"white\", \"worry\", \"classic\", \"cut\", \"lovely\", \"probably\", \"need\", \"however\", \"pant\", \"though\", \"design\", \"actually\", \"different\", \"arm\", \"available\", \"material\", \"size\", \"summer\", \"fabric\", \"wear\", \"really\", \"small\", \"look\", \"like\", \"sleeve\", \"dress\", \"short\", \"even\", \"soft\", \"perfect\", \"buy\", \"fit\", \"style\", \"black\", \"remover\", \"let\", \"local\", \"stain\", \"fab\", \"dream\", \"120lbs\", \"scalloped\", \"unzip\", \"32a\", \"comment\", \"espadrilles\", \"void\", \"wrap\", \"cartonnier\", \"colder\", \"prone\", \"unlined\", \"wearable\", \"weighty\", \"anywhere\", \"buyer\", \"dye\", \"removal\", \"result\", \"slight\", \"spray\", \"unwearable\", \"backside\", \"everyone\", \"delicate\", \"armpit\", \"stun\", \"wrinkle\", \"today\", \"yes\", \"never\", \"legging\", \"bit\", \"wash\", \"length\", \"gorgeous\", \"low\", \"lace\", \"otherwise\", \"care\", \"dark\", \"fit\", \"worth\", \"absolutely\", \"perfect\", \"enough\", \"petite\", \"well\", \"quality\", \"long\", \"dress\", \"love\", \"pant\", \"much\", \"buy\", \"wear\", \"size\", \"right\", \"like\", \"short\", \"look\", \"little\", \"jean\", \"top\", \"small\", \"seem\"], \"Freq\": [21.0, 15.0, 27.0, 57.0, 13.0, 10.0, 17.0, 70.0, 23.0, 11.0, 14.0, 18.0, 10.0, 62.0, 6.0, 63.0, 22.0, 21.0, 17.0, 14.0, 10.0, 4.0, 9.0, 11.0, 10.0, 16.0, 20.0, 9.0, 10.0, 6.0, 4.375955928076234, 3.5317611737622583, 6.037759783045175, 2.7089116770411947, 2.7089105566985556, 2.706589024458695, 2.6716004412867296, 17.49492639820346, 7.70888257932288, 1.8753947671175435, 1.8753937511325895, 1.8753898427814004, 1.8753885044110032, 1.8753861999998485, 1.875385874508801, 1.8753853441402721, 1.8753849731201213, 1.8753830648951606, 1.8753810079411626, 1.8753794208367869, 1.8753776100104855, 1.8753766070337274, 1.8753766070337274, 1.8753490470996281, 1.8753229536345908, 1.875316393882652, 1.8718933902934352, 1.8638557990071491, 1.8629419703263075, 3.54238810483161, 18.54018062299524, 8.978002779548746, 8.972208661465181, 3.4532243138335175, 4.811740180741895, 13.912457505846673, 5.91398781278972, 6.221730398915446, 27.633688950352358, 26.487375410388406, 7.499727653963455, 18.97952563869451, 8.326500041684579, 20.16740776853021, 7.532176781746246, 11.713523627498441, 5.9618684586773245, 11.761137970114033, 25.300266877491232, 4.383131948936083, 7.714042260865692, 10.404516111928887, 15.365605347993888, 11.987354611643559, 8.749028410226844, 8.899277876293564, 20.091889953883513, 19.85896720384475, 11.401510951726737, 19.228565941813596, 8.609915704007102, 14.156701236720906, 10.295181864929248, 8.795887241654938, 11.277182694126138, 7.7104788848670545, 2.656229366346353, 2.6562272691881916, 2.6562207720730164, 2.656218493991523, 2.656203208061444, 2.644845824890468, 5.0591820164610315, 5.029234269823493, 4.292427579164153, 1.8389176310616042, 1.8389154505087435, 1.8389131682251239, 1.8389124593185484, 1.8389121896151004, 1.8389115714608935, 1.8389112046133045, 1.8389108224621642, 1.8389088065617336, 1.838908445487856, 1.8389079138384308, 1.8389078810182264, 1.838907376948983, 1.8389050955605752, 1.8389041388618415, 1.8388691404237651, 1.8388559355994583, 1.8388550902025675, 1.833572458080066, 1.8336727870550305, 1.8322869436256195, 3.474388283081511, 3.4593553133285555, 5.111787098342895, 3.4748542787415904, 3.476392204955223, 3.4754520729606053, 13.51182631642113, 3.4254780829906086, 4.2941758460050465, 30.743823357724885, 10.486323150122779, 4.782300577617858, 2.6574413737235747, 23.22642491566028, 2.6554918961865, 9.204685471272679, 2.6572780422455966, 2.6605672013645267, 2.6576509220311086, 7.281319011497947, 5.423927586922654, 19.455126045604988, 7.290306254114689, 6.225254621946401, 5.9275802831231, 12.8511152892919, 17.16310957072821, 16.53779603685903, 10.212239025455126, 8.278418179065072, 10.164886096922316, 12.930885279765931, 10.831742448072417, 7.905937902037676, 6.920264922518874, 10.62758477948186, 5.670463843343743, 5.093835334398259, 8.102221408024944, 5.952496467689475, 5.415031038183157, 5.3277936328329725, 5.112622236499941, 5.108638142266185, 4.199641009231156, 2.5991580813635164, 2.597673963996227, 2.595973494566747, 1.8000729008383614, 1.8000721471514134, 1.8000704903910298, 1.8000703278459254, 1.8000685196089083, 1.8000685091878537, 1.8000634338667996, 1.800061660244925, 1.7991043074253283, 3.3979548349466215, 1.794302944280338, 1.781314868297215, 7.162986707836607, 3.4022637018941566, 2.600513894388637, 5.785532134097574, 3.389271251636853, 12.692752130027916, 3.3499460689374443, 3.785872944535252, 1.0000265671276296, 1.0000265671276296, 1.0000265671276296, 1.000025815753632, 1.000025815753632, 1.000025815753632, 8.114214637405341, 4.952936210281607, 5.807844446627529, 9.811636496984262, 1.8029882913269448, 1.7998882087988664, 7.410326406288524, 6.890079895686272, 23.240807808836262, 5.56644918093404, 7.840694724801702, 21.41054788836841, 17.366022862692432, 4.901324238037537, 7.090564825402996, 8.619109659267869, 16.913639695451014, 7.3479489343774285, 3.401447825761623, 10.059891223042978, 14.223881591828246, 14.20287259997957, 13.942033196716665, 10.613700423605113, 12.291376499685644, 4.823732212569319, 6.602750107998599, 7.404454387997787, 6.253440971269294, 5.402882562017468, 5.386590713852564, 4.996232085038182, 2.272285169133916, 2.2722712630781197, 1.5731159494899034, 1.5731140084049993, 1.573113184050815, 1.5731129706238274, 1.5731077043950477, 1.5731013997157155, 1.5674885602333248, 2.2724353214704016, 3.676679175113016, 0.8739460999440293, 0.8739460999440293, 0.8739460999440293, 0.8739444225983348, 0.8739444225983348, 0.8739444225983348, 0.8739444225983348, 0.8739444225983348, 0.8739444225983348, 0.8739438847581226, 0.8739438847581226, 0.8739436347259559, 0.8739436347259559, 0.8739436347259559, 0.8739436347259559, 0.8739431012317925, 0.8739431012317925, 0.8739431012317925, 0.8739431012317925, 7.640639076355919, 1.5754273799174694, 1.5698757387836464, 2.273696267312406, 5.084719802096197, 1.5739435752055637, 1.5687011678739635, 4.384616384726721, 2.975144823561152, 2.114958093619676, 3.67101834653677, 3.6791744770067045, 4.379522238551648, 2.980447792924059, 3.3161143822709165, 1.5740568608137044, 1.5706896475732208, 4.394230512146704, 1.5780469416955398, 3.9437527038572955, 8.585610109786236, 2.9799621618341368, 4.378436810472714, 6.7106550127958435, 4.380287154572656, 5.076862300030648, 5.530607555120845, 5.420550803901549, 2.711151518023472, 5.270608649502898, 2.9786917683744325, 2.973145588186212, 2.9746152986059644, 2.9724471178923966, 3.177393603216437, 3.662446290265908, 2.4658079657393452, 2.2808256607955384, 1.5265680805630286, 1.5265623782433304, 1.5200030139727978, 2.8988413547554086, 1.5021856352511127, 2.206165691506297, 0.8480882435648209, 0.8480882435648209, 0.8480882435648209, 0.8480879520513048, 0.8480879520513048, 0.8480879520513048, 0.8480879520513048, 0.8480879520513048, 0.8480866768928041, 0.8480866768928041, 0.8480866768928041, 0.8480866768928041, 0.8480866768928041, 0.8480866768928041, 0.8480862284535652, 0.8480862284535652, 0.8480862284535652, 0.8480862284535652, 0.8480862284535652, 0.8480862284535652, 0.8480862284535652, 0.8480862284535652, 0.8480842491090668, 0.8480842491090668, 1.5283696099035466, 1.5271548059321538, 2.207898772414396, 2.2093133665682005, 2.1990837292598955, 1.5282436395983952, 1.5265877083615822, 1.4398577000415067, 4.460365333916143, 3.4150496697040444, 5.226665574824985, 3.3684473374179524, 2.2066250605838653, 2.2113353273352407, 1.528169087003872, 1.5290327125787904, 2.2070568726045, 10.14101645961623, 2.212435651357759, 2.2007485945790903, 4.4267348997587685, 2.2143522250448107, 2.890167913912701, 4.344980760965431, 3.5717914025803372, 3.2143847013051277, 6.674528676597469, 5.83237401160459, 2.888449881252791, 3.5691715645241953, 3.8617388721466845, 5.158170839004665, 4.914775471079788, 2.8916588884360195, 4.457578671256176, 2.8873879519172068, 3.9490588006065606, 2.5592775179833924, 2.5441871892377694, 2.5316260698961046, 2.296226233329446, 2.2113676723010283], \"Total\": [21.0, 15.0, 27.0, 57.0, 13.0, 10.0, 17.0, 70.0, 23.0, 11.0, 14.0, 18.0, 10.0, 62.0, 6.0, 63.0, 22.0, 21.0, 17.0, 14.0, 10.0, 4.0, 9.0, 11.0, 10.0, 16.0, 20.0, 9.0, 10.0, 6.0, 5.124746922579897, 4.289504542763565, 7.590703714379088, 3.457699369783997, 3.4576993017667386, 3.4576055907118706, 3.456192891987149, 23.29113695398136, 10.771805842483127, 2.6241763221335956, 2.624176213020976, 2.6241757684954465, 2.6241756250108956, 2.6241753235575627, 2.6241752817544794, 2.624175236426837, 2.6241751982493366, 2.6241749419971923, 2.624174700658654, 2.6241743452875217, 2.62417441656993, 2.624174125990705, 2.624174125990705, 2.6241710664690703, 2.6241676578413524, 2.6241666029977186, 2.624105403089616, 2.62231887249516, 2.6239293414546854, 4.990386720579883, 27.573513137472734, 13.328953276883915, 13.644721278324509, 5.106176119964089, 7.539135001396464, 25.11209326102859, 9.6413716632464, 10.217709762000279, 60.03231658524726, 57.96742712066019, 13.289285555119486, 41.61569976609784, 15.497938555377045, 45.43548411413609, 13.873528575269534, 23.930116714680864, 10.605578091970099, 24.380877905309298, 62.31215423239446, 7.405465234592171, 14.928127740864731, 22.345327084846787, 38.29017069212887, 27.29795729170886, 18.550463748024942, 20.245319337298792, 68.32948154674003, 72.2080219095096, 30.021878031192127, 70.98037261692316, 19.381212298722627, 63.11661602216628, 33.91124553266694, 26.11883914593086, 62.22787478248069, 20.206634656511945, 3.409061053889967, 3.4090608445600386, 3.409060321633753, 3.4090599929230914, 3.4090583879761818, 3.4092779695893545, 6.660059537349334, 6.69607530968736, 5.74308133913265, 2.5917503846248895, 2.5917501669702196, 2.5917499270136, 2.5917499074680093, 2.591749852956994, 2.591749727997069, 2.5917497849445335, 2.5917496710868115, 2.591749567237898, 2.5917494598132915, 2.5917494273047916, 2.59174956643779, 2.591749444373639, 2.5917491277266356, 2.591749171593575, 2.591745166183716, 2.5917441908992607, 2.591744323044532, 2.5916338142053204, 2.5918512417227335, 2.591603969843785, 4.9256658213438, 4.925833874068202, 7.3603479602978705, 5.026440757193704, 5.059829764054381, 5.059851936888159, 21.590660991397755, 5.025396897848605, 6.5763544336198665, 63.11661602216628, 20.059564219509635, 8.331683200154076, 4.0877509991319725, 62.22787478248069, 4.108126672157567, 20.206634656511945, 4.20912288597266, 4.242483098427691, 4.2425511524840465, 16.722191279170815, 11.430119353642887, 68.32948154674003, 17.29044876792561, 13.947062132498713, 13.091011123482, 41.61569976609784, 72.2080219095096, 70.98037261692316, 33.91124553266694, 26.02547198744082, 38.29017069212887, 62.31215423239446, 45.43548411413609, 26.11883914593086, 22.345327084846787, 60.03231658524726, 17.900270239264323, 13.567685922397475, 57.96742712066019, 25.11209326102859, 20.434195543092596, 30.021878031192127, 15.13236224053915, 17.074279377837062, 4.9573814854843175, 3.357307165074771, 3.3573196650450017, 3.357130415946539, 2.5572221340978, 2.55722216138321, 2.5572219791010147, 2.5572219625401904, 2.557221896958474, 2.557221957261822, 2.557221491505029, 2.557221110377215, 2.5572599290916633, 4.835879043102276, 2.5563456770329083, 2.558000588800188, 10.492638710968242, 4.99074496571916, 4.056591115571514, 9.035626123010614, 5.690027883359528, 21.429057319398865, 5.824644307853027, 6.617073840709074, 1.757176112353535, 1.757176112353535, 1.757176112353535, 1.7571759972266245, 1.7571759972266245, 1.7571759972266245, 14.779695155603983, 8.951019425704786, 10.537331603172701, 18.875458715984312, 3.2361557761678195, 3.235679298472451, 14.621919455200343, 13.939794571757279, 72.2080219095096, 11.530223204718228, 18.221580075315416, 70.98037261692316, 57.96742712066019, 10.412645929912653, 17.543518316830102, 24.380877905309298, 68.32948154674003, 20.694014134275896, 6.609212190339346, 33.91124553266694, 62.22787478248069, 62.31215423239446, 63.11661602216628, 45.43548411413609, 60.03231658524726, 11.392175766467224, 27.29795729170886, 41.61569976609784, 30.021878031192127, 23.930116714680864, 38.29017069212887, 20.434195543092596, 3.0546410054082718, 3.054642173273029, 2.3554719895524943, 2.355472198738196, 2.35547221403783, 2.3554722612639343, 2.3554726789660565, 2.3554731592181275, 2.356536130089949, 3.733204320885763, 6.086763357733112, 1.6563030142785837, 1.6563030142785837, 1.6563030142785837, 1.656303151126309, 1.656303151126309, 1.656303151126309, 1.656303151126309, 1.656303151126309, 1.656303151126309, 1.6563032067533916, 1.6563032067533916, 1.6563031934400032, 1.6563031934400032, 1.6563031934400032, 1.6563031934400032, 1.6563033154834177, 1.6563033154834177, 1.6563033154834177, 1.6563033154834177, 15.241839847310795, 3.0340282156919534, 3.034923079774377, 4.6890216713688835, 11.362463205032924, 3.1553965498047916, 3.156380150026063, 10.732068863940441, 6.98809311328762, 4.735742318675723, 9.893987132394216, 10.037631230566886, 13.567685922397475, 8.680910547051111, 11.114518685255844, 3.833835353367064, 3.852178700664297, 17.29044876792561, 3.9720033382003272, 17.39116095349451, 62.22787478248069, 11.936641449408986, 26.02547198744082, 68.32948154674003, 27.573513137472734, 38.29017069212887, 60.03231658524726, 62.31215423239446, 10.194904092510528, 72.2080219095096, 17.074279377837062, 17.39714525733061, 18.550463748024942, 21.429057319398865, 30.021878031192127, 70.98037261692316, 15.13236224053915, 14.30758097483394, 2.3140951257914173, 2.314095959468623, 2.3155921723808106, 4.468354305421399, 2.318462874283377, 3.6917162555377683, 1.635614637443573, 1.635614637443573, 1.635614637443573, 1.635614672930659, 1.635614672930659, 1.635614672930659, 1.635614672930659, 1.635614672930659, 1.6356148209111363, 1.6356148209111363, 1.6356148209111363, 1.6356148209111363, 1.6356148209111363, 1.6356148209111363, 1.635614924350393, 1.635614924350393, 1.635614924350393, 1.635614924350393, 1.635614924350393, 1.635614924350393, 1.635614924350393, 1.635614924350393, 1.6356151863759092, 1.6356151863759092, 3.013214565116183, 3.013247914132656, 4.5086076184806565, 4.609093749571123, 4.644214382692915, 3.113839691309914, 3.1314242681411266, 3.166101488673876, 14.456569591028675, 10.217709762000279, 17.900270239264323, 10.11299777536335, 6.057410717675868, 6.2433083299985475, 3.8131271380916587, 3.980506932758769, 6.944268541727366, 70.98037261692316, 7.059274710722963, 7.099803815362362, 21.429057319398865, 7.708526736464833, 12.639636655743232, 26.11883914593086, 20.434195543092596, 16.722191279170815, 72.2080219095096, 57.96742712066019, 13.567685922397475, 22.345327084846787, 30.021878031192127, 68.32948154674003, 62.22787478248069, 15.62132944186069, 62.31215423239446, 17.074279377837062, 60.03231658524726, 20.059564219509635, 23.930116714680864, 63.11661602216628, 38.29017069212887, 11.177329891543248], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.7337, -5.9481, -5.4118, -6.2133, -6.2133, -6.2142, -6.2272, -4.348, -5.1675, -6.581, -6.581, -6.581, -6.581, -6.581, -6.581, -6.581, -6.581, -6.581, -6.581, -6.5811, -6.5811, -6.5811, -6.5811, -6.5811, -6.5811, -6.5811, -6.5829, -6.5872, -6.5877, -5.9451, -4.2899, -5.0151, -5.0157, -5.9706, -5.6388, -4.5771, -5.4325, -5.3818, -3.8908, -3.9332, -5.195, -4.2665, -5.0904, -4.2058, -5.1907, -4.7491, -5.4245, -4.7451, -3.979, -5.7321, -5.1668, -4.8676, -4.4777, -4.726, -5.0409, -5.0239, -4.2095, -4.2212, -4.7761, -4.2535, -5.0569, -4.5597, -4.8782, -5.0356, -4.7871, -5.1673, -6.0813, -6.0813, -6.0813, -6.0813, -6.0813, -6.0856, -5.437, -5.4429, -5.6013, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.449, -6.4519, -6.4519, -6.4526, -5.8128, -5.8171, -5.4266, -5.8126, -5.8122, -5.8125, -4.4546, -5.8269, -5.6009, -3.6325, -4.7081, -5.4933, -6.0808, -3.9129, -6.0816, -4.8385, -6.0809, -6.0797, -6.0807, -5.0729, -5.3674, -4.0901, -5.0716, -5.2296, -5.2786, -4.5048, -4.2154, -4.2525, -4.7346, -4.9445, -4.7393, -4.4986, -4.6757, -4.9906, -5.1237, -4.6947, -5.3229, -5.4302, -4.9661, -5.2744, -5.369, -5.3853, -5.4265, -5.4273, -5.481, -5.9608, -5.9614, -5.962, -6.3281, -6.3281, -6.3281, -6.3281, -6.3281, -6.3281, -6.3281, -6.3281, -6.3287, -5.6928, -6.3314, -6.3386, -4.947, -5.6915, -5.9603, -5.1606, -5.6954, -4.3749, -5.707, -5.5847, -6.9159, -6.9159, -6.9159, -6.9159, -6.9159, -6.9159, -4.8223, -5.316, -5.1568, -4.6324, -6.3265, -6.3282, -4.9131, -4.9859, -3.7701, -5.1992, -4.8566, -3.8521, -4.0615, -5.3265, -4.9572, -4.762, -4.0878, -4.9215, -5.6918, -4.6074, -4.261, -4.2625, -4.2811, -4.5538, -4.4071, -5.3424, -5.0285, -4.9139, -5.0828, -5.229, -5.2321, -5.3073, -5.478, -5.4781, -5.8458, -5.8458, -5.8458, -5.8458, -5.8458, -5.8458, -5.8494, -5.478, -4.9968, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -6.4336, -4.2653, -5.8443, -5.8478, -5.4774, -4.6726, -5.8452, -5.8486, -4.8207, -5.2085, -5.5498, -4.9984, -4.9961, -4.8219, -5.2068, -5.1, -5.8452, -5.8473, -4.8185, -5.8426, -4.9267, -4.1487, -5.2069, -4.8221, -4.3951, -4.8217, -4.6741, -4.5885, -4.6086, -5.3015, -4.6367, -5.2073, -5.2092, -5.2087, -5.2094, -5.1428, -5.0007, -5.3963, -5.4743, -5.7791, -5.7791, -5.7834, -5.1378, -5.7952, -5.4108, -6.3668, -6.3668, -6.3668, -6.3668, -6.3668, -6.3668, -6.3668, -6.3668, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -6.3669, -5.7779, -5.7787, -5.41, -5.4094, -5.414, -5.778, -5.779, -5.8375, -4.7068, -4.9739, -4.5483, -4.9876, -5.4106, -5.4085, -5.778, -5.7774, -5.4104, -3.8855, -5.408, -5.4133, -4.7144, -5.4071, -5.1408, -4.7331, -4.929, -5.0344, -4.3038, -4.4387, -5.1414, -4.9297, -4.851, -4.5615, -4.6098, -5.1402, -4.7075, -5.1417, -4.8286, -5.2624, -5.2683, -5.2732, -5.3708, -5.4085], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0575, 1.0211, 0.9865, 0.9714, 0.9714, 0.9705, 0.9579, 0.9293, 0.8809, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8795, 0.8794, 0.8776, 0.874, 0.8729, 0.8727, 0.8185, 0.8203, 0.7962, 0.8243, 0.7664, 0.6249, 0.7267, 0.7194, 0.4396, 0.4322, 0.6433, 0.4303, 0.5942, 0.4032, 0.6046, 0.501, 0.6394, 0.4864, 0.3141, 0.691, 0.5552, 0.4511, 0.3024, 0.3925, 0.4639, 0.3935, -0.0086, -0.0755, 0.2473, -0.0906, 0.404, -0.2794, 0.0234, 0.1271, -0.4926, 0.252, 1.1176, 1.1176, 1.1176, 1.1176, 1.1176, 1.1132, 1.0922, 1.0809, 1.076, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0239, 1.0211, 1.0211, 1.0204, 1.0181, 1.0137, 1.0025, 0.9979, 0.9918, 0.9915, 0.8984, 0.9838, 0.9409, 0.6478, 0.7185, 0.812, 0.9365, 0.3816, 0.9308, 0.5808, 0.9072, 0.9005, 0.8994, 0.5357, 0.6217, 0.1109, 0.5035, 0.5605, 0.5748, 0.1921, -0.0697, -0.0896, 0.1669, 0.2217, 0.0409, -0.2054, -0.0667, 0.1721, 0.1949, -0.3643, 0.2176, 0.3874, -0.6006, -0.0724, 0.0391, -0.3619, 0.282, 0.1605, 1.3435, 1.2534, 1.2528, 1.2522, 1.1582, 1.1582, 1.1582, 1.1582, 1.1582, 1.1582, 1.1582, 1.1582, 1.1577, 1.1564, 1.1554, 1.1475, 1.1276, 1.1262, 1.0647, 1.0635, 0.9912, 0.9856, 0.9562, 0.951, 0.9456, 0.9456, 0.9456, 0.9456, 0.9456, 0.9456, 0.9097, 0.9175, 0.9136, 0.855, 0.9244, 0.9228, 0.8297, 0.8047, 0.3757, 0.7811, 0.6661, 0.3108, 0.304, 0.7558, 0.6034, 0.4695, 0.1131, 0.4739, 0.8451, 0.2941, 0.0334, 0.0306, -0.0007, 0.0552, -0.0767, 0.65, 0.09, -0.2171, -0.0595, 0.0211, -0.452, 0.1008, 1.8306, 1.8306, 1.7228, 1.7228, 1.7228, 1.7228, 1.7228, 1.7228, 1.7187, 1.6301, 1.6224, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4871, 1.4359, 1.4711, 1.4673, 1.4026, 1.3224, 1.4309, 1.4273, 1.2313, 1.2726, 1.3204, 1.135, 1.1228, 0.9957, 1.0574, 0.917, 1.2363, 1.2293, 0.7566, 1.2034, 0.6426, 0.1458, 0.7388, 0.3441, -0.1942, 0.2867, 0.106, -0.2581, -0.3155, 0.802, -0.4909, 0.3804, 0.3598, 0.2961, 0.1511, -0.1194, -0.8378, 0.3122, 0.2902, 1.8072, 1.8072, 1.8023, 1.7905, 1.7892, 1.7084, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5664, 1.5444, 1.5436, 1.5093, 1.4879, 1.4756, 1.5115, 1.5048, 1.4353, 1.0473, 1.1273, 0.9922, 1.1238, 1.2134, 1.1853, 1.3088, 1.2664, 1.077, 0.2774, 1.063, 1.0519, 0.6461, 0.9759, 0.7477, 0.4296, 0.4791, 0.5741, -0.158, -0.0732, 0.6762, 0.3889, 0.1724, -0.3605, -0.3153, 0.5364, -0.4143, 0.446, -0.4982, 0.1642, -0.0181, -0.9929, -0.5907, 0.6029]}, \"token.table\": {\"Topic\": [3, 5, 1, 1, 5, 4, 2, 3, 1, 2, 5, 4, 3, 4, 5, 3, 5, 2, 4, 4, 5, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 2, 2, 3, 4, 2, 5, 1, 4, 4, 2, 4, 1, 1, 2, 3, 5, 1, 2, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 5, 2, 4, 4, 1, 1, 3, 1, 2, 3, 4, 5, 5, 1, 2, 4, 1, 5, 5, 3, 2, 1, 2, 3, 1, 3, 4, 4, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 3, 4, 4, 5, 2, 1, 2, 4, 5, 1, 2, 4, 4, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 4, 2, 4, 5, 3, 1, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 1, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 5, 4, 4, 2, 3, 4, 3, 5, 1, 2, 3, 4, 5, 1, 1, 1, 3, 1, 2, 3, 4, 5, 1, 3, 4, 2, 4, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 2, 1, 1, 1, 2, 3, 5, 1, 3, 1, 4, 1, 3, 4, 5, 1, 4, 1, 1, 2, 1, 2, 3, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 5, 2, 4, 2, 3, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 5, 1, 5, 1, 2, 3, 5, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 5, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 4, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 3, 5, 1, 1, 2, 4, 5, 4, 2, 1, 2, 3, 4, 5, 2, 2, 5, 1, 3, 4, 1, 2, 1, 2, 3, 3, 3, 1, 2, 3, 4, 5, 2, 4, 3, 4, 5, 2, 4, 1, 2, 5, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 5, 1, 1, 1, 2, 2, 3, 1, 2, 3, 1, 2, 4, 4, 5, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 3, 2, 4, 1, 2, 4, 4, 1, 3, 5, 5, 5, 1, 2, 3, 4, 5, 2, 3, 2, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 5, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 2, 3, 5, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 4, 4, 3, 5, 1, 1, 2, 3, 1, 2, 3, 4, 2, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 4, 1, 3, 4, 5, 4, 5, 2, 3, 4, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 1, 2, 5, 1, 2, 3, 4, 5, 3, 1, 5, 5, 5, 1, 2, 3, 3, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 2, 1, 5, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 5, 5, 2, 3, 5, 2, 3, 2, 2, 3, 5], \"Freq\": [0.5690949578063403, 0.6113909579355296, 0.7621445468085848, 0.7621445468085848, 0.611390944670496, 0.6547411731230742, 0.45391189049507075, 0.45391189049507075, 0.14084896231022992, 0.4225468869306898, 0.28169792462045984, 0.6037541497694427, 0.2608354057567314, 0.5216708115134628, 0.2608354057567314, 0.6181082287556096, 0.3090541143778048, 0.7716793889542203, 0.8490866281425918, 0.5357327989820465, 0.26786639949102325, 0.6113908506900937, 0.23134159521759437, 0.40484779163079015, 0.05783539880439859, 0.23134159521759437, 0.05783539880439859, 0.331867814563092, 0.663735629126184, 0.22134603322139368, 0.11067301661069684, 0.664038099664181, 0.7716796138764735, 0.25176212476525495, 0.25176212476525495, 0.5035242495305099, 0.7716794482103103, 0.6113907527452931, 0.9325086289389851, 0.6037542096807497, 0.6037541497694427, 0.771679411004171, 0.6547414234468079, 0.7621442243023624, 0.30555317402679466, 0.45832976104019196, 0.22916488052009598, 0.07638829350669867, 0.7621440697726916, 0.7716810575090186, 0.17100332703058752, 0.22800443604078333, 0.3990077630713708, 0.11400221802039166, 0.05700110901019583, 0.2075181100958911, 0.3458635168264852, 0.13834540673059406, 0.2766908134611881, 0.13978603395765252, 0.34946508489413125, 0.27957206791530503, 0.13978603395765252, 0.06989301697882626, 0.7820989713732578, 0.26333863359363496, 0.26333863359363496, 0.4388977226560583, 0.08777954453121166, 0.6090547164203585, 0.20301823880678616, 0.8490863044535295, 0.7621443098141358, 0.7621464253717712, 0.7820987107483311, 0.3663994633703868, 0.1665452106229031, 0.1998542527474837, 0.09992712637374185, 0.13323616849832248, 0.6113908506900937, 0.1520599307859329, 0.6082397231437316, 0.1520599307859329, 0.5024485659201856, 0.5024485659201856, 0.6113908893555633, 0.782098854809373, 0.7716810968547237, 0.24004753324790534, 0.6001188331197633, 0.12002376662395267, 0.762144111445169, 0.31681861894605523, 0.6336372378921105, 0.6037542595643697, 0.5690949578063403, 0.6037542595643697, 0.7805263480184349, 0.7716794651550317, 0.6113908893555633, 0.4401845911833811, 0.24210152515085961, 0.24210152515085961, 0.044018459118338106, 0.044018459118338106, 0.3959095681190959, 0.4453982641339829, 0.09897739202977397, 0.09897739202977397, 0.7395371913339469, 0.24651239711131565, 0.6037542096807497, 0.611390944670496, 0.8800077607260101, 0.5161976847059044, 0.3226235529411903, 0.06452471058823805, 0.06452471058823805, 0.7621442111377689, 0.6090339375416912, 0.20301131251389706, 0.6037542595643697, 0.8490867260875266, 0.1863573580598205, 0.2795360370897308, 0.372714716119641, 0.09317867902991026, 0.5575003188494275, 0.23892870807832609, 0.07964290269277537, 0.07964290269277537, 0.07964290269277537, 0.43201094283340585, 0.1440036476111353, 0.1440036476111353, 0.2880072952222706, 0.7716795326576602, 0.5690949578063403, 0.7716795280605862, 0.6037541942565984, 0.3469143596771985, 0.17345717983859926, 0.5203715395157978, 0.3318714875392361, 0.6637429750784722, 0.3598896284466433, 0.3598896284466433, 0.26991722133498247, 0.259593356826243, 0.519186713652486, 0.259593356826243, 0.7818606488038714, 0.7621442353903268, 0.27087672258125134, 0.5417534451625027, 0.2769775361671562, 0.23543090574208275, 0.3185241665922296, 0.06924438404178905, 0.09694213765850467, 0.6113908506900937, 0.7621454353930828, 0.7823668050720567, 0.7621467317339145, 0.6589952850299865, 0.32949764251499325, 0.12972647487483513, 0.25945294974967026, 0.12972647487483513, 0.12972647487483513, 0.25945294974967026, 0.611390944670496, 0.40236486483610984, 0.17244208492976135, 0.17244208492976135, 0.17244208492976135, 0.11496138995317423, 0.6113907527452931, 0.6037541497694427, 0.6037542096807497, 0.5969677740845332, 0.19898925802817774, 0.8490864775718424, 0.5690949205202973, 0.8626405116011133, 0.2689672642009339, 0.3073911590867816, 0.1536955795433908, 0.1536955795433908, 0.0768477897716954, 0.7621444831177431, 0.7621439406683675, 0.6632060573360016, 0.26528242293440063, 0.26767963169962306, 0.2395028283628206, 0.29585643503642545, 0.056353606673604846, 0.14088401668401213, 0.3351573555281147, 0.5585955925468579, 0.11171911850937156, 0.6964902225473444, 0.1741225556368361, 0.7820870992611214, 0.7716793947738133, 0.4643672367488163, 0.20638543855502947, 0.20638543855502947, 0.05159635963875737, 0.10319271927751474, 0.19776529614910768, 0.2966479442236615, 0.19776529614910768, 0.2966479442236615, 0.45655846487719803, 0.3123821075475566, 0.16820575021791506, 0.04805878577654717, 0.5875238004953692, 0.19584126683178973, 0.7716794312545114, 0.7621645066715705, 0.7621444624150435, 0.09530491114257776, 0.09530491114257776, 0.6671343779980443, 0.09530491114257776, 0.20037088788725577, 0.6011126636617673, 0.8015410876885309, 0.20038527192213273, 0.2988752954844877, 0.19925019698965848, 0.39850039397931697, 0.09962509849482924, 0.8676524610148909, 0.8490866451663773, 0.7621443799065704, 0.19763510762834677, 0.5929053228850403, 0.5359010948238704, 0.20096291055895138, 0.20096291055895138, 0.5014601534575104, 0.0835766922429184, 0.20894173060729598, 0.0835766922429184, 0.1253650383643776, 0.5968437996024288, 0.1989479332008096, 0.17497630060727065, 0.43744075151817663, 0.262464450910906, 0.08748815030363533, 0.42652820570482297, 0.42652820570482297, 0.48051447108342604, 0.160171490361142, 0.320342980722284, 0.43959333190270355, 0.14653111063423452, 0.2564294436099104, 0.07326555531711726, 0.07326555531711726, 0.7716795377398181, 0.27356189536233455, 0.2051714215217509, 0.47873331688408544, 0.06839047384058364, 0.3158458449854843, 0.3158458449854843, 0.2234603135334785, 0.33519047030021776, 0.16759523515010888, 0.27932539191684813, 0.8642683946690147, 0.4012058370949909, 0.20862703528939527, 0.2246752687731949, 0.08024116741899819, 0.06419293393519854, 0.6203629109125656, 0.2067876369708552, 0.14955459486414188, 0.4985153162138063, 0.1994061264855225, 0.14955459486414188, 0.8637099502472709, 0.23920310043232226, 0.41860542575656395, 0.11960155021616113, 0.1794023253242417, 0.46641545075541707, 0.18323464136819956, 0.19989233603803588, 0.09994616801901794, 0.06663077867934529, 0.4485277558702158, 0.13800854026775872, 0.29326814806898727, 0.10350640520081902, 0.28620110916911917, 0.28620110916911917, 0.42930166375367873, 0.3301740782020751, 0.3301740782020751, 0.3301740782020751, 0.4025033187099248, 0.2300018964056713, 0.11500094820283566, 0.2300018964056713, 0.05750047410141783, 0.19763424156933065, 0.5929027247079919, 0.7820986582792931, 0.5401416215304514, 0.2700708107652257, 0.13503540538261286, 0.762143908978606, 0.4475208602688738, 0.31326460218821167, 0.04475208602688738, 0.1790083441075495, 0.8490866506814986, 0.8800078957131168, 0.10107148782575918, 0.30321446347727754, 0.10107148782575918, 0.40428595130303674, 0.20214297565151837, 0.879951716099391, 0.3193435045432598, 0.6386870090865197, 0.17574606320023448, 0.5272381896007033, 0.17574606320023448, 0.23571101564803182, 0.7071330469440955, 0.675221813224335, 0.07502464591381501, 0.22507393774144502, 0.8936203329337009, 0.782098712362663, 0.2948874287252861, 0.2948874287252861, 0.2948874287252861, 0.05897748574505723, 0.029488742872528614, 0.3285818558165301, 0.6571637116330602, 0.26225194277169217, 0.26225194277169217, 0.5245038855433843, 0.7302598579377337, 0.24341995264591124, 0.6223180901605972, 0.10371968169343287, 0.20743936338686575, 0.368522681656864, 0.0737045363313728, 0.2948181453254912, 0.22111360899411842, 0.046665608528413435, 0.6066529108693747, 0.1399968255852403, 0.18666243411365374, 0.23734859487727852, 0.23734859487727852, 0.23734859487727852, 0.23734859487727852, 0.7622156467411642, 0.8676289287079954, 0.7621441989968202, 0.7716793175084536, 0.7717139624577963, 0.8935699603569884, 0.33830197087009345, 0.06766039417401869, 0.5412831533921495, 0.21116013767396755, 0.21116013767396755, 0.4223202753479351, 0.8487033041685891, 0.6113908893555633, 0.733899887893623, 0.244633295964541, 0.4238307593142283, 0.05297884491427854, 0.5297884491427854, 0.6037541942565984, 0.24468788063889102, 0.24468788063889102, 0.24468788063889102, 0.09787515225555642, 0.19575030451111283, 0.5690949205202973, 0.771649224231964, 0.6037542096807497, 0.6890670733639224, 0.14506675228714153, 0.14506675228714153, 0.6037542096807497, 0.3433686066123415, 0.5150529099185123, 0.6113908506900937, 0.8642687060308304, 0.6113908506900937, 0.4445471987897433, 0.24697066599430184, 0.19757653279544146, 0.09878826639772073, 0.049394133198860365, 0.7507440394429223, 0.15014880788858448, 0.771679626937623, 0.2560601525553354, 0.2560601525553354, 0.1280300762776677, 0.1280300762776677, 0.19204511441650152, 0.2357072346468922, 0.7071217039406765, 0.2416157622951655, 0.2416157622951655, 0.3382620672132317, 0.0966463049180662, 0.0966463049180662, 0.5766377282172122, 0.07207971602715152, 0.21623914808145456, 0.14415943205430304, 0.7426795578183046, 0.18566988945457616, 0.09283494472728808, 0.6113909579355296, 0.7820987308057911, 0.3578672222089816, 0.2684004166567362, 0.2684004166567362, 0.1789336111044908, 0.18980137242694506, 0.18980137242694506, 0.5694041172808352, 0.09490068621347253, 0.19682663182747634, 0.19682663182747634, 0.13121775455165088, 0.5248710182066035, 0.17570287645018226, 0.2928381274169704, 0.17570287645018226, 0.17570287645018226, 0.17570287645018226, 0.28811120825513037, 0.48018534709188393, 0.1920741388367536, 0.7716794960754859, 0.6180172211513111, 0.30900861057565554, 0.6037542096807497, 0.1767696556961139, 0.3696092800918745, 0.22497956179505404, 0.14462971829682045, 0.08034984349823358, 0.8935732873084273, 0.2152112059153404, 0.2869482745537872, 0.5021594804691276, 0.29426466132269813, 0.29426466132269813, 0.09808822044089939, 0.29426466132269813, 0.09808822044089939, 0.6113908506900937, 0.8800079805658264, 0.3917454461252501, 0.26116363075016674, 0.13058181537508337, 0.13058181537508337, 0.05223272615003335, 0.6037541942565984, 0.4851630731311623, 0.1617210243770541, 0.2156280325027388, 0.1617210243770541, 0.6113908506900937, 0.6037541497694427, 0.6037541894036137, 0.22379604025283142, 0.6713881207584943, 0.8676289457753387, 0.5267401299314666, 0.15049717998041903, 0.22574576997062853, 0.5657400235959638, 0.09429000393266063, 0.18858000786532125, 0.18858000786532125, 0.22179796616166553, 0.22179796616166553, 0.44359593232333105, 0.2643341427080115, 0.33041767838501435, 0.1982506070310086, 0.13216707135400574, 0.06608353567700287, 0.8800083948638313, 0.33510263476985397, 0.16755131738492698, 0.25132697607739046, 0.25132697607739046, 0.6037541942565984, 0.6595957378988064, 0.0732884153220896, 0.1465768306441792, 0.1465768306441792, 0.6591896507936303, 0.32959482539681517, 0.6793157099325032, 0.13586314198650065, 0.13586314198650065, 0.7820987056833819, 0.7298913760023226, 0.08586957364733207, 0.1288043604709981, 0.771722849352077, 0.806877584812139, 0.7904405475126353, 0.13174009125210587, 0.49218900347254607, 0.08203150057875767, 0.36914175260440957, 0.04101575028937884, 0.04101575028937884, 0.3455858672589472, 0.11519528908631574, 0.23039057817263148, 0.3455858672589472, 0.6037541894036137, 0.21532167070637187, 0.21532167070637187, 0.43064334141274374, 0.22181163823933875, 0.4911543418156787, 0.22181163823933875, 0.03168737689133411, 0.04753106533700116, 0.7820986499343465, 0.8680071089073794, 0.6113908893555633, 0.6113908506900937, 0.6113909579355296, 0.15112420143294664, 0.15112420143294664, 0.6044968057317865, 0.5690949205202973, 0.7626837532908353, 0.611390944670496, 0.2195199309536695, 0.10975996547683475, 0.439039861907339, 0.10975996547683475, 0.10975996547683475, 0.3584984387750924, 0.4301981265301109, 0.14339937551003698, 0.07169968775501849, 0.14934121164277797, 0.7467060582138898, 0.7716794963137138, 0.5872157400980437, 0.29360787004902184, 0.2926994255959519, 0.2780644543161543, 0.24879451175655912, 0.10244479895858316, 0.07317485639898798, 0.6113908893555633, 0.6113908893555633, 0.34457886699004153, 0.30629232621337027, 0.15314616310668513, 0.07657308155334257, 0.15314616310668513, 0.17601817175646509, 0.26402725763469764, 0.4400454293911627, 0.08800908587823254, 0.7716808064679264, 0.13894896507315238, 0.648428503674711, 0.046316321691050794, 0.09263264338210159, 0.09263264338210159, 0.3169173776468333, 0.6338347552936666, 0.14165761228713916, 0.2833152245742783, 0.2833152245742783, 0.2833152245742783, 0.611390944670496, 0.21696239094573638, 0.21696239094573638, 0.43392478189147277, 0.7127375658234669, 0.2375791886078223, 0.880007706690028, 0.7716792527029817, 0.32114691157376996, 0.6422938231475399], \"Term\": [\"0p\", \"120lbs\", \"25p\", \"26p\", \"32a\", \"32dd\", \"34c\", \"34c\", \"absolutely\", \"absolutely\", \"absolutely\", \"ace\", \"actually\", \"actually\", \"actually\", \"add\", \"add\", \"alteration\", \"amazing\", \"ankle\", \"ankle\", \"anywhere\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"armpit\", \"armpit\", \"around\", \"around\", \"around\", \"arrive\", \"available\", \"available\", \"available\", \"baby\", \"backside\", \"bad\", \"balloon\", \"bandage\", \"barely\", \"base\", \"beach\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beige\", \"bell\", \"big\", \"big\", \"big\", \"big\", \"big\", \"bit\", \"bit\", \"bit\", \"bit\", \"black\", \"black\", \"black\", \"black\", \"black\", \"blazer\", \"blue\", \"blue\", \"blue\", \"blue\", \"bra\", \"bra\", \"bralette\", \"break\", \"bring\", \"brown\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buyer\", \"cami\", \"cami\", \"cami\", \"care\", \"care\", \"cartonnier\", \"cause\", \"center\", \"chest\", \"chest\", \"chest\", \"chunky\", \"classic\", \"classic\", \"clo\", \"closely\", \"clothing\", \"coat\", \"cocktail\", \"colder\", \"color\", \"color\", \"color\", \"color\", \"color\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfy\", \"comfy\", \"comical\", \"comment\", \"coral\", \"could\", \"could\", \"could\", \"could\", \"couple\", \"cozy\", \"cozy\", \"crop\", \"customer\", \"cut\", \"cut\", \"cut\", \"cut\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"dark\", \"dark\", \"dark\", \"dark\", \"date\", \"dd\", \"deep\", \"defeat\", \"definitely\", \"definitely\", \"definitely\", \"delicate\", \"delicate\", \"design\", \"design\", \"design\", \"different\", \"different\", \"different\", \"disappointed\", \"draw\", \"dream\", \"dream\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"dye\", \"early\", \"ease\", \"effect\", \"elegant\", \"elegant\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"espadrilles\", \"even\", \"even\", \"even\", \"even\", \"even\", \"everyone\", \"exceptionally\", \"experience\", \"extra\", \"extra\", \"extremely\", \"eyelet\", \"fab\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fade\", \"faux\", \"first\", \"first\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"flatter\", \"flatter\", \"flatter\", \"flowy\", \"flowy\", \"forward\", \"generally\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"great\", \"great\", \"great\", \"great\", \"green\", \"green\", \"happen\", \"hard\", \"hei\", \"hip\", \"hip\", \"hip\", \"hip\", \"hold\", \"hold\", \"hope\", \"hope\", \"however\", \"however\", \"however\", \"however\", \"inside\", \"iron\", \"itchy\", \"ivory\", \"ivory\", \"jacket\", \"jacket\", \"jacket\", \"jean\", \"jean\", \"jean\", \"jean\", \"jean\", \"jumpsuit\", \"jumpsuit\", \"keep\", \"keep\", \"keep\", \"keep\", \"kind\", \"kind\", \"lace\", \"lace\", \"lace\", \"large\", \"large\", \"large\", \"large\", \"large\", \"lay\", \"lb\", \"lb\", \"lb\", \"lb\", \"legging\", \"legging\", \"length\", \"length\", \"length\", \"length\", \"let\", \"like\", \"like\", \"like\", \"like\", \"like\", \"linen\", \"linen\", \"little\", \"little\", \"little\", \"little\", \"local\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"lovely\", \"lovely\", \"lovely\", \"low\", \"low\", \"low\", \"material\", \"material\", \"material\", \"material\", \"material\", \"med\", \"med\", \"mid\", \"model\", \"model\", \"model\", \"moss\", \"much\", \"much\", \"much\", \"much\", \"narrow\", \"navy\", \"need\", \"need\", \"need\", \"need\", \"need\", \"neutral\", \"never\", \"never\", \"nicely\", \"nicely\", \"nicely\", \"night\", \"night\", \"online\", \"online\", \"online\", \"open\", \"orange\", \"order\", \"order\", \"order\", \"order\", \"order\", \"others\", \"others\", \"otherwise\", \"otherwise\", \"otherwise\", \"oversized\", \"oversized\", \"pair\", \"pair\", \"pair\", \"pant\", \"pant\", \"pant\", \"pant\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"petite\", \"petite\", \"petite\", \"petite\", \"pic\", \"pilcro\", \"plan\", \"pm\", \"portion\", \"pound\", \"pretty\", \"pretty\", \"pretty\", \"probably\", \"probably\", \"probably\", \"product\", \"prone\", \"pull\", \"pull\", \"purchase\", \"purchase\", \"purchase\", \"purpose\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quintessential\", \"rack\", \"rating\", \"really\", \"really\", \"really\", \"recently\", \"recommend\", \"recommend\", \"removal\", \"remover\", \"result\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"reviewer\", \"reviewer\", \"rich\", \"right\", \"right\", \"right\", \"right\", \"right\", \"room\", \"room\", \"run\", \"run\", \"run\", \"run\", \"run\", \"sale\", \"sale\", \"sale\", \"sale\", \"saw\", \"saw\", \"saw\", \"scalloped\", \"seam\", \"seem\", \"seem\", \"seem\", \"seem\", \"shape\", \"shape\", \"shape\", \"shape\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"short\", \"short\", \"short\", \"short\", \"short\", \"shoulder\", \"shoulder\", \"shoulder\", \"silk\", \"similar\", \"similar\", \"sit\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skin\", \"skirt\", \"skirt\", \"skirt\", \"sleeve\", \"sleeve\", \"sleeve\", \"sleeve\", \"sleeve\", \"slight\", \"sm\", \"small\", \"small\", \"small\", \"small\", \"small\", \"snuggly\", \"soft\", \"soft\", \"soft\", \"soft\", \"spray\", \"squeeze\", \"squish\", \"stain\", \"stain\", \"stay\", \"still\", \"still\", \"still\", \"store\", \"store\", \"store\", \"store\", \"stun\", \"stun\", \"stun\", \"style\", \"style\", \"style\", \"style\", \"style\", \"suit\", \"summer\", \"summer\", \"summer\", \"summer\", \"summery\", \"super\", \"super\", \"super\", \"super\", \"superb\", \"superb\", \"sure\", \"sure\", \"sure\", \"surprise\", \"sweater\", \"sweater\", \"sweater\", \"taller\", \"tee\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"though\", \"though\", \"though\", \"though\", \"tiny\", \"today\", \"today\", \"today\", \"top\", \"top\", \"top\", \"top\", \"top\", \"totally\", \"typical\", \"unlined\", \"unwearable\", \"unzip\", \"usual\", \"usual\", \"usual\", \"vary\", \"versatile\", \"void\", \"waist\", \"waist\", \"waist\", \"waist\", \"waist\", \"want\", \"want\", \"want\", \"want\", \"warm\", \"warm\", \"warmer\", \"wash\", \"wash\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wearable\", \"weighty\", \"well\", \"well\", \"well\", \"well\", \"well\", \"white\", \"white\", \"white\", \"white\", \"winner\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worry\", \"worry\", \"worth\", \"worth\", \"worth\", \"worth\", \"wrap\", \"wrinkle\", \"wrinkle\", \"wrinkle\", \"wrong\", \"wrong\", \"xsp\", \"xxsp\", \"yes\", \"yes\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1351398900902007847201117872\", ldavis_el1351398900902007847201117872_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1351398900902007847201117872\", ldavis_el1351398900902007847201117872_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1351398900902007847201117872\", ldavis_el1351398900902007847201117872_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "IVtPDPtQFWWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "VxFB8PelFWWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "cl-J413pFWWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9a91f238-f975-47e8-d51e-46fc174af16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4\n",
              "Doc_0  0.02815  0.88765  0.02751  0.02819  0.02850\n",
              "Doc_1  0.00927  0.00903  0.96310  0.00932  0.00928\n",
              "Doc_2  0.02541  0.02495  0.02498  0.89951  0.02516\n",
              "Doc_3  0.94904  0.01283  0.01277  0.01282  0.01254\n",
              "Doc_4  0.93822  0.01524  0.01539  0.01623  0.01492"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3008a2e-e30d-479a-bb59-a450acc1aabe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.02815</td>\n",
              "      <td>0.88765</td>\n",
              "      <td>0.02751</td>\n",
              "      <td>0.02819</td>\n",
              "      <td>0.02850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.00927</td>\n",
              "      <td>0.00903</td>\n",
              "      <td>0.96310</td>\n",
              "      <td>0.00932</td>\n",
              "      <td>0.00928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.02541</td>\n",
              "      <td>0.02495</td>\n",
              "      <td>0.02498</td>\n",
              "      <td>0.89951</td>\n",
              "      <td>0.02516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.94904</td>\n",
              "      <td>0.01283</td>\n",
              "      <td>0.01277</td>\n",
              "      <td>0.01282</td>\n",
              "      <td>0.01254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.93822</td>\n",
              "      <td>0.01524</td>\n",
              "      <td>0.01539</td>\n",
              "      <td>0.01623</td>\n",
              "      <td>0.01492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3008a2e-e30d-479a-bb59-a450acc1aabe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3008a2e-e30d-479a-bb59-a450acc1aabe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3008a2e-e30d-479a-bb59-a450acc1aabe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "MCP5EM4rFWWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "xu83FnucFWWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3d8a9189-38a2-4a8f-c9c3-98a32e9c0c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  dominant_topic\n",
              "Doc_0  0.02815  0.88765  0.02751  0.02819  0.02850               1\n",
              "Doc_1  0.00927  0.00903  0.96310  0.00932  0.00928               2\n",
              "Doc_2  0.02541  0.02495  0.02498  0.89951  0.02516               3\n",
              "Doc_3  0.94904  0.01283  0.01277  0.01282  0.01254               0\n",
              "Doc_4  0.93822  0.01524  0.01539  0.01623  0.01492               0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75782ff9-b91f-40d1-9c68-cf2494a5e9f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "      <th>dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.02815</td>\n",
              "      <td>0.88765</td>\n",
              "      <td>0.02751</td>\n",
              "      <td>0.02819</td>\n",
              "      <td>0.02850</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.00927</td>\n",
              "      <td>0.00903</td>\n",
              "      <td>0.96310</td>\n",
              "      <td>0.00932</td>\n",
              "      <td>0.00928</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.02541</td>\n",
              "      <td>0.02495</td>\n",
              "      <td>0.02498</td>\n",
              "      <td>0.89951</td>\n",
              "      <td>0.02516</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.94904</td>\n",
              "      <td>0.01283</td>\n",
              "      <td>0.01277</td>\n",
              "      <td>0.01282</td>\n",
              "      <td>0.01254</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.93822</td>\n",
              "      <td>0.01524</td>\n",
              "      <td>0.01539</td>\n",
              "      <td>0.01623</td>\n",
              "      <td>0.01492</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75782ff9-b91f-40d1-9c68-cf2494a5e9f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75782ff9-b91f-40d1-9c68-cf2494a5e9f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75782ff9-b91f-40d1-9c68-cf2494a5e9f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "Ut6yrr_pFWWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "t1tKRdn0FWWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57114d1-a265-48f4-e798-41643dbc18d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "GVyUhxinFWWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "MSV3X0vVFWWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "laMIgV5NFWWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "id": "9_G-6nDLFWWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67d102f-e95a-4f0c-fda6-8c5a3e3eaf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score for the model:  -2.72741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "55VFwUJNFWWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "id": "uEjEYpOXFWWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9427d41-e1a6-4a79-ac50-ac83819e157f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score by topic (higher values are better):  [-1.85277 -3.71361 -2.25444 -1.64265 -4.17359]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "b7re4HnVFWWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "id": "KFGsNF8pFWWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87ae0f3-b5bf-46f9-bf2a-6140f0b69b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log-Likelihood (higher values are better):  -30244.946527880245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "UtqJ4d5bFWWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "id": "A9AnAADnFWWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ef690c-04ed-4019-bf5f-19989d70aaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (lower values are better):  758.3988993379553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "15az3h_rFWWe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8llozD941yid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Millen_tops**"
      ],
      "metadata": {
        "id": "3E7hHv3w1znU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_Millen_tops)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "BNvusYur1znU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "XCJdSPRJ1znU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "07CNoFVe1znU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHtYZ3jP1znU",
        "outputId": "7658dc98-d8d0-403e-995a-e3c8d29e7074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "color top look like love fabric shirt blue buy white\n",
            "Topic 1:\n",
            "size small top fit large run order look like big\n",
            "Topic 2:\n",
            "wear love great jean pant comfortable fit look color perfect\n",
            "Topic 3:\n",
            "sweater sleeve long look like soft little short length wear\n",
            "Topic 4:\n",
            "dress fit size petite wear perfect love length skirt great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "stG6P4GX1znU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1E5HQDf1znU",
        "outputId": "f0e0e183-a390-406e-a479-d78e645e4d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "135lbs  0.000013  0.000599  0.000013  0.000018  0.000173\n",
              "32c     0.000012  0.000475  0.000013  0.000018  0.000012\n",
              "32d     0.000012  0.000415  0.000014  0.000018  0.000178\n",
              "34b     0.000013  0.000010  0.000013  0.000019  0.001972\n",
              "34c     0.000013  0.000873  0.000014  0.000018  0.000509\n",
              "34d     0.000013  0.000010  0.000013  0.000753  0.000767\n",
              "34dd    0.000012  0.000619  0.000013  0.000018  0.000012\n",
              "36c     0.000013  0.000422  0.000013  0.000018  0.000307\n",
              "36dd    0.000225  0.000010  0.000013  0.000018  0.000543\n",
              "able    0.000013  0.000806  0.000498  0.000019  0.002315"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-865747ed-0d75-46d0-98f7-ec53f6f351c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135lbs</th>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32c</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32d</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34b</th>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.001972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34c</th>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000873</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34d</th>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.000767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34dd</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000619</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36c</th>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000422</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36dd</th>\n",
              "      <td>0.000225</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>able</th>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.002315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-865747ed-0d75-46d0-98f7-ec53f6f351c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-865747ed-0d75-46d0-98f7-ec53f6f351c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-865747ed-0d75-46d0-98f7-ec53f6f351c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "xPN_ZuxC1znV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq-Di5Tm1znV",
        "outputId": "1512bb1e-1bca-4206-cecc-55b9eadab053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Topic_0   Topic_1   Topic_2   Topic_3   Topic_4\n",
              "color   0.039157  0.002286  0.016418  0.005686  0.004945\n",
              "top     0.023666  0.030651  0.015509  0.000019  0.000012\n",
              "look    0.023471  0.017409  0.018121  0.021820  0.007608\n",
              "like    0.021781  0.016779  0.006103  0.018160  0.009092\n",
              "love    0.020716  0.013353  0.039344  0.008792  0.014600\n",
              "fabric  0.016390  0.011530  0.003992  0.001298  0.006783\n",
              "shirt   0.014597  0.005600  0.003601  0.005922  0.000012\n",
              "blue    0.012480  0.000009  0.000014  0.000019  0.000012\n",
              "buy     0.011869  0.003032  0.013640  0.000019  0.009937\n",
              "white   0.011147  0.000010  0.003399  0.000019  0.000012"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2484621d-c916-4eeb-b0b2-0b01a283b85a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>color</th>\n",
              "      <td>0.039157</td>\n",
              "      <td>0.002286</td>\n",
              "      <td>0.016418</td>\n",
              "      <td>0.005686</td>\n",
              "      <td>0.004945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0.023666</td>\n",
              "      <td>0.030651</td>\n",
              "      <td>0.015509</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>look</th>\n",
              "      <td>0.023471</td>\n",
              "      <td>0.017409</td>\n",
              "      <td>0.018121</td>\n",
              "      <td>0.021820</td>\n",
              "      <td>0.007608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0.021781</td>\n",
              "      <td>0.016779</td>\n",
              "      <td>0.006103</td>\n",
              "      <td>0.018160</td>\n",
              "      <td>0.009092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>0.020716</td>\n",
              "      <td>0.013353</td>\n",
              "      <td>0.039344</td>\n",
              "      <td>0.008792</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fabric</th>\n",
              "      <td>0.016390</td>\n",
              "      <td>0.011530</td>\n",
              "      <td>0.003992</td>\n",
              "      <td>0.001298</td>\n",
              "      <td>0.006783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shirt</th>\n",
              "      <td>0.014597</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.005922</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blue</th>\n",
              "      <td>0.012480</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>buy</th>\n",
              "      <td>0.011869</td>\n",
              "      <td>0.003032</td>\n",
              "      <td>0.013640</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.009937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>white</th>\n",
              "      <td>0.011147</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.003399</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2484621d-c916-4eeb-b0b2-0b01a283b85a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2484621d-c916-4eeb-b0b2-0b01a283b85a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2484621d-c916-4eeb-b0b2-0b01a283b85a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa38x5eR1znV",
        "outputId": "5791747f-e963-4e28-c5b1-72f074d4bc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
              "topic                                                    \n",
              "1      150.222153  -72.269554       1        1  26.746735\n",
              "4       51.163364 -159.968018       2        1  21.187561\n",
              "0      -73.144554   21.523815       3        1  19.620631\n",
              "2      -66.410133 -110.606438       4        1  18.532609\n",
              "3       54.417324   12.443444       5        1  13.912465, topic_info=        Term         Freq        Total Category  logprob  loglift\n",
              "264    dress  2235.000000  2235.000000  Default  30.0000  30.0000\n",
              "752     size  1906.000000  1906.000000  Default  29.0000  29.0000\n",
              "769    small  1073.000000  1073.000000  Default  28.0000  28.0000\n",
              "832  sweater   575.000000   575.000000  Default  27.0000  27.0000\n",
              "453    large   648.000000   648.000000  Default  26.0000  26.0000\n",
              "..       ...          ...          ...      ...      ...      ...\n",
              "861    think   106.827387   614.825463   Topic5  -4.8905   0.2223\n",
              "330      fit   140.709525  2091.141854   Topic5  -4.6150  -0.7264\n",
              "493     love   124.940046  1965.602246   Topic5  -4.7339  -0.7833\n",
              "957     well   103.106483   736.294028   Topic5  -4.9260   0.0065\n",
              "579    order    97.883316   928.717584   Topic5  -4.9779  -0.2776\n",
              "\n",
              "[365 rows x 6 columns], token_table=      Topic      Freq    Term\n",
              "term                         \n",
              "3         2  0.983552     34b\n",
              "6         1  0.948962    34dd\n",
              "15        1  0.869787  across\n",
              "15        3  0.115972  across\n",
              "24        5  0.927496  afraid\n",
              "...     ...       ...     ...\n",
              "985       2  0.356482      xs\n",
              "985       5  0.629785      xs\n",
              "990       5  0.941925    xxsp\n",
              "993       3  0.978490  yellow\n",
              "998       1  0.980701     zip\n",
              "\n",
              "[573 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 1, 3, 4])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1351398900952735528699738294\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1351398900952735528699738294_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.74673462018264, 21.187560691274175, 19.62063072717097, 18.532608745752434, 13.912465215619784]}, \"tinfo\": {\"Term\": [\"dress\", \"size\", \"small\", \"sweater\", \"large\", \"wear\", \"sleeve\", \"jean\", \"top\", \"color\", \"long\", \"pant\", \"run\", \"soft\", \"petite\", \"great\", \"length\", \"perfect\", \"big\", \"short\", \"blue\", \"pair\", \"comfortable\", \"skirt\", \"waist\", \"jacket\", \"black\", \"arm\", \"white\", \"love\", \"small\", \"large\", \"chest\", \"area\", \"huge\", \"sadly\", \"exchange\", \"weird\", \"everywhere\", \"athletic\", \"strange\", \"odd\", \"zip\", \"cup\", \"fix\", \"chested\", \"head\", \"breast\", \"literally\", \"natural\", \"armpit\", \"34dd\", \"bc\", \"funny\", \"crazy\", \"lean\", \"med\", \"experience\", \"bust\", \"bummer\", \"run\", \"big\", \"barely\", \"usual\", \"xl\", \"across\", \"way\", \"size\", \"tight\", \"usually\", \"medium\", \"maybe\", \"normal\", \"order\", \"shoulder\", \"top\", \"however\", \"return\", \"normally\", \"waist\", \"review\", \"hip\", \"fit\", \"want\", \"could\", \"like\", \"fabric\", \"look\", \"really\", \"think\", \"arm\", \"bit\", \"love\", \"much\", \"wear\", \"little\", \"cute\", \"dress\", \"inch\", \"curve\", \"wedding\", \"jumpsuit\", \"34b\", \"glove\", \"appropriate\", \"maxi\", \"holiday\", \"sack\", \"calf\", \"beyond\", \"inseam\", \"rack\", \"flirty\", \"whim\", \"im\", \"shorten\", \"offer\", \"shift\", \"support\", \"casually\", \"midi\", \"wise\", \"breezy\", \"winner\", \"hug\", \"slip\", \"dd\", \"regular\", \"knee\", \"petite\", \"local\", \"tummy\", \"skirt\", \"spot\", \"glad\", \"sell\", \"store\", \"length\", \"true\", \"saw\", \"perfect\", \"lb\", \"fit\", \"size\", \"figure\", \"perfectly\", \"right\", \"waist\", \"gorgeous\", \"work\", \"short\", \"flattering\", \"buy\", \"retailer\", \"wear\", \"order\", \"love\", \"great\", \"online\", \"well\", \"like\", \"flatter\", \"think\", \"beautiful\", \"fabric\", \"look\", \"blue\", \"green\", \"sheer\", \"pink\", \"cheap\", \"dry\", \"yellow\", \"skin\", \"ivory\", \"hand\", \"pay\", \"thread\", \"purple\", \"clean\", \"justice\", \"gold\", \"water\", \"opinion\", \"beige\", \"flower\", \"moss\", \"care\", \"peach\", \"shade\", \"motif\", \"interest\", \"lavender\", \"money\", \"panel\", \"pale\", \"cream\", \"wash\", \"white\", \"price\", \"color\", \"picture\", \"photo\", \"red\", \"navy\", \"shrink\", \"worth\", \"shirt\", \"cold\", \"person\", \"online\", \"fabric\", \"top\", \"like\", \"black\", \"much\", \"look\", \"purchase\", \"love\", \"buy\", \"pretty\", \"soft\", \"quality\", \"really\", \"detail\", \"design\", \"material\", \"fit\", \"beautiful\", \"nice\", \"good\", \"bit\", \"jean\", \"pant\", \"pair\", \"compliment\", \"skinny\", \"boot\", \"pilcro\", \"tights\", \"night\", \"dressy\", \"outfit\", \"linen\", \"comfort\", \"waistband\", \"house\", \"ag\", \"shoe\", \"lounge\", \"travel\", \"cooler\", \"necklace\", \"scarf\", \"chino\", \"everyday\", \"jewelry\", \"wore\", \"boyfriend\", \"trouser\", \"legging\", \"business\", \"weather\", \"transition\", \"day\", \"throw\", \"heel\", \"casual\", \"favorite\", \"highly\", \"comfy\", \"comfortable\", \"wear\", \"denim\", \"great\", \"versatile\", \"leg\", \"many\", \"easy\", \"love\", \"super\", \"perfect\", \"black\", \"fall\", \"stretch\", \"recommend\", \"summer\", \"time\", \"buy\", \"soft\", \"color\", \"look\", \"fit\", \"top\", \"work\", \"style\", \"cute\", \"well\", \"skirt\", \"flattering\", \"sweater\", \"sleeve\", \"tee\", \"coat\", \"itchy\", \"wool\", \"basic\", \"bulky\", \"edge\", \"bell\", \"poncho\", \"xxsp\", \"chunky\", \"overly\", \"closure\", \"afraid\", \"wrist\", \"begin\", \"whether\", \"overwhelm\", \"interesting\", \"fairly\", \"collar\", \"sleeved\", \"tuck\", \"shorter\", \"boxy\", \"oversized\", \"pic\", \"attach\", \"broad\", \"knit\", \"long\", \"nicely\", \"underneath\", \"jacket\", \"longer\", \"cozy\", \"length\", \"arm\", \"short\", \"soft\", \"little\", \"neck\", \"xs\", \"cami\", \"nice\", \"material\", \"look\", \"really\", \"like\", \"cute\", \"petite\", \"warm\", \"bit\", \"wear\", \"great\", \"cut\", \"good\", \"right\", \"think\", \"fit\", \"love\", \"well\", \"order\"], \"Freq\": [2235.0, 1906.0, 1073.0, 575.0, 648.0, 1916.0, 390.0, 445.0, 1605.0, 1345.0, 558.0, 387.0, 596.0, 688.0, 479.0, 1200.0, 515.0, 699.0, 412.0, 564.0, 251.0, 227.0, 547.0, 393.0, 466.0, 278.0, 346.0, 299.0, 288.0, 1965.0, 1072.449831867526, 647.6703179912062, 207.20379377601282, 141.47493290543895, 113.02346005159971, 63.98096796704151, 55.14579378068504, 49.242627967056784, 44.34087241316742, 44.34040676905434, 40.42578645060845, 33.5497474639555, 31.593387689832408, 27.673418705175962, 25.69467702806948, 24.74148509468278, 25.64882144385645, 23.757474303506303, 22.76273012824136, 21.7652920185393, 20.805282112228586, 16.90431127476698, 16.887083751017872, 16.88162753878683, 16.856155477678662, 13.94742458742757, 13.942485367577422, 13.940884125491264, 207.63873151077277, 13.881304161255352, 550.65372063468, 376.80947295681995, 35.14002953905239, 154.61264354559148, 84.85265171018169, 59.90205799519813, 263.3043312480215, 1272.5260009339404, 216.0006050418624, 281.2931903959287, 310.23204783991054, 90.50036819509982, 82.94336361262104, 547.8807772772543, 181.9757481278241, 837.347395719554, 193.9722705664685, 204.81904114620568, 112.30497502986427, 272.47387886036574, 153.46142594873683, 127.44832823894136, 703.9774961010448, 206.19076152540504, 217.75698511849322, 458.3787556498516, 314.9929859323855, 475.60141214818697, 284.513393106401, 240.43216596062067, 159.0601236686052, 214.88927885032473, 364.7918701320209, 202.73518777413707, 287.59387460806465, 215.89035854404108, 199.74939984839565, 2234.9667952971245, 99.97976382008484, 54.546850042122095, 50.614419913621866, 47.63871870894825, 42.686518464686685, 34.78937644442577, 32.809605041687185, 26.88739333811522, 26.88203137587393, 25.882994343061306, 21.9435709687969, 20.913410273014705, 18.995168830252567, 18.00075436485197, 17.006443904047813, 17.00272630928552, 16.022497671390912, 16.00913638785473, 15.985585915237326, 15.033966049164272, 15.024859025529198, 14.040888670482854, 13.06552492439442, 13.058843140812, 13.974929044124512, 15.549470495867958, 31.41736782640365, 80.80002660702422, 18.145128128408942, 184.43907695240986, 110.09888238120315, 346.7931156372316, 58.34015903687801, 31.299347915333687, 261.46750332499073, 46.127604224692035, 86.32904376075055, 64.87594494722721, 214.92343877076388, 264.72169038262723, 159.16877539002272, 113.57650628008541, 318.05838500263656, 130.85241745506758, 694.8078918034081, 633.5788651999839, 82.79992476140025, 153.5712923916441, 157.232847182562, 193.35966556023658, 100.27555679864102, 201.42369744387162, 194.70292109001753, 143.17187639311186, 215.03686688849504, 153.26919293168015, 323.4432539661081, 220.19873404884297, 315.9654156038126, 235.2913273152085, 118.19316035798306, 171.8999370809346, 196.7704228170851, 124.16467594672748, 145.82528258322833, 137.80634399215285, 146.78388267410477, 164.63460976654395, 250.10460093112806, 137.4971879853514, 126.63318895177885, 93.05226922177835, 79.24009379532355, 76.27275184150164, 65.40807882263141, 52.54802372259272, 49.5843509421515, 43.67258765895089, 42.6835990809782, 40.71374001613362, 38.73462112428107, 37.760026168518976, 37.73871898919126, 31.826018086243394, 26.902711991356277, 28.747727203735263, 24.90783350720314, 24.904445284325643, 24.90171475356777, 24.89929458824577, 23.92376215943898, 23.91053558687167, 23.90040999539984, 21.91698424887507, 20.961524359168042, 19.978182099944313, 19.9703442498308, 18.986025464362267, 44.06274355883502, 209.7793421588063, 223.3841195162409, 188.04682864977397, 784.7259371988524, 192.60469197458792, 140.61773582972896, 100.55670268069744, 73.05729927938606, 41.26079686713212, 82.76023873798623, 292.52614219391586, 45.89677548791596, 136.54828635943375, 152.9892188976635, 328.46360394771256, 474.26898836139384, 436.4977284891638, 164.37979086809477, 210.43759408241417, 470.37745688544544, 170.33223271355735, 415.15049420935776, 237.85490498310975, 151.62955740489562, 198.93645201280668, 146.07898595921571, 191.04330655416027, 121.45321645445357, 125.10398031783689, 152.29011358635867, 207.05275729583798, 140.0010516391624, 138.9677236124281, 130.83741442860523, 129.1100293136027, 444.49355107627144, 386.363605184887, 226.7914647869355, 163.74358723847786, 107.58564610378285, 107.58375366885875, 61.3036410058698, 61.29170878468785, 60.29695128009612, 59.30855497972518, 40.596098118810374, 39.60138506631824, 26.800568046319707, 27.730298023011542, 24.826002884236992, 23.87335581644858, 23.862967129828053, 21.898802766645314, 21.890008035542838, 19.926573497796934, 19.923772535335782, 19.91637954327865, 18.942862170749557, 19.870009148154583, 18.922615774410172, 18.918639847802808, 15.98669162886726, 15.976277668474383, 138.94905811378618, 15.003553213558066, 72.33793364833464, 35.54333159648188, 184.03039627976315, 55.29557185883364, 67.5359796276476, 175.13423285665746, 91.54456116267389, 61.228120607018376, 120.79077656086443, 357.6693043745561, 1044.8663763451755, 82.29406018596778, 622.0697267248651, 81.21688906230918, 78.34189671468539, 124.70899348995175, 87.53573842136579, 744.7544203599192, 175.19919437029682, 307.9600925484104, 181.29869999016864, 159.51302855804607, 106.79710783988087, 116.13020731280245, 157.27993642102106, 134.1365800108198, 258.1866914935031, 236.53415392106928, 310.7707282782059, 343.02532301809185, 344.5941834610203, 293.5745491895912, 165.69191309582553, 133.72341678870959, 146.40827032337506, 144.23316936445684, 130.8209130620278, 122.65185958604026, 574.3430990537166, 389.3378811972075, 141.98485398518284, 113.8411519576022, 56.533873051113304, 49.48986706238864, 42.44749144914767, 41.44270760527666, 34.400706373658196, 32.38971914696414, 22.35269595093365, 22.333674219234037, 21.30321155574301, 18.305260072188492, 17.315474234246352, 17.3009528183935, 13.286011465500655, 13.257562241891481, 19.466676722925683, 12.986110170136987, 27.699997970904928, 30.667549701290085, 41.46501779802329, 15.738652684154129, 42.28714257653971, 23.890681808199584, 100.20297533896327, 33.466875181616984, 26.615659504153953, 11.496011937978928, 28.741174290689173, 76.01660735062056, 378.30188340144355, 106.79497483566468, 95.51701584791697, 160.02565483227275, 60.50492368974407, 55.62305740217762, 218.40056491517345, 140.09921924628637, 222.11480955791512, 252.57609801817966, 243.56719377038826, 78.36846336960717, 52.989775500444374, 52.91436174347409, 168.5934047711404, 163.76252274735836, 310.06651991094054, 182.690059210803, 258.0560922817489, 144.17613618379423, 132.16775162499255, 71.68785744504625, 138.64508292254317, 209.05820840018148, 154.17768014614248, 100.25738517051118, 107.12533148035166, 93.22898394991684, 106.82738747880671, 140.70952526094365, 124.94004596252317, 103.1064832521989, 97.88331608876], \"Total\": [2235.0, 1906.0, 1073.0, 575.0, 648.0, 1916.0, 390.0, 445.0, 1605.0, 1345.0, 558.0, 387.0, 596.0, 688.0, 479.0, 1200.0, 515.0, 699.0, 412.0, 564.0, 251.0, 227.0, 547.0, 393.0, 466.0, 278.0, 346.0, 299.0, 288.0, 1965.0, 1073.4872036859176, 648.7075451455873, 208.23145197574422, 142.50340907908767, 114.0539531869887, 65.00318375260623, 56.174161626516195, 50.28828328547646, 45.38305874704798, 45.3829939734003, 41.458942770005336, 34.59203258321194, 32.62970651422213, 28.705662233418863, 26.74382444661233, 25.762617786533358, 26.74436119150606, 24.78156224854455, 23.800515088863598, 22.819830225243983, 21.838677872557653, 17.914308390480187, 17.914372990964214, 17.91451126927526, 17.914799205799344, 14.971367835154615, 14.971484090733021, 14.971321880470088, 223.04776774662133, 14.971879614087282, 596.9007943805575, 412.1356608360679, 38.5318352721313, 179.95295559599683, 98.44349793161531, 68.98242738347666, 343.0619709950808, 1906.8956061430224, 286.60494409413565, 386.336507386131, 440.74813978073485, 110.59337466063756, 100.43556092725157, 928.7175843034888, 261.97609914817144, 1605.7225251284233, 290.4144026539, 311.962471480142, 153.62958621865124, 466.61457865895807, 238.2461550202432, 191.45434785213956, 2091.141853922255, 398.9663989925577, 451.20334660918013, 1465.2268449705166, 884.250565009592, 1763.705321729209, 751.9530661139602, 614.8254630055617, 299.9242228634312, 577.0937197250594, 1965.6022462676333, 516.3990388222132, 1916.4285886624696, 681.4925403994894, 561.0765524311743, 2235.9971753641994, 101.02071129289989, 55.574613657293895, 51.622641968083414, 48.65880478966252, 43.71907246763998, 35.815288638655545, 33.83958120237389, 27.911794365343454, 27.911758482088008, 26.923824814783632, 22.971700853102444, 21.98403651724074, 20.008017398004103, 19.02001913615307, 18.03212296420325, 18.03207657226369, 17.044241489995233, 17.04414853016652, 17.044347153808673, 16.05625758590016, 16.055997884176854, 15.068387615837704, 14.080278768903904, 14.080214875163817, 15.06802747028773, 17.044241695416726, 35.81469190767598, 93.03774904808523, 21.027951850414805, 215.15271506415473, 132.57280656643297, 479.730171876634, 71.37938620464374, 36.79031728995227, 393.07623904393364, 58.73968558261389, 122.50729998684149, 88.05083327542451, 398.8995139327263, 515.7181960839321, 283.06080177761777, 190.25599237086604, 699.0990165178448, 235.41278074532698, 2091.141853922255, 1906.8956061430224, 131.50092706400605, 299.00743214767556, 329.5159093295027, 466.61457865895807, 184.3515455216299, 589.9903357550564, 564.235687220463, 358.04562371500714, 794.1719911763311, 433.76248814284924, 1916.4285886624696, 928.7175843034888, 1965.6022462676333, 1200.0509608179282, 295.45105481548984, 736.2940277143742, 1465.2268449705166, 358.9789849104043, 614.8254630055617, 518.9726951444458, 884.250565009592, 1763.705321729209, 251.1394831549749, 138.53526615633388, 127.66984151253799, 94.08608765895619, 80.25746545699916, 77.29413253562855, 66.42885945149953, 53.58801058935869, 50.624956679887475, 44.698320690566035, 43.71037376933541, 41.734978748381536, 39.75953798863648, 38.77163537028586, 38.771678816378284, 32.84504676055521, 27.906309373628496, 29.88129418578524, 25.9308230672865, 25.930763345333066, 25.930805075326283, 25.93089645104587, 24.943069608158858, 24.942995116126294, 24.943040696851583, 22.968134590650585, 21.979767821733994, 20.992004368205226, 20.992015996883488, 20.004211509686176, 47.65455748462831, 245.12004257885897, 288.5008773896104, 242.260468558628, 1345.747346934388, 282.1396914748232, 209.51169343242123, 144.36283160621585, 97.99587967644356, 48.60571152089825, 117.79903777508852, 598.0869748218502, 56.72348013985591, 251.9155682924044, 295.45105481548984, 884.250565009592, 1605.7225251284233, 1465.2268449705166, 346.46206663974857, 516.3990388222132, 1763.705321729209, 414.73631341984765, 1965.6022462676333, 794.1719911763311, 411.4459590537692, 688.5708308211167, 404.34537437040694, 751.9530661139602, 278.0899913426542, 305.79522633576056, 565.2330215568603, 2091.141853922255, 518.9726951444458, 561.4362389183491, 480.24334235724984, 577.0937197250594, 445.5132155104065, 387.3927749987084, 227.80798614146042, 164.7621310806061, 108.61201092496341, 108.61205874189453, 62.31256718656765, 62.312750649909546, 61.32757302226221, 60.342557501245594, 41.625814287255444, 40.64066568701315, 27.834569705728992, 28.81960728981807, 25.864234861896374, 24.8790456916891, 24.879179084982177, 22.908859431785963, 22.908999069985875, 20.938830695496883, 20.938813394477606, 20.93899831120325, 19.953639308652242, 20.939636152854703, 19.953869342693977, 19.953856786146833, 16.99830738883353, 16.99856393878074, 148.18205857160447, 16.013269358464647, 80.1824288413961, 38.676256148141, 216.07063618206567, 62.330227613366816, 77.11386807172667, 222.02508538574233, 110.6328353305333, 71.2044770471576, 158.95198164550683, 547.2182773201752, 1916.4285886624696, 104.03181391915723, 1200.0509608179282, 107.87117447017215, 103.75724163744609, 188.54579701450893, 124.47777517545617, 1965.6022462676333, 320.3503011853473, 699.0990165178448, 346.46206663974857, 297.34009251761483, 169.5323211451432, 193.35579105885435, 317.9841309764122, 246.29194172211965, 794.1719911763311, 688.5708308211167, 1345.747346934388, 1763.705321729209, 2091.141853922255, 1605.7225251284233, 589.9903357550564, 379.62856863964385, 561.0765524311743, 736.2940277143742, 393.07623904393364, 358.04562371500714, 575.3607569333695, 390.3539041272338, 143.007640985371, 114.85459964090005, 57.542786879624735, 50.504364298142086, 43.46599277572089, 42.46049489157585, 35.42218057500289, 33.41120911321718, 23.356848314428422, 23.3564235129655, 22.35049011894233, 19.334463075858583, 18.329281933059878, 18.328920419158283, 14.307219809721719, 14.306734530327041, 22.31854865347327, 15.289924815488304, 33.329486895957366, 37.29349353692147, 53.322304998069804, 20.26750090273037, 55.28380656123555, 31.28726506853261, 132.18121114587873, 44.29546749786712, 35.26434567762429, 15.244742579542136, 38.28710345887956, 103.3228302572892, 558.9257712597596, 167.05141328560876, 150.92145243131193, 278.3308324637163, 92.18417582878413, 84.1218011214785, 515.7181960839321, 299.9242228634312, 564.235687220463, 688.5708308211167, 681.4925403994894, 141.85936747076533, 84.1556955541066, 88.09939845446496, 561.4362389183491, 565.2330215568603, 1763.705321729209, 751.9530661139602, 1465.2268449705166, 561.0765524311743, 479.730171876634, 151.43363692247524, 577.0937197250594, 1916.4285886624696, 1200.0509608179282, 389.416547730419, 480.24334235724984, 329.5159093295027, 614.8254630055617, 2091.141853922255, 1965.6022462676333, 736.2940277143742, 928.7175843034888], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.2376, -3.742, -4.8816, -5.2632, -5.4877, -6.0568, -6.2054, -6.3186, -6.4234, -6.4234, -6.5159, -6.7023, -6.7624, -6.8949, -6.9691, -7.0069, -6.9708, -7.0474, -7.0902, -7.135, -7.1801, -7.3878, -7.3888, -7.3891, -7.3906, -7.58, -7.5804, -7.5805, -4.8795, -7.5848, -3.9042, -4.2836, -6.656, -5.1744, -5.7744, -6.1226, -4.642, -3.0666, -4.8401, -4.5759, -4.478, -5.71, -5.7972, -3.9093, -5.0115, -3.4851, -4.9476, -4.8932, -5.4941, -4.6078, -5.1819, -5.3676, -3.6586, -4.8865, -4.832, -4.0876, -4.4628, -4.0508, -4.5646, -4.7329, -5.1461, -4.8452, -4.316, -4.9034, -4.5538, -4.8406, -4.9183, -2.2704, -5.3774, -5.9833, -6.0581, -6.1187, -6.2285, -6.433, -6.4916, -6.6907, -6.6909, -6.7288, -6.8939, -6.942, -7.0382, -7.0919, -7.1488, -7.149, -7.2083, -7.2092, -7.2107, -7.272, -7.2726, -7.3404, -7.4124, -7.4129, -7.3451, -7.2383, -6.535, -5.5904, -7.0839, -4.765, -5.281, -4.1336, -5.9161, -6.5387, -4.416, -6.1509, -5.5242, -5.8099, -4.6121, -4.4037, -4.9124, -5.2499, -4.2201, -5.1083, -3.4387, -3.531, -5.5659, -4.9482, -4.9246, -4.7178, -5.3744, -4.6769, -4.7109, -5.0183, -4.6115, -4.9501, -4.2033, -4.5878, -4.2267, -4.5215, -5.21, -4.8354, -4.7003, -5.1607, -4.9999, -5.0565, -4.9934, -4.8786, -4.3836, -4.9819, -5.0642, -5.3723, -5.533, -5.5712, -5.7249, -5.9438, -6.0018, -6.1288, -6.1517, -6.1989, -6.2488, -6.2743, -6.2748, -6.4452, -6.6133, -6.547, -6.6903, -6.6905, -6.6906, -6.6907, -6.7306, -6.7312, -6.7316, -6.8182, -6.8628, -6.9109, -6.9113, -6.9618, -6.1199, -4.5595, -4.4966, -4.6688, -3.2402, -4.6449, -4.9595, -5.2948, -5.6143, -6.1856, -5.4896, -4.227, -6.0791, -4.9888, -4.8751, -4.1111, -3.7437, -3.8267, -4.8033, -4.5563, -3.752, -4.7678, -3.8769, -4.4339, -4.8841, -4.6125, -4.9214, -4.653, -5.106, -5.0764, -4.8797, -4.5725, -4.9639, -4.9713, -5.0316, -5.0448, -3.7515, -3.8917, -4.4244, -4.7502, -5.1702, -5.1702, -5.7326, -5.7328, -5.7492, -5.7657, -6.1448, -6.1696, -6.56, -6.5259, -6.6366, -6.6757, -6.6761, -6.762, -6.7624, -6.8564, -6.8565, -6.8569, -6.907, -6.8592, -6.9081, -6.9083, -7.0767, -7.0774, -4.9144, -7.1402, -5.5671, -6.2777, -4.6334, -5.8358, -5.6358, -4.6829, -5.3316, -5.7339, -5.0544, -3.9689, -2.8968, -5.4382, -3.4154, -5.4513, -5.4874, -5.0225, -5.3764, -3.2354, -4.6825, -4.1185, -4.6483, -4.7763, -5.1775, -5.0937, -4.7904, -4.9496, -4.2948, -4.3824, -4.1094, -4.0107, -4.0061, -4.1663, -4.7383, -4.9527, -4.8621, -4.877, -4.9746, -5.0391, -3.2085, -3.5973, -4.606, -4.8269, -5.5269, -5.6599, -5.8134, -5.8374, -6.0236, -6.0839, -6.4548, -6.4556, -6.5029, -6.6545, -6.7101, -6.711, -6.975, -6.9771, -6.593, -6.9978, -6.2403, -6.1385, -5.8369, -6.8056, -5.8172, -6.3882, -4.9545, -6.0512, -6.2802, -7.1197, -6.2034, -5.2308, -3.626, -4.8908, -5.0024, -4.4864, -5.459, -5.5431, -4.1754, -4.6194, -4.1585, -4.03, -4.0663, -5.2003, -5.5916, -5.593, -4.4342, -4.4633, -3.8249, -4.3539, -4.0085, -4.5907, -4.6776, -5.2894, -4.6298, -4.2191, -4.5236, -4.954, -4.8877, -5.0267, -4.8905, -4.615, -4.7339, -4.926, -4.9779], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3178, 1.3172, 1.3138, 1.3115, 1.3097, 1.3029, 1.3003, 1.2977, 1.2955, 1.2955, 1.2935, 1.2882, 1.2865, 1.2821, 1.2787, 1.2783, 1.2769, 1.2766, 1.2742, 1.2714, 1.2703, 1.2607, 1.2597, 1.2594, 1.2578, 1.2479, 1.2476, 1.2474, 1.2472, 1.2431, 1.2381, 1.2291, 1.2266, 1.167, 1.1702, 1.1776, 1.0542, 0.9143, 1.0359, 1.0014, 0.9676, 1.1183, 1.1274, 0.791, 0.9544, 0.6677, 0.9152, 0.898, 1.0054, 0.7808, 0.8789, 0.9118, 0.23, 0.6587, 0.5902, 0.1567, 0.2866, 0.0082, 0.3469, 0.3799, 0.6845, 0.3309, -0.3655, 0.3838, -0.5779, 0.1692, 0.286, 1.5513, 1.5414, 1.5331, 1.532, 1.5306, 1.5279, 1.5227, 1.5208, 1.5144, 1.5142, 1.5123, 1.506, 1.5018, 1.4998, 1.4967, 1.4932, 1.493, 1.4899, 1.4891, 1.4876, 1.486, 1.4854, 1.4811, 1.477, 1.4765, 1.4764, 1.46, 1.4208, 1.4107, 1.4043, 1.3977, 1.366, 1.2273, 1.35, 1.3901, 1.1441, 1.3101, 1.2018, 1.2463, 0.9333, 0.8849, 0.9761, 1.0359, 0.7642, 0.9645, 0.4499, 0.4499, 1.0892, 0.8855, 0.8119, 0.6708, 0.9428, 0.4771, 0.4878, 0.6351, 0.2453, 0.5115, -0.2274, 0.1125, -0.2762, -0.0775, 0.6356, 0.097, -0.456, 0.4901, 0.1128, 0.2258, -0.244, -0.8197, 1.6245, 1.6211, 1.6204, 1.6175, 1.6158, 1.6153, 1.6131, 1.609, 1.6078, 1.6054, 1.6048, 1.6038, 1.6025, 1.6022, 1.6016, 1.5971, 1.592, 1.5899, 1.5883, 1.5882, 1.5881, 1.588, 1.5869, 1.5863, 1.5859, 1.5817, 1.5812, 1.5791, 1.5787, 1.5763, 1.5502, 1.4729, 1.3728, 1.3753, 1.0892, 1.2468, 1.2299, 1.267, 1.3349, 1.4648, 1.2756, 0.9134, 1.4168, 1.0162, 0.9705, 0.6383, 0.409, 0.4176, 0.883, 0.7309, 0.307, 0.7387, 0.0737, 0.4229, 0.6304, 0.387, 0.6105, 0.2584, 0.8002, 0.7348, 0.3171, -0.6839, 0.3184, 0.2323, 0.3283, 0.1312, 1.6833, 1.683, 1.6812, 1.6794, 1.6761, 1.6761, 1.6693, 1.6691, 1.6687, 1.6684, 1.6606, 1.6597, 1.6478, 1.6471, 1.6447, 1.6444, 1.6439, 1.6405, 1.6401, 1.6361, 1.6359, 1.6356, 1.6337, 1.6332, 1.6326, 1.6324, 1.6243, 1.6236, 1.6213, 1.6205, 1.5827, 1.6012, 1.5251, 1.5659, 1.553, 1.4484, 1.4962, 1.5347, 1.4111, 1.2604, 1.0791, 1.4512, 1.0286, 1.4018, 1.4047, 1.2723, 1.3336, 0.7151, 1.0821, 0.8658, 1.038, 1.0629, 1.2235, 1.1758, 0.9817, 1.078, 0.562, 0.6171, 0.22, 0.0483, -0.1175, -0.0136, 0.4157, 0.6422, 0.3422, 0.0554, 0.5855, 0.6143, 1.9706, 1.9698, 1.9652, 1.9635, 1.9547, 1.9521, 1.9487, 1.9481, 1.9431, 1.9413, 1.9284, 1.9276, 1.9244, 1.9177, 1.9155, 1.9147, 1.8983, 1.8962, 1.8357, 1.8091, 1.7874, 1.7768, 1.7209, 1.7195, 1.7044, 1.7027, 1.6954, 1.6921, 1.691, 1.6902, 1.6856, 1.6655, 1.5821, 1.525, 1.5149, 1.4189, 1.5513, 1.5587, 1.1132, 1.2112, 1.0401, 0.9695, 0.9435, 1.379, 1.5098, 1.4626, 0.7694, 0.7336, 0.234, 0.5575, 0.2358, 0.6136, 0.6832, 1.2246, 0.5463, -0.2432, -0.0796, 0.6155, 0.4721, 0.7098, 0.2223, -0.7264, -0.7833, 0.0065, -0.2776]}, \"token.table\": {\"Topic\": [2, 1, 1, 3, 5, 4, 2, 1, 1, 5, 1, 1, 1, 5, 1, 3, 5, 1, 1, 2, 3, 4, 5, 5, 3, 5, 2, 1, 5, 1, 2, 3, 5, 3, 4, 3, 4, 1, 5, 4, 1, 2, 2, 5, 5, 1, 4, 1, 2, 1, 2, 3, 4, 2, 3, 5, 3, 2, 3, 4, 2, 3, 1, 1, 4, 5, 3, 5, 5, 3, 5, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 3, 4, 4, 4, 1, 2, 3, 4, 5, 4, 5, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 4, 2, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 4, 3, 2, 4, 5, 4, 1, 1, 1, 1, 2, 3, 4, 5, 1, 5, 2, 4, 5, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 1, 2, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 4, 2, 4, 1, 2, 5, 2, 4, 1, 3, 5, 2, 3, 1, 2, 2, 2, 3, 2, 5, 5, 3, 4, 5, 4, 4, 2, 3, 2, 4, 3, 5, 1, 3, 1, 2, 5, 1, 2, 4, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 3, 4, 5, 2, 3, 2, 4, 5, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 5, 1, 1, 2, 5, 2, 3, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 4, 1, 2, 1, 2, 5, 1, 2, 1, 2, 3, 3, 1, 2, 3, 5, 4, 5, 3, 5, 2, 5, 4, 3, 3, 4, 3, 3, 2, 4, 5, 1, 2, 4, 5, 1, 2, 3, 2, 5, 1, 3, 5, 4, 5, 1, 3, 4, 3, 5, 1, 2, 3, 5, 2, 3, 1, 2, 3, 4, 3, 1, 2, 3, 4, 5, 2, 1, 3, 4, 5, 1, 2, 4, 2, 3, 4, 2, 5, 1, 2, 3, 4, 1, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 4, 2, 1, 2, 3, 5, 4, 1, 2, 3, 3, 3, 2, 1, 3, 4, 5, 4, 1, 2, 5, 2, 2, 5, 1, 2, 5, 1, 3, 1, 2, 3, 4, 2, 4, 5, 4, 5, 1, 2, 1, 3, 4, 5, 2, 5, 1, 2, 3, 1, 1, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 5, 2, 5, 5, 1, 2, 3, 4, 5, 3, 2, 4, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 1, 3, 4, 3, 4, 4, 4, 2, 3, 4, 5, 4, 5, 2, 4, 1, 3, 4, 5, 1, 2, 1, 2, 5, 2, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 4, 5, 3, 4, 3, 1, 3, 4, 1, 2, 3, 4, 5, 4, 5, 2, 1, 1, 2, 3, 4, 5, 2, 5, 2, 3, 4, 2, 3, 2, 5, 4, 1, 2, 4, 5, 2, 3, 5, 1, 3, 2, 5, 5, 3, 1], \"Freq\": [0.9835524308487509, 0.9489621161726758, 0.8697867308504105, 0.11597156411338806, 0.927495979644866, 0.9646672262842161, 0.9751893737291585, 0.9894500132396601, 0.5301339067648422, 0.46678457199420065, 0.9615966736882212, 0.9695261627249427, 0.1967891543164452, 0.7215602324936323, 0.9083398118156663, 0.07785769815562854, 0.9662726494414787, 0.9489586941488037, 0.24471422328809045, 0.26590994341540536, 0.2697637107112808, 0.09634418239688601, 0.12332055346801409, 0.908662977735621, 0.9641036050081728, 0.9577624051726126, 0.9552385879422545, 0.9147473412885677, 0.08492349322307657, 0.37255647159430344, 0.16288515502262568, 0.22353388295658208, 0.24086209093771246, 0.4733562943574059, 0.5224237151139662, 0.9954627478695903, 0.9943647257129246, 0.234526524089627, 0.7565371744826677, 0.9412701884959831, 0.968461945994125, 0.9291196228309414, 0.23506609763953604, 0.7574352035051717, 0.9656034416154294, 0.9350863325689031, 0.9367231428022517, 0.932535672073099, 0.0672501686591177, 0.10451136645735898, 0.2707222143172552, 0.29968319538375227, 0.32486665718070623, 0.9577000911113984, 0.38592772023946603, 0.6015932109615206, 0.9641008766201631, 0.08557591574388879, 0.12611187583309927, 0.7881992239568705, 0.9290974161883937, 0.984332106055942, 0.9940861384576636, 0.9703982804522298, 0.9522072493192393, 0.9395767112150364, 0.9800979411129707, 0.9274776863646633, 0.9925592911074349, 0.8109516532939026, 0.17629383767258752, 0.1875387795100378, 0.03750775590200756, 0.768908995991155, 0.04607105497271533, 0.07950972390452485, 0.5833190024771215, 0.23109835639539467, 0.06018960407725713, 0.9700167915454709, 0.08223409536021525, 0.11512773350430136, 0.14619394730704935, 0.6542179141990458, 0.0036548486826762333, 0.23277470099439868, 0.7612361843330335, 0.9953743552865721, 0.9551631746227937, 0.4831524447641688, 0.2681717698002955, 0.07092145978189633, 0.1507081020365297, 0.028811843036395387, 0.3328506953811628, 0.6657013907623256, 0.9489361172687212, 0.9233114800025759, 0.06295305545472109, 0.9754173156612518, 0.9896605010907084, 0.2953135932980715, 0.2850418161398777, 0.14637282450426153, 0.02054355431638758, 0.2567944289548448, 0.35645759769034985, 0.12476015919162245, 0.2602140463139554, 0.2566494703370519, 0.14347160052733285, 0.8515733708719112, 0.8560034818438547, 0.09511149798265052, 0.048062220696117854, 0.7882204194163328, 0.1634115503668007, 0.3695283322569822, 0.019620973394176046, 0.4087702790453343, 0.1536976249210457, 0.04578227125307744, 0.09349491462986015, 0.17620195449473644, 0.43511094885434914, 0.2948685769095589, 0.9995540354991562, 0.977751067292468, 0.9832570404353523, 0.28920825383693294, 0.7069535093791695, 0.9598505639145629, 0.9551264336211208, 0.9695247789542624, 0.9790978344399189, 0.9351211677749601, 0.3562338690692078, 0.16624247223229696, 0.3709355843006354, 0.08594848904526918, 0.020356221089669016, 0.16088597315399947, 0.8312441946289972, 0.23542065722554084, 0.5381043593726648, 0.22533120048730337, 0.08135017034600135, 0.08135017034600135, 0.8315795190924582, 0.14448567340329124, 0.631174257498588, 0.19771723728871432, 0.022813527379467038, 0.33665817490073224, 0.33235430618751266, 0.09898898040405053, 0.1649816340067509, 0.06742727650710688, 0.9721870576851416, 0.14764095456236248, 0.3454241201081688, 0.12535552745860964, 0.12535552745860964, 0.25628241169315746, 0.033515281866848386, 0.39939044224660997, 0.12847524715625216, 0.34353163913519597, 0.09775290544497446, 0.9427619828096678, 0.9641058254653895, 0.9489513693380117, 0.2856972605204698, 0.7019989829931543, 0.9772362957372456, 0.9742717138838097, 0.2706961003600834, 0.17491132638651544, 0.272778378055161, 0.060386053157249375, 0.22280371337329943, 0.10306395829901376, 0.5424418857842829, 0.20070349774018467, 0.1518837280195992, 0.04999787672275628, 0.19582501716412876, 0.10666213700854674, 0.5183113220259068, 0.1283278835884078, 0.988917867638112, 0.9843770262556324, 0.972167546415636, 0.11671052464426687, 0.8818128528677942, 0.12639654658287067, 0.8566877046172345, 0.663343514653855, 0.1984807366680826, 0.13580260929921442, 0.9673342515243848, 0.9665857170524855, 0.6680109465204402, 0.3099019854991733, 0.02066013236661155, 0.8655665691586175, 0.11168600892369258, 0.990759170045945, 0.9387334724981343, 0.9898960195405828, 0.9496193261954752, 0.9578487932126332, 0.1500173109657582, 0.8400969414082461, 0.990567247277053, 0.9876551661300332, 0.42395590512015113, 0.5748554645696965, 0.9966034329449176, 0.952196271995575, 0.9864607280735658, 0.9800968428518936, 0.829732754770326, 0.16594655095406521, 0.2613168835267674, 0.7355586351123823, 0.998909300268076, 0.9554241050369431, 0.3100936141567117, 0.5564693623908115, 0.13168358957339812, 0.9351182974161036, 0.24094703757985675, 0.7517547572491531, 0.9380352880766093, 0.05398764247922932, 0.513846519305035, 0.062049391010419314, 0.4227114762584816, 0.31257958559257487, 0.13445017109549617, 0.29756484567328084, 0.0791686286653683, 0.1760819499626295, 0.9842358466284209, 0.966365640160529, 0.31695137832819315, 0.10858519442725136, 0.12619360433437318, 0.08950941702786935, 0.3580376681114774, 0.8125595229092442, 0.16811576336053327, 0.2129084148898459, 0.10913792696034118, 0.6762973178853928, 0.33628331241553905, 0.6617187760434801, 0.26988635467364247, 0.09355304311166178, 0.2664844258332184, 0.19447693204424238, 0.17576632342191, 0.9603271636245266, 0.18569372348504234, 0.16076497704458462, 0.21113121985285635, 0.3790186958804289, 0.06359374091953506, 0.10077127308511638, 0.042430009720049004, 0.16441628766518987, 0.6629689018757656, 0.03182250729003675, 0.22291691248495976, 0.16984145713139792, 0.26891564045804667, 0.04776790981820566, 0.2901458225994714, 0.9673330079245791, 0.8228341008603723, 0.17180052655326455, 0.9351110360973268, 0.7033495368902069, 0.15428312422107762, 0.14066990737804136, 0.9232771746473029, 0.9527437041834972, 0.9641042739466672, 0.9621922319610929, 0.39310685097903364, 0.15685544300148635, 0.4066622596334831, 0.042602712913983945, 0.9640737806919764, 0.0816360853784249, 0.7449292790781272, 0.1632721707568498, 0.028196939485327453, 0.41590485740857996, 0.5498403199638854, 0.9551639638411789, 0.15495971575973136, 0.12111793875473256, 0.24757931598393862, 0.1745523234994675, 0.30101370072867356, 0.11373743942839676, 0.16761306863132153, 0.07782035329311357, 0.6405213694125502, 0.9783527546120194, 0.8264005222225954, 0.16926275756366413, 0.7290262426444182, 0.24734818946864187, 0.0195274886422612, 0.9828852906579632, 0.938727652964091, 0.08123172894064663, 0.39938933395817927, 0.5178522719966223, 0.970506826769087, 0.5900609714534306, 0.23688579145940647, 0.06675872304765092, 0.10552185255919015, 0.9849657166359134, 0.9309800809765014, 0.22575673234471477, 0.7449972167375587, 0.1308050905504814, 0.8502330885781291, 0.9964532141513306, 0.9497999954059709, 0.9527431764042689, 0.9964047470975342, 0.9837481652963177, 0.9621911166919737, 0.4548711877523903, 0.4405670623513718, 0.10442011542743551, 0.220730299330498, 0.5150373651044954, 0.24748548712813415, 0.016721992373522575, 0.13099627078901338, 0.3215363010275783, 0.5438330029725706, 0.7233232770050442, 0.27515467597886406, 0.2625151804127842, 0.6729934625127741, 0.06682204592325416, 0.22685803029307613, 0.765645852239132, 0.3154465773134296, 0.6840583081066507, 0.9789357549234372, 0.9884564478555741, 0.9419079022921836, 0.3208197749798529, 0.14582717044538768, 0.36942883179498215, 0.1652707931714394, 0.21877279572409392, 0.7760242565307482, 0.040989899967574066, 0.29657398211832997, 0.4098989996757406, 0.25076174097810017, 0.9808967098950304, 0.16817306270878105, 0.22505512803675112, 0.36107745816885345, 0.14591486323261885, 0.09892533100516533, 0.94637128759696, 0.37901301669379406, 0.2540052146965427, 0.12367793176323806, 0.24336625282443616, 0.1448107648944285, 0.2534188385652499, 0.5999303117054896, 0.0415619445340781, 0.699626066323648, 0.2562986579601483, 0.8552064980687529, 0.13943584207642712, 0.3388951419690056, 0.3527275967432507, 0.2028760033555952, 0.1014380016777976, 0.6571303241295461, 0.33978446028161896, 0.6421929453048254, 0.26023504973136713, 0.09234146925951738, 0.11835543867777737, 0.4764565095490012, 0.039451812892592454, 0.08497313546096837, 0.2822321999239306, 0.9231014687655229, 0.07538941214963435, 0.9656874600418449, 0.9845671597190652, 0.5991926907499437, 0.2995963453749719, 0.09986544845832397, 0.955155528586062, 0.20442736690174973, 0.7382099360340962, 0.05678537969493048, 0.9621939902671663, 0.9947533301161637, 0.9342152067348674, 0.25581563625520104, 0.4898953034168229, 0.11369583833564491, 0.14044780029697312, 0.9646620540822878, 0.26052942649578087, 0.3456002596372603, 0.3934526032793425, 0.9387385924079178, 0.22373320214045492, 0.7670852644815597, 0.69471986410891, 0.03817142110488517, 0.26338280562370764, 0.14401599690584344, 0.8435222675913686, 0.6675771845606326, 0.332477560888799, 0.9890271987541285, 0.9943651634865114, 0.6639933276934309, 0.33326868171585994, 0.9965315983446844, 0.19736029711789152, 0.7894411884715661, 0.11823157925193147, 0.8706143563096771, 0.9986146051105116, 0.2890044002629238, 0.3441911701623766, 0.36742770485688303, 0.7831162108503922, 0.20429118543923275, 0.16294830585068634, 0.5389828578138087, 0.2958138475443229, 0.9648099379161967, 0.2772332714052884, 0.08847870363998567, 0.6311480859652311, 0.21600060367911128, 0.15278091479742018, 0.1317076851701898, 0.35297659625610867, 0.15014676109401637, 0.3647980785827479, 0.12264762986833765, 0.49373533049561563, 0.01572405511132534, 0.14671439304440323, 0.15295755870586722, 0.5462769953780972, 0.15295755870586722, 0.9342303174306259, 0.9976349500431307, 0.992953936038466, 0.3903546850951243, 0.2374657667662006, 0.1577683518926127, 0.03903546850951242, 0.1740331304382429, 0.9823893824694941, 0.0962614806610026, 0.8823969060591905, 0.7536506415920536, 0.0662933434733751, 0.08722808351759881, 0.0942063301990067, 0.9789328727071455, 0.04060222161585197, 0.1461679978170671, 0.1502282199786523, 0.5440697696524164, 0.11774644268597072, 0.5212606704468183, 0.29519421480500824, 0.18309514589171397, 0.05171131332721125, 0.9308036398898026, 0.9603213101013742, 0.9412559824243385, 0.5617167725148883, 0.22963264285199836, 0.13071396593113752, 0.07772181758067637, 0.21706175363861938, 0.7597161377351678, 0.842613010257086, 0.13590532423501386, 0.1126413755376302, 0.1457711918722273, 0.1126413755376302, 0.6360924736242647, 0.8613362280527505, 0.13892519807302428, 0.7273451890456458, 0.15271660552915695, 0.11906718397188508, 0.1483250745955697, 0.7508956901400717, 0.09270317162223107, 0.5829222069780227, 0.41361759539249404, 0.9715607752189033, 0.5163342088962302, 0.08522020923530013, 0.19801166263496206, 0.16292098824395612, 0.037597151133220645, 0.5216806622721686, 0.47545579346324224, 0.8567230887798157, 0.1427871814633026, 0.9675231374563288, 0.7666253395476795, 0.11368208457170913, 0.11659700981713757, 0.15027953647936523, 0.16854267459317696, 0.026612001251554256, 0.5452851236838079, 0.10905702473676157, 0.8979523449260778, 0.08730092242336868, 0.9879385877137328, 0.9743820388903885, 0.2553327786503921, 0.23360232940355025, 0.17520174705266267, 0.19557404322157695, 0.13988976702654463, 0.08961156171276194, 0.8513098362712385, 0.942764408296092, 0.7729612541137829, 0.22183641373669108, 0.9387334611842821, 0.058670841324017634, 0.9232813643299426, 0.9702131821863674, 0.9521968711928885, 0.23898696547215703, 0.34068354652413874, 0.28136054091048274, 0.1372903844201753, 0.28862714536697287, 0.7045897960429043, 0.908632157252979, 0.8634394529443279, 0.13205544574442662, 0.3564821109548309, 0.629785062686868, 0.9419250335047004, 0.9784903810889187, 0.9807014349348296], \"Term\": [\"34b\", \"34dd\", \"across\", \"across\", \"afraid\", \"ag\", \"appropriate\", \"area\", \"arm\", \"arm\", \"armpit\", \"athletic\", \"attach\", \"attach\", \"barely\", \"barely\", \"basic\", \"bc\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"begin\", \"beige\", \"bell\", \"beyond\", \"big\", \"big\", \"bit\", \"bit\", \"bit\", \"bit\", \"black\", \"black\", \"blue\", \"boot\", \"boxy\", \"boxy\", \"boyfriend\", \"breast\", \"breezy\", \"broad\", \"broad\", \"bulky\", \"bummer\", \"business\", \"bust\", \"bust\", \"buy\", \"buy\", \"buy\", \"buy\", \"calf\", \"cami\", \"cami\", \"care\", \"casual\", \"casual\", \"casual\", \"casually\", \"cheap\", \"chest\", \"chested\", \"chino\", \"chunky\", \"clean\", \"closure\", \"coat\", \"cold\", \"cold\", \"collar\", \"collar\", \"collar\", \"color\", \"color\", \"color\", \"color\", \"color\", \"comfort\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfy\", \"comfy\", \"compliment\", \"cooler\", \"could\", \"could\", \"could\", \"could\", \"could\", \"cozy\", \"cozy\", \"crazy\", \"cream\", \"cream\", \"cup\", \"curve\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cute\", \"cute\", \"cute\", \"cute\", \"day\", \"day\", \"dd\", \"dd\", \"denim\", \"denim\", \"denim\", \"design\", \"design\", \"design\", \"design\", \"design\", \"detail\", \"detail\", \"detail\", \"detail\", \"dress\", \"dressy\", \"dry\", \"easy\", \"easy\", \"edge\", \"everyday\", \"everywhere\", \"exchange\", \"experience\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fairly\", \"fairly\", \"fall\", \"fall\", \"fall\", \"favorite\", \"favorite\", \"favorite\", \"figure\", \"figure\", \"figure\", \"figure\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fix\", \"flatter\", \"flatter\", \"flatter\", \"flatter\", \"flatter\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flirty\", \"flower\", \"funny\", \"glad\", \"glad\", \"glove\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"hand\", \"head\", \"heel\", \"heel\", \"highly\", \"highly\", \"hip\", \"hip\", \"hip\", \"holiday\", \"house\", \"however\", \"however\", \"however\", \"hug\", \"hug\", \"huge\", \"im\", \"inch\", \"inseam\", \"interest\", \"interesting\", \"interesting\", \"itchy\", \"ivory\", \"jacket\", \"jacket\", \"jean\", \"jewelry\", \"jumpsuit\", \"justice\", \"knee\", \"knee\", \"knit\", \"knit\", \"large\", \"lavender\", \"lb\", \"lb\", \"lb\", \"lean\", \"leg\", \"leg\", \"legging\", \"legging\", \"length\", \"length\", \"length\", \"like\", \"like\", \"like\", \"like\", \"like\", \"linen\", \"literally\", \"little\", \"little\", \"little\", \"little\", \"little\", \"local\", \"local\", \"long\", \"long\", \"long\", \"longer\", \"longer\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lounge\", \"love\", \"love\", \"love\", \"love\", \"love\", \"many\", \"many\", \"many\", \"many\", \"many\", \"material\", \"material\", \"material\", \"material\", \"material\", \"maxi\", \"maybe\", \"maybe\", \"med\", \"medium\", \"medium\", \"medium\", \"midi\", \"money\", \"moss\", \"motif\", \"much\", \"much\", \"much\", \"much\", \"natural\", \"navy\", \"navy\", \"navy\", \"neck\", \"neck\", \"neck\", \"necklace\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nicely\", \"nicely\", \"nicely\", \"nicely\", \"night\", \"normal\", \"normal\", \"normally\", \"normally\", \"normally\", \"odd\", \"offer\", \"online\", \"online\", \"online\", \"opinion\", \"order\", \"order\", \"order\", \"order\", \"outfit\", \"overly\", \"oversized\", \"oversized\", \"overwhelm\", \"overwhelm\", \"pair\", \"pale\", \"panel\", \"pant\", \"pay\", \"peach\", \"perfect\", \"perfect\", \"perfect\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"person\", \"person\", \"person\", \"petite\", \"petite\", \"photo\", \"photo\", \"photo\", \"pic\", \"pic\", \"picture\", \"picture\", \"pilcro\", \"pink\", \"poncho\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purple\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"rack\", \"really\", \"really\", \"really\", \"really\", \"recommend\", \"recommend\", \"recommend\", \"red\", \"red\", \"red\", \"regular\", \"regular\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"return\", \"return\", \"review\", \"review\", \"review\", \"right\", \"right\", \"right\", \"right\", \"right\", \"run\", \"run\", \"sack\", \"sadly\", \"saw\", \"saw\", \"saw\", \"scarf\", \"sell\", \"sell\", \"sell\", \"shade\", \"sheer\", \"shift\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"shoe\", \"short\", \"short\", \"short\", \"shorten\", \"shorter\", \"shorter\", \"shoulder\", \"shoulder\", \"shoulder\", \"shrink\", \"shrink\", \"size\", \"size\", \"skin\", \"skinny\", \"skirt\", \"skirt\", \"sleeve\", \"sleeved\", \"sleeved\", \"slip\", \"slip\", \"small\", \"soft\", \"soft\", \"soft\", \"spot\", \"spot\", \"store\", \"store\", \"store\", \"strange\", \"stretch\", \"stretch\", \"stretch\", \"style\", \"style\", \"style\", \"style\", \"style\", \"summer\", \"summer\", \"summer\", \"summer\", \"super\", \"super\", \"super\", \"super\", \"support\", \"sweater\", \"tee\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thread\", \"throw\", \"throw\", \"tight\", \"tight\", \"tight\", \"tight\", \"tights\", \"time\", \"time\", \"time\", \"time\", \"time\", \"top\", \"top\", \"top\", \"transition\", \"transition\", \"travel\", \"trouser\", \"true\", \"true\", \"true\", \"true\", \"tuck\", \"tuck\", \"tummy\", \"tummy\", \"underneath\", \"underneath\", \"underneath\", \"underneath\", \"usual\", \"usual\", \"usually\", \"usually\", \"usually\", \"versatile\", \"versatile\", \"versatile\", \"waist\", \"waist\", \"waistband\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warm\", \"warm\", \"wash\", \"wash\", \"water\", \"way\", \"way\", \"way\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"weather\", \"weather\", \"wedding\", \"weird\", \"well\", \"well\", \"well\", \"well\", \"well\", \"whether\", \"whether\", \"whim\", \"white\", \"white\", \"winner\", \"winner\", \"wise\", \"wool\", \"wore\", \"work\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"wrist\", \"xl\", \"xl\", \"xs\", \"xs\", \"xxsp\", \"yellow\", \"zip\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 1, 3, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1351398900952735528699738294\", ldavis_el1351398900952735528699738294_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1351398900952735528699738294\", ldavis_el1351398900952735528699738294_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1351398900952735528699738294\", ldavis_el1351398900952735528699738294_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "MjvbJwsS1znV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "DfrWFMvz1znV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTNYAE8z1znV",
        "outputId": "28eab870-b667-49ef-c4ba-7ff4ad3f15c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4\n",
              "Doc_0  0.26743  0.14430  0.08270  0.00972  0.49586\n",
              "Doc_1  0.00677  0.15310  0.38276  0.13342  0.32395\n",
              "Doc_2  0.21194  0.18288  0.27501  0.15484  0.17533\n",
              "Doc_3  0.01311  0.19640  0.01250  0.39700  0.38098\n",
              "Doc_4  0.00700  0.18169  0.00679  0.63231  0.17221"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a8ce038-0a73-491a-80f4-b8f15c2c564d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.26743</td>\n",
              "      <td>0.14430</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.00972</td>\n",
              "      <td>0.49586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.00677</td>\n",
              "      <td>0.15310</td>\n",
              "      <td>0.38276</td>\n",
              "      <td>0.13342</td>\n",
              "      <td>0.32395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.21194</td>\n",
              "      <td>0.18288</td>\n",
              "      <td>0.27501</td>\n",
              "      <td>0.15484</td>\n",
              "      <td>0.17533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.01311</td>\n",
              "      <td>0.19640</td>\n",
              "      <td>0.01250</td>\n",
              "      <td>0.39700</td>\n",
              "      <td>0.38098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.00700</td>\n",
              "      <td>0.18169</td>\n",
              "      <td>0.00679</td>\n",
              "      <td>0.63231</td>\n",
              "      <td>0.17221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a8ce038-0a73-491a-80f4-b8f15c2c564d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a8ce038-0a73-491a-80f4-b8f15c2c564d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a8ce038-0a73-491a-80f4-b8f15c2c564d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "mcN_GgXn1znV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8xDQFFt1znV",
        "outputId": "8fb1510c-d1b0-484a-b991-b1cc63fcdd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  dominant_topic\n",
              "Doc_0  0.26743  0.14430  0.08270  0.00972  0.49586               4\n",
              "Doc_1  0.00677  0.15310  0.38276  0.13342  0.32395               2\n",
              "Doc_2  0.21194  0.18288  0.27501  0.15484  0.17533               2\n",
              "Doc_3  0.01311  0.19640  0.01250  0.39700  0.38098               3\n",
              "Doc_4  0.00700  0.18169  0.00679  0.63231  0.17221               3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0df95e41-71ff-4d99-bb5d-77fdea2c448a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_0</th>\n",
              "      <th>Topic_1</th>\n",
              "      <th>Topic_2</th>\n",
              "      <th>Topic_3</th>\n",
              "      <th>Topic_4</th>\n",
              "      <th>dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc_0</th>\n",
              "      <td>0.26743</td>\n",
              "      <td>0.14430</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.00972</td>\n",
              "      <td>0.49586</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_1</th>\n",
              "      <td>0.00677</td>\n",
              "      <td>0.15310</td>\n",
              "      <td>0.38276</td>\n",
              "      <td>0.13342</td>\n",
              "      <td>0.32395</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_2</th>\n",
              "      <td>0.21194</td>\n",
              "      <td>0.18288</td>\n",
              "      <td>0.27501</td>\n",
              "      <td>0.15484</td>\n",
              "      <td>0.17533</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_3</th>\n",
              "      <td>0.01311</td>\n",
              "      <td>0.19640</td>\n",
              "      <td>0.01250</td>\n",
              "      <td>0.39700</td>\n",
              "      <td>0.38098</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_4</th>\n",
              "      <td>0.00700</td>\n",
              "      <td>0.18169</td>\n",
              "      <td>0.00679</td>\n",
              "      <td>0.63231</td>\n",
              "      <td>0.17221</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0df95e41-71ff-4d99-bb5d-77fdea2c448a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0df95e41-71ff-4d99-bb5d-77fdea2c448a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0df95e41-71ff-4d99-bb5d-77fdea2c448a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "lokSgJuX1znV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhpuPPRa1znV",
        "outputId": "0416933f-afca-4708-923d-e6b46357d2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "mAXYdMnj1znV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "Rx0tMbkj1znW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "mAP_jcmc1znW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpxtdIo41znW",
        "outputId": "efef73d4-ab95-494a-dafc-7991f0c2251e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score for the model:  -1.99131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "Y55PGVnQ1znW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUeu5brg1znW",
        "outputId": "a14cac27-b645-4fe1-cc2e-5dfab09fd3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score by topic (higher values are better):  [-2.19056 -1.78003 -2.19029 -1.99035 -1.80531]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "V0C9Tlug1znW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9OHWz31znW",
        "outputId": "ca0ab936-de03-4eb3-f210-657f0befe2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log-Likelihood (higher values are better):  -622660.6536874948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "_RrojRWP1znW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2M9cpmp1znX",
        "outputId": "ac551d22-ba6d-4504-faad-d1db9bddf539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (lower values are better):  444.14405115823604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "a0CYZRSo1znX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OeS48rsA11ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Millen_dress**"
      ],
      "metadata": {
        "id": "Bs963S1k12Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_Millen_dress)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "AaG8oruT12Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "02AinK2p12Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "Zuv0_ILR12Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "id": "hqyfp1Ar12Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "PLmSHlaV12Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "id": "4zH1-mN112Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "0SYSS8H912Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "cgb5uGjW12Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "id": "I2dhDsUH12Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "tHRGTtTS12Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "AGS_ddDv12Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "c95qCCa212Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "6q1fOz_Q12Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "LmXG0nMi12Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "_I692V8r12Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "h9OvSMK812Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "E2qja8Zn12Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "KULiIZNM12Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "QQi6atm612Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "id": "J9IlEMci12Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "OHEgAUgo12Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "id": "na77NTj212Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "-aFGz_6K12Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "id": "ycBrKQ2J12Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "34snd7nt12Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "id": "91UDX3pf12Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "As6fgpLo12Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-amqi6Y13hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Millen_bottoms**"
      ],
      "metadata": {
        "id": "-a4XtoTG133J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_Millen_bottoms)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "WB6qOw93133J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "rxo5ILtf133J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "qltMXZJF133J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "id": "y7QHNLWS133J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "oeJzFtwU133J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "id": "PLSTGGjn133J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "rK3tHulI133J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "NMNgEGpn133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "id": "VAX-jrhc133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "h6ZDzMmK133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "Wz39gUlK133K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "jQrpemuo133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "sory8908133K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "7O-uUaaE133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "QK6xWUD5133K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "8niZeoCj133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "5LUqZUDy133K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "b2OTQEme133K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "YxKTWo5M133L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "id": "kHRpNTy4133L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "l5sheVmg133L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "id": "Io-Re5iC133L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "DA_6Vje3133L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "id": "4yTKVqyj133L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "i87NkeR_133L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "id": "FQSxt0c0133L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "-BwoJmVB133L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOgcEPf_144E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GenX_tops**"
      ],
      "metadata": {
        "id": "FolACw4-15Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_GenX_tops)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "Od7yvBVY15Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "3fCXj5ro15Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "uRIBAlu_15Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "id": "Yv3kSoBo15Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "5ivEIJ6r15Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "id": "VE5jlBf015Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "ADTpbbEo15Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "6HhTNWDY15Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "id": "lSWOUNbl15Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "7U1Ys9Nv15Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "rYYX7tn615Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "Ns0p13ep15Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "TvenP6R-15Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "shU9Z2hB15Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "J2q62lEf15Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "b9XV67wy15Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "3YbJbIht15Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "MpWHQOXz15Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "xKFH7LFB15Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "id": "KPB3YXzl15Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "BLeIdiVg15Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "id": "fnpT_vbh15Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "e8XD7KAE15Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "id": "iMa2eDnE15Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "trerO6eJ15Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "id": "EKD0K4js15Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "QccDjs9B15Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3d_YF8es16C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GenX_dress**"
      ],
      "metadata": {
        "id": "pY5BpysB16Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_GenX_dress)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "ToBRb5s616Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "5hxwMQCI16Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "R8xbAFWD16Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "id": "YUP1n1U716Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "Wr7XUwjF16Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "id": "NOAMJpvl16Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "b4PmxGao16Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "VV32OfMx16Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "id": "CRIx8MZx16Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "HLBCKumN16Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "lfwrB4UF16Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "ZNSvX8zA16Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "JjDIIaoP16Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "0a1aiLOk16Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "2omaZsKo16Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "QiCb7TqX16Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "YMcQigQ516Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "5hTCcRK916Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "Jb20gIFD16Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "id": "NUC_mRaz16Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "xpqGu5hd16Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "id": "701nF7n116Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "t_1-QtiK16Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "id": "oEzPwoJB16Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "hP8hVSFn16Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "id": "oVzA9Deb16Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "iC7vc-em16Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmN8josg17Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GenX_bottoms**"
      ],
      "metadata": {
        "id": "wA9QjVzM17is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize data\n",
        "normalized_corpus_news = normalize_corpus(df_GenX_bottoms)\n",
        "\n",
        "#define a Bag-of-Words vecgtorizer\n",
        "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
        "\n",
        "#vectorize data\n",
        "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
      ],
      "metadata": {
        "id": "5BbjH-e317it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news = LatentDirichletAllocation(n_components=5, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_news_corpus)"
      ],
      "metadata": {
        "id": "h6vDw1WI17it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results with top 10 words for each topic:"
      ],
      "metadata": {
        "id": "lmHMYPYH17it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_news, bow_vectorizer_news.get_feature_names(), no_top_words_news)"
      ],
      "metadata": {
        "id": "svtFZ-oi17it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display **word vectors** (words are in alphabetical order) for each topic. Each column is a topic:"
      ],
      "metadata": {
        "id": "-9Zj7gi517it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_news.components_ / lda_news.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T, \n",
        "                               index = bow_vectorizer_news.get_feature_names(), \n",
        "                               columns = [\"Topic_\" + str(i) for i in range(5)])\n",
        "word_weights_df.head(10)"
      ],
      "metadata": {
        "id": "aaa1NIcY17iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **sort by word weights in Topic 0** (descending order) and see the weights by 10 most frequent words in Topic 0:"
      ],
      "metadata": {
        "id": "ckrLkYjT17iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "sYOOkNpL17iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
      ],
      "metadata": {
        "id": "qAfNelgp17iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_news.transform(bow_news_corpus)"
      ],
      "metadata": {
        "id": "DVMjGNsq17iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert lda_news_topic_weights into a nice-looking dataframe and have a look at the computed topic weights in documents:"
      ],
      "metadata": {
        "id": "K8s08YEn17iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_news))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(5)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 5), columns=topic_names, index=doc_names)\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "Vcl3qitZ17iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topic with the highest weight in each document is a **dominant topic**. The weights across the 4 topics sum up to 1. Let's add a column that shows dominant topic for each document:"
      ],
      "metadata": {
        "id": "ZAwUp6Oh17iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "df_document_topic.head(5)"
      ],
      "metadata": {
        "id": "i6YnmiTw17iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models. \n",
        "\n",
        "How do you specify different models? You can set **different number of topics** and also play with the **parameters of the Dirichlet distributions**. \n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score. Let's install the gensim package and the functions needed:"
      ],
      "metadata": {
        "id": "nb50D-TF17iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gensim\n",
        "import gensim\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "98v4RLkx17iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function CoherenceModel() needs as **inputs**:\n",
        "\n",
        "**1. Dictionary of the corpus**<br>\n",
        "**2. Corpus with each document represented as Bag-of-Words**<br>\n",
        "**3. An array of top words for each topic: we'll have top 20 words for each topic** \n",
        "  \n",
        "We will now create those objects:"
      ],
      "metadata": {
        "id": "oJeWNHjS17iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "news_corpus_tokenized = [tokenize_text(normalized_corpus_news[doc_id]) for doc_id in range(len(normalized_corpus_news))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "news_dictionary = Dictionary(news_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "news_corpus_bow = [news_dictionary.doc2bow(doc) for doc in news_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer_news, lda_model = lda_news, n_words=20)"
      ],
      "metadata": {
        "id": "vXpW7LZ-17iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute **the coherence score for the model overall**. We use one of the coherence metrics \"u-mass\" which measures semantic similarity of words in a topic, but there are other metrics as well.\n",
        "\n",
        "*Note: You can check out different coherence metrics here if you are interested: https://dl.acm.org/doi/abs/10.1145/2684822.2685324*"
      ],
      "metadata": {
        "id": "SpSzT-vQ17iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords, \n",
        "                    corpus = news_corpus_bow , \n",
        "                    dictionary = news_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 5))  # get coherence value"
      ],
      "metadata": {
        "id": "Cicj5V8217iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also see **coherence scores by topic**:"
      ],
      "metadata": {
        "id": "V6E-ZMAa17iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),5))"
      ],
      "metadata": {
        "id": "1NFG7J4317iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Likelihood Score**\n",
        "\n",
        "To compute the log-likelihood score we use the **.score** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "RPAF4FVT17iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Log-Likelihood (higher values are better): \", lda_news.score(bow_news_corpus))"
      ],
      "metadata": {
        "id": "7sVHyom617ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity Score**\n",
        "\n",
        "To compute the Perplexity score we use the **.perplexity** attribute of our defined and fitted LDA function:"
      ],
      "metadata": {
        "id": "Ls66IVBU17ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity (lower values are better): \", lda_news.perplexity(bow_news_corpus))"
      ],
      "metadata": {
        "id": "pH--R1C117ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**NOTE:** Generally, you can write a simple script that selects the best topic model **automatically** based on a criterion for \"best model\" (log-likelihood, perplexity, or coherence score). The script can vary both parameters of the Dirichlet distributions and the number of topics, or just the number of topics."
      ],
      "metadata": {
        "id": "kLq5BYgP17ix"
      }
    }
  ]
}